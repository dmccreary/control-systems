{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Control Systems","text":""},{"location":"about/","title":"About the Control Systems Course","text":""},{"location":"course-description/","title":"Course Description","text":"<p>Title: Control Systems</p>"},{"location":"course-description/#course-overview","title":"Course Overview","text":"<p>This course introduces the analysis and design of feedback control systems used to regulate the behavior of dynamic systems. Students develop mathematical models of physical systems, analyze system behavior in the time and frequency domains, and design controllers to meet performance, stability, and robustness requirements.</p> <p>The course emphasizes classical control theory using mathematically rigorous and conceptually stable techniques that remain relevant across technologies and application domains. Computational tools are used to support analysis and visualization, while laboratories and projects reinforce engineering judgment through simulation and data-driven validation.</p>"},{"location":"course-description/#intended-audience","title":"Intended Audience","text":"<p>This course is intended for:</p> <ul> <li>Upper-division undergraduate students in Electrical Engineering  </li> <li>Students in Mechanical Engineering, Computer Engineering, or Mechatronics programs with sufficient mathematical preparation  </li> <li>Engineering students preparing for advanced coursework in robotics, embedded systems, power systems, signal processing, and cyber-physical systems  </li> </ul>"},{"location":"course-description/#prerequisites","title":"Prerequisites","text":"<p>Here is a list of the specific mathematical and technical skills students are expected to have proficiency in before they take this course:</p> <ul> <li>Calculus (differentiation, integration, basic multivariable concepts)  </li> <li>Differential equations (first- and second-order linear ODEs)  </li> <li>Linear algebra (vectors, matrices, eigenvalues and eigenvectors at a conceptual level)  </li> <li>Complex numbers (rectangular and polar forms, magnitude and phase)  </li> <li>Signals and systems concepts (LTI systems recommended)  </li> <li>Basic programming or scripting experience (MATLAB, Python, or equivalent)  </li> </ul>"},{"location":"course-description/#detailed-topics-covered","title":"Detailed Topics Covered","text":""},{"location":"course-description/#foundations-of-control-systems","title":"Foundations of Control Systems","text":"<ul> <li>Purpose and applications of control systems  </li> <li>Open-loop versus closed-loop control  </li> <li>Feedback concepts and real-world examples  </li> </ul>"},{"location":"course-description/#system-modeling","title":"System Modeling","text":"<ul> <li>Differential equation models of dynamic systems  </li> <li>Electrical, mechanical, and electromechanical analogies  </li> <li>Linearization of nonlinear systems (introductory)  </li> <li>Transfer function representations  </li> </ul>"},{"location":"course-description/#laplace-transform-methods","title":"Laplace Transform Methods","text":"<ul> <li>Laplace transform review  </li> <li>Poles, zeros, and system behavior  </li> <li>Initial and final value theorems  </li> </ul>"},{"location":"course-description/#block-diagrams-and-signal-flow","title":"Block Diagrams and Signal Flow","text":"<ul> <li>Block diagram representation of systems  </li> <li>Block diagram reduction techniques  </li> <li>Signal flow graphs and Mason\u2019s gain formula (introductory)  </li> </ul>"},{"location":"course-description/#time-domain-analysis","title":"Time-Domain Analysis","text":"<ul> <li>Step, ramp, and impulse responses  </li> <li>Transient response specifications  </li> <li>Steady-state error analysis  </li> </ul>"},{"location":"course-description/#stability-analysis","title":"Stability Analysis","text":"<ul> <li>Concept of stability in feedback systems  </li> <li>Routh\u2013Hurwitz stability criterion  </li> <li>Root locus analysis  </li> </ul>"},{"location":"course-description/#frequency-domain-analysis","title":"Frequency-Domain Analysis","text":"<ul> <li>Sinusoidal steady-state response  </li> <li>Bode magnitude and phase plots  </li> <li>Gain margin and phase margin  </li> <li>Nyquist stability criterion (introductory)  </li> </ul>"},{"location":"course-description/#controller-design","title":"Controller Design","text":"<ul> <li>Proportional, integral, and derivative control  </li> <li>PID controller tuning concepts  </li> <li>Lead and lag compensation  </li> <li>Performance\u2013robustness tradeoffs  </li> </ul>"},{"location":"course-description/#computer-aided-analysis","title":"Computer-Aided Analysis","text":"<ul> <li>Time-domain simulation  </li> <li>Frequency-domain visualization  </li> <li>Validation of analytical results using computational tools  </li> </ul>"},{"location":"course-description/#concepts-not-covered-in-this-course","title":"Concepts NOT covered in this course","text":"<p>The course scope is bounded to classical, continuous-time, SISO control using transfer function methods, with frequency and time-domain analysis. Any learning graph should exclude state-space methods, digital control, MIMO systems, and advanced nonlinear/optimal/robust control techniques.</p> <ul> <li>State-space representation and state feedback design</li> <li>Discrete-time/digital control (Z-transforms, sampling)</li> <li>Multi-input multi-output (MIMO) systems</li> <li>Lyapunov stability theory</li> <li>Optimal control (LQR, LQG, MPC)</li> <li>Robust control (H\u221e, \u03bc-synthesis)</li> <li>Adaptive control</li> <li>Nonlinear control methods (beyond basic linearization)</li> <li>Kalman filtering and state estimation</li> <li>Hardware implementation (sensors, actuators, real-time systems)</li> </ul> <p>Note that specific hardware used in labs might be found in an appendix to this book, but they are not mentioned in the main chapter content.</p>"},{"location":"course-description/#blooms-taxonomy-2001-learning-objectives","title":"Bloom\u2019s Taxonomy (2001) Learning Objectives","text":""},{"location":"course-description/#1-remember","title":"1. Remember","text":"<p>Students will be able to:</p> <ul> <li>Recall fundamental control systems terminology  </li> <li>Identify standard control system block diagram symbols  </li> <li>List common performance specifications for control systems  </li> <li>Recognize standard test inputs used in system analysis  </li> <li>Recall definitions of stability and steady-state error  </li> <li>Identify typical controller structures (P, PI, PID)  </li> </ul>"},{"location":"course-description/#2-understand","title":"2. Understand","text":"<p>Students will be able to:</p> <ul> <li>Explain the purpose and benefits of feedback control  </li> <li>Describe how system poles and zeros affect response  </li> <li>Interpret time-domain response plots  </li> <li>Explain the meaning of Bode magnitude and phase plots  </li> <li>Summarize stability concepts using qualitative reasoning  </li> <li>Describe controller parameter effects on system behavior  </li> </ul>"},{"location":"course-description/#3-apply","title":"3. Apply","text":"<p>Students will be able to:</p> <ul> <li>Compute transfer functions from system models  </li> <li>Apply Laplace transforms to analyze dynamic systems  </li> <li>Calculate time-domain performance metrics  </li> <li>Use computational tools to simulate system response  </li> <li>Construct block diagrams for interconnected systems  </li> <li>Apply standard tuning rules to PID controllers  </li> </ul>"},{"location":"course-description/#4-analyze","title":"4. Analyze","text":"<p>Students will be able to:</p> <ul> <li>Analyze system stability using root locus techniques  </li> <li>Compare open-loop and closed-loop system behavior  </li> <li>Analyze frequency response to assess robustness  </li> <li>Decompose complex systems into simpler subsystems  </li> <li>Evaluate the impact of controller parameters on performance  </li> <li>Analyze tradeoffs between speed, accuracy, and stability  </li> </ul>"},{"location":"course-description/#5-evaluate","title":"5. Evaluate","text":"<p>Students will be able to:</p> <ul> <li>Assess whether a control system meets design specifications  </li> <li>Judge system robustness using stability margins  </li> <li>Critique controller designs based on simulation results  </li> <li>Evaluate modeling assumptions and their limitations  </li> <li>Compare alternative controller strategies  </li> <li>Interpret experimental or simulated data to draw conclusions  </li> </ul>"},{"location":"course-description/#6-create","title":"6. Create","text":"<p>Students will be able to:</p> <ul> <li>Design feedback controllers to meet given requirements  </li> <li>Develop mathematical models for new physical systems  </li> <li>Integrate modeling, analysis, and simulation into a design workflow  </li> <li>Create and document complete control system solutions  </li> <li>Implement and test controllers in simulation or laboratory settings  </li> <li>Propose design improvements based on performance evaluation  </li> </ul>"},{"location":"course-description/#abet-alignment","title":"ABET Alignment","text":"<p>This course is designed to align with the student outcomes and curricular expectations of the Accreditation Board for Engineering and Technology (ABET) for undergraduate electrical engineering programs, emphasizing analytical rigor, design competence, and professional engineering practice.</p> <p>See ABET CRITERIA FOR ACCREDITING ENGINEERING TECHNOLOGY PROGRAMS</p>"},{"location":"appendix/","title":"Appendicies","text":"<p>Introducing Gyra</p> <p>Consumer Products that Use Control Theory</p>"},{"location":"appendix/consumer-products-that-use-control-theory/","title":"Consumer Products that Use Control Systems","text":""},{"location":"appendix/consumer-products-that-use-control-theory/#self-balancing-and-personal-mobility-products","title":"Self-Balancing and Personal Mobility Products","text":""},{"location":"appendix/consumer-products-that-use-control-theory/#segway-personal-transporter","title":"Segway Personal Transporter","text":"<p>Core control idea: Real-time inverted-pendulum stabilization</p> <p>Tech: The Segway relies on continuous closed-loop control to stabilize an inherently unstable inverted-pendulum system. Multiple high-rate inertial sensors (gyroscopes and accelerometers) feed real-time state estimates into a control processor that computes corrective wheel torques hundreds of times per second. Classical PID control is used for fast inner-loop stabilization, while higher-level control layers manage velocity, acceleration limits, and rider intent. Sensor fusion techniques improve robustness to noise and bias, and actuator saturation handling ensures stability under abrupt disturbances such as uneven terrain or sudden rider movement.</p>"},{"location":"appendix/consumer-products-that-use-control-theory/#self-balancing-hoverboards","title":"Self-Balancing Hoverboards","text":"<p>Core control idea: Dynamic balance control under variable loads</p> <p>Tech: Hoverboards implement tightly coupled balance and motion controllers using low-cost microcontrollers and MEMS IMUs. The system continuously estimates pitch angle and angular velocity, applying PID-based torque commands to each wheel motor to maintain upright balance. Nested control loops separate fast stabilization from slower velocity and turning commands, allowing intuitive rider input through weight shifts. Despite cost constraints, these systems must address nonlinear dynamics, sensor noise, and actuator delays while maintaining acceptable safety margins.</p>"},{"location":"appendix/consumer-products-that-use-control-theory/#electric-unicycles","title":"Electric Unicycles","text":"<p>Core control idea: Single-axis stabilization with velocity regulation</p> <p>Tech: Electric unicycles use a minimalist control architecture focused on stabilizing a single wheel beneath the rider. A fast inner-loop controller maintains pitch stability, while an outer-loop controller regulates forward speed based on rider lean angle. High sampling rates and careful tuning are required to maintain stability with limited lateral support. The system must handle nonlinear dynamics, abrupt load changes, and power limitations while providing smooth and predictable behavior.</p>"},{"location":"appendix/consumer-products-that-use-control-theory/#consumer-drones-and-camera-stabilization","title":"Consumer Drones and Camera Stabilization","text":""},{"location":"appendix/consumer-products-that-use-control-theory/#dji-consumer-drones","title":"DJI Consumer Drones","text":"<p>Core control idea: Multivariable flight control</p> <p>Tech: Quadcopter drones employ cascaded multi-axis control systems to manage roll, pitch, yaw, and altitude simultaneously. Inner-loop PID controllers stabilize angular rates, while outer-loop controllers regulate position, velocity, and heading. State estimation is enhanced through Kalman filtering that fuses IMU, GPS, barometer, and vision data. Advanced implementations incorporate adaptive control and feedforward compensation to handle wind disturbances, payload changes, and aggressive maneuvering while maintaining flight stability and safety.</p>"},{"location":"appendix/consumer-products-that-use-control-theory/#motorized-camera-gimbals","title":"Motorized Camera Gimbals","text":"<p>Core control idea: High-bandwidth disturbance rejection</p> <p>Tech: Camera gimbals use precision feedback control to isolate cameras from external motion. High-speed IMUs measure angular disturbances, which are counteracted by brushless motors driven through tightly tuned PID controllers. The control system prioritizes low latency and high bandwidth to suppress hand tremors and sudden movements. Feedforward terms and friction compensation improve responsiveness, while sensor fusion minimizes drift and noise over extended operation.</p>"},{"location":"appendix/consumer-products-that-use-control-theory/#smart-home-and-domestic-robotics","title":"Smart Home and Domestic Robotics","text":""},{"location":"appendix/consumer-products-that-use-control-theory/#nest-smart-thermostat","title":"Nest Smart Thermostat","text":"<p>Core control idea: Closed-loop environmental regulation</p> <p>Tech: Smart thermostats implement classical feedback control to regulate indoor temperature while incorporating predictive and adaptive elements. Temperature sensors provide continuous feedback, and control algorithms adjust HVAC outputs to minimize steady-state error and oscillation. Learning models estimate building thermal dynamics and occupant behavior, allowing anticipatory control actions. The system balances comfort, energy efficiency, and actuator wear through carefully tuned control logic.</p>"},{"location":"appendix/consumer-products-that-use-control-theory/#robotic-vacuum-cleaners","title":"Robotic Vacuum Cleaners","text":"<p>Core control idea: Feedback-driven motion and navigation control</p> <p>Tech: Robotic vacuums integrate motion control with real-time sensing and navigation. Low-level controllers regulate wheel speeds and turning angles using feedback from encoders and inertial sensors. Higher-level control modules perform wall-following, obstacle avoidance, and trajectory correction based on sensor input. Modern systems incorporate simultaneous localization and mapping techniques, blending control theory with probabilistic state estimation to operate reliably in dynamic household environments.</p>"},{"location":"appendix/consumer-products-that-use-control-theory/#automotive-driver-assistance-systems","title":"Automotive Driver Assistance Systems","text":""},{"location":"appendix/consumer-products-that-use-control-theory/#adaptive-cruise-control","title":"Adaptive Cruise Control","text":"<p>Core control idea: Longitudinal vehicle control</p> <p>Tech: Adaptive cruise control systems maintain a safe following distance using closed-loop feedback based on radar or LiDAR measurements. Controllers adjust throttle and braking commands to regulate relative velocity and spacing. Control algorithms must ensure stability across a wide range of speeds, vehicle masses, and road conditions. Safety constraints, actuator limits, and human comfort requirements heavily influence controller design and tuning.</p>"},{"location":"appendix/consumer-products-that-use-control-theory/#lane-keeping-assist-systems","title":"Lane-Keeping Assist Systems","text":"<p>Core control idea: Lateral vehicle stabilization</p> <p>Tech: Lane-keeping systems use camera-based lane detection combined with vehicle state estimation to compute steering corrections. Feedback controllers regulate lateral position and heading angle while accounting for vehicle dynamics, road curvature, and speed. Control designs often include state-space models and observers to ensure smooth corrections without inducing oscillations or driver discomfort. Robustness to sensor noise and environmental variability is critical.</p>"},{"location":"appendix/consumer-products-that-use-control-theory/#wearable-and-human-centered-control-systems","title":"Wearable and Human-Centered Control Systems","text":""},{"location":"appendix/consumer-products-that-use-control-theory/#powered-prosthetic-limbs","title":"Powered Prosthetic Limbs","text":"<p>Core control idea: Human-in-the-loop adaptive control</p> <p>Tech: Powered prosthetics integrate sensors measuring force, joint angle, and muscle signals to infer user intent. Control systems employ impedance or admittance control to produce natural, compliant motion that adapts to both the user and the environment. Adaptive algorithms adjust control parameters over time to match individual gait patterns and activity levels. Stability and safety are paramount, requiring conservative yet responsive controller designs.</p>"},{"location":"appendix/consumer-products-that-use-control-theory/#lower-body-exoskeletons","title":"Lower-Body Exoskeletons","text":"<p>Core control idea: Cooperative gait control</p> <p>Tech: Exoskeletons coordinate actuator output with human motion through feedback from joint sensors and force measurements. Controllers synchronize with gait phases, applying assistive torque while preserving user balance and autonomy. Multi-layer control architectures separate real-time joint stabilization from higher-level gait planning. Robust control strategies ensure safe operation across varying walking speeds and terrain conditions.</p>"},{"location":"appendix/consumer-products-that-use-control-theory/#consumer-robotics-and-educational-toys","title":"Consumer Robotics and Educational Toys","text":""},{"location":"appendix/consumer-products-that-use-control-theory/#anki-vector-and-cozmo-robots","title":"Anki Vector and Cozmo Robots","text":"<p>Core control idea: Embedded balance and motion control</p> <p>Tech: These consumer robots combine classical control with higher-level behavior planning. Low-level PID controllers regulate wheel speed, steering, and balance, providing a stable physical platform. On top of this foundation, perception and decision-making modules issue motion commands that rely on predictable control responses. The architecture demonstrates how reliable feedback control enables expressive and interactive robotic behavior.</p>"},{"location":"appendix/consumer-products-that-use-control-theory/#self-balancing-robot-kits","title":"Self-Balancing Robot Kits","text":"<p>Core control idea: Educational inverted-pendulum control</p> <p>Tech: DIY self-balancing robots expose learners to real-world control challenges using microcontrollers and inertial sensors. PID controllers estimate tilt angle and apply corrective motor torque to maintain balance. The systems highlight issues such as sensor noise, loop timing, actuator saturation, and tuning sensitivity. These kits serve as practical demonstrations of core control theory concepts in an accessible and hands-on format.</p> <p>If you want, the next logical step would be to map each product to specific control-system topics (PID tuning, stability margins, observers, nonlinear dynamics) or turn this into a concept-to-product alignment table for your control systems textbook.</p>"},{"location":"appendix/gyra/","title":"Meet Gyra","text":""},{"location":"appendix/gyra/#meet-gyra-our-unbalancing-robot-mascot","title":"Meet Gyra - Our (un)Balancing Robot Mascot","text":"<p>Gyra is the official mascot of this control systems course. She is a small, two-wheel, self-balancing robot who is constantly fighting gravity. Gyra is not perfectly stable, not optimally tuned, and not afraid to fall over. Her purpose in the textbook is to turn abstract control concepts into a continuous narrative that gives students something tangible to care about.</p> <p>Throughout the course, students take on the role of Gyra\u2019s control engineers. Their mission is simple to state but challenging to achieve: help Gyra stay upright without wobbling, oscillating, or crashing too often.</p> <p>Gyra represents every real-world control system that is just a little unstable until someone understands it well enough to design the right controller.</p>"},{"location":"appendix/gyra/#physical-description","title":"Physical Description","text":"<p>Gyra is designed to look friendly, expressive, and slightly unstable.</p> <ul> <li>Height: Approximately knee-high to a human</li> <li>Body shape: Rounded, slightly top-heavy torso</li> <li>Center of mass: Intentionally high to make balancing difficult</li> <li>Wheels: Two moderately narrow wheels with visible motors</li> <li>Chassis: Exposed fasteners and panels that suggest frequent iteration and redesign</li> <li>Arms: Short, expressive arms that add personality but no physical stability</li> </ul> <p>Gyra\u2019s design makes it visually obvious why control is necessary. Without active feedback, she cannot remain upright for long.</p>"},{"location":"appendix/gyra/#sensors-and-actuators","title":"Sensors and Actuators","text":"<p>Gyra\u2019s hardware is intentionally visible and named in human terms to reinforce intuition.</p> <ul> <li>Inertial Measurement Unit (IMU), which Gyra refers to as her \u201cinner ear\u201d</li> <li>Gyroscope, her \u201csense of spin\u201d</li> <li>Accelerometers, which she describes as \u201clistening to gravity\u201d</li> <li>DC motors with limited torque and saturation</li> <li>Motor drivers with response delays and nonlinearities</li> </ul> <p>These components are used throughout the textbook to motivate discussions of modeling assumptions, noise, delay, saturation, and real-world constraints.</p>"},{"location":"appendix/gyra/#personality","title":"Personality","text":"<p>Gyra has a distinct personality that makes her relatable and memorable.</p> <ul> <li>Curious and eager to try new controller settings</li> <li>Optimistic, even after repeated falls</li> <li>Dramatic when oscillations grow too large</li> <li>Self-aware about her instability</li> <li>Honest about her limitations</li> </ul> <p>Gyra never blames the student when she falls. Instead, she treats each failure as useful information about the system.</p> <p>She frequently comments on her behavior in short narrative asides embedded in the text, helping students connect equations to physical outcomes.</p>"},{"location":"appendix/gyra/#role-in-the-textbook","title":"Role in the Textbook","text":"<p>Gyra serves multiple educational roles at once.</p>"},{"location":"appendix/gyra/#narrative-anchor","title":"Narrative Anchor","text":"<p>Each major topic in control systems is framed as a step forward in Gyra\u2019s development. Students are not just learning theory; they are helping Gyra improve.</p> <p>Examples include:</p> <ul> <li>Open-loop control as Gyra reacting too late</li> <li>Proportional control as Gyra becoming twitchy</li> <li>Integral action as Gyra accumulating past mistakes</li> <li>Derivative action as Gyra anticipating trouble</li> <li>Stability analysis as predicting whether Gyra will fall over eventually</li> </ul>"},{"location":"appendix/gyra/#concrete-system-model","title":"Concrete System Model","text":"<p>Gyra functions as a living system model.</p> <ul> <li>Her mass and geometry motivate system dynamics</li> <li>Her motors explain actuator limits</li> <li>Her delays motivate phase lag</li> <li>Her falls make instability consequences obvious</li> </ul> <p>Instead of abstract plants and blocks, Gyra gives students a system they can imagine clearly.</p>"},{"location":"appendix/gyra/#safe-failure-mechanism","title":"Safe Failure Mechanism","text":"<p>Gyra falls over often, especially early in the course. This is intentional.</p> <p>Her failures reinforce the idea that:</p> <ul> <li>Instability is expected during design</li> <li>Tuning is iterative</li> <li>Trade-offs are unavoidable</li> <li>Perfect control does not exist</li> </ul> <p>Students learn that falling over is not a mistake; it is data.</p>"},{"location":"appendix/gyra/#recurring-themes-and-metaphors","title":"Recurring Themes and Metaphors","text":"<p>Gyra introduces consistent metaphors that appear throughout the book.</p> <ul> <li>Overshoot is described as overreacting</li> <li>Oscillation is described as wobbling or panic</li> <li>Integral windup is described as holding onto past mistakes</li> <li>Damping is described as calming down</li> <li>Critical damping is described as feeling \u201cjust right\u201d</li> </ul> <p>These metaphors are repeated deliberately to build intuition alongside formal mathematics.</p>"},{"location":"appendix/gyra/#educational-philosophy","title":"Educational Philosophy","text":"<p>Gyra embodies the core philosophy of this course.</p> <p>Control systems are not about memorizing equations. They are about understanding behavior, predicting outcomes, and making thoughtful design choices under constraints.</p> <p>Gyra reminds students that every control system is ultimately trying to do something simple in a complicated world.</p> <p>Stay upright React in time Do not overreact Recover gracefully</p> <p>If Gyra can do that, so can the students.</p>"},{"location":"appendix/gyra/#closing-note","title":"Closing Note","text":"<p>Gyra is not perfect, and she never will be. Even at the end of the course, she still leans slightly forward, still hums quietly, and still needs feedback to stay upright.</p> <p>That is what makes her a control system.</p> <p>And that is why she belongs in this textbook.</p> <p>Note that Gyra was inspired by the real-world MIP Robot</p>"},{"location":"chapters/","title":"Chapters","text":"<p>This textbook is organized into 16 chapters covering 300 concepts in classical control systems.</p>"},{"location":"chapters/#chapter-overview","title":"Chapter Overview","text":"<ol> <li> <p>Introduction to Control Systems - Fundamental control concepts including feedback, open/closed-loop control, and system components.</p> </li> <li> <p>Dynamic System Properties - Essential properties of dynamic systems including linearity, time-invariance, and LTI systems.</p> </li> <li> <p>Time-Domain Response Fundamentals - System responses in the time domain including natural/forced response and damping characteristics.</p> </li> <li> <p>Transient Response Specifications - Quantitative measures of transient response including overshoot, settling time, and standard test inputs.</p> </li> <li> <p>Laplace Transform Methods - Laplace transform techniques for control analysis including s-domain representation and partial fractions.</p> </li> <li> <p>Poles, Zeros, and System Analysis - Relationship between pole-zero locations and system behavior.</p> </li> <li> <p>Physical System Modeling - Mathematical models for electrical, mechanical, and electromechanical systems.</p> </li> <li> <p>Linearization and Nonlinear Effects - Linearization techniques and common nonlinearities in control systems.</p> </li> <li> <p>Block Diagrams and Signal Flow - Graphical system representation including block diagram reduction and Mason's gain formula.</p> </li> <li> <p>Stability Analysis and Routh-Hurwitz - Stability concepts, characteristic equations, and the Routh-Hurwitz criterion.</p> </li> <li> <p>Root Locus Analysis and Design - Root locus method for analyzing closed-loop pole movement with gain.</p> </li> <li> <p>Frequency Response and Bode Plots - Frequency-domain analysis techniques including Bode plot construction and bandwidth.</p> </li> <li> <p>Nyquist Analysis and Stability Margins - Nyquist diagrams, stability criterion, and gain/phase margins.</p> </li> <li> <p>Steady-State Error Analysis - Steady-state accuracy, error constants, and system type classification.</p> </li> <li> <p>PID Control and Controller Tuning - Proportional, integral, and derivative control with tuning methods.</p> </li> <li> <p>Compensator Design and Performance - Lead/lag compensation and performance tradeoffs in control design.</p> </li> </ol>"},{"location":"chapters/#how-to-use-this-textbook","title":"How to Use This Textbook","text":"<p>The chapters are organized to respect concept dependencies\u2014each chapter builds on knowledge from previous chapters. Students should work through the chapters sequentially, as later topics assume familiarity with earlier material. The learning graph visualization shows how concepts connect across the textbook.</p> <p>Note: Each chapter includes a list of concepts covered. Make sure to complete prerequisites before moving to advanced chapters.</p>"},{"location":"chapters/01-intro-to-control-systems/","title":"Introduction to Control Systems","text":""},{"location":"chapters/01-intro-to-control-systems/#summary","title":"Summary","text":"<p>This chapter introduces the fundamental vocabulary and building blocks of control systems. Students will learn the difference between open-loop and closed-loop (feedback) control, and understand the roles of key system components including the plant, controller, actuator, and sensor. By the end of this chapter, students will be able to identify and describe the basic elements of any control system and explain how feedback enables systems to regulate their behavior.</p>"},{"location":"chapters/01-intro-to-control-systems/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 12 concepts from the learning graph:</p> <ol> <li>Control System</li> <li>Feedback</li> <li>Open-Loop Control</li> <li>Closed-Loop Control</li> <li>Plant</li> <li>Controller</li> <li>Actuator</li> <li>Sensor</li> <li>Reference Input</li> <li>Error Signal</li> <li>Disturbance</li> <li>System Response</li> </ol>"},{"location":"chapters/01-intro-to-control-systems/#prerequisites","title":"Prerequisites","text":"<p>This chapter assumes only the prerequisites listed in the course description.</p>"},{"location":"chapters/01-intro-to-control-systems/#welcome","title":"Welcome!","text":"Image generation prompt Generate a wide landscape image of junior high school kids playing with the MIP two-wheel self-balancing robot. Make the image 1.91:1 w/h ratio and make it 1200 pixels wide. The kids are in a brightly lit school with fun robotics parts around the room. The kids are smiling and laughing and having a great time. The kids are from a diverse gender and race profile.  <p>Welcome to the wonderful world of control systems\u2014where physics meets finesse, and math becomes magic! If you've ever wondered how a Segway stays upright, how a drone hovers in place, or how your car's cruise control keeps you at exactly 65 mph even going uphill, you're about to peek behind the curtain.</p> <p>Consider the MIP robot\u2014that delightful little self-balancing toy that zooms around on two wheels like a tiny, determined penguin. MIP (Mobile Inverted Pendulum) looks simple: just a round body perched on two wheels. But here's the thing\u2014balancing on two wheels is really hard. Try standing a broomstick on your palm. Now imagine doing that while the broomstick is also trying to drive somewhere. That's MIP's life, every millisecond of every day.</p> <p>Without control systems, MIP would face-plant immediately. But thanks to clever sensors measuring tilt angle, a microcontroller running control algorithms, and motors responding dozens of times per second, MIP doesn't just balance\u2014it dances, spins, and even plays games. The \"secret sauce\" is a feedback control loop that constantly asks: \"Am I falling? Which way? How fast?\" and responds with precisely the right motor commands to stay upright. It's like having superhuman reflexes, except the superhuman is math.</p> <p>Here's the exciting part: the same principles that make MIP balance also guide spacecraft to Mars, keep power grids stable, regulate your body temperature, and enable robots to perform surgery. Control systems are everywhere, hiding in plain sight, quietly making the modern world possible.</p> <p>By the end of this course, you'll understand how these systems work\u2014and more importantly, how to design them yourself. Think of it as becoming a Jedi Knight of engineering. The Force? That's feedback. Your lightsaber? Transfer functions and Bode plots. Your enemies? Instability and steady-state error. (Don't worry, we'll defeat them.)</p> <p>Mastering control systems theory is like gaining a superpower. It doesn't just help you understand the world around you\u2014from thermostats to Tesla autopilots\u2014it empowers you to create innovative products that seemed impossible before. Ready to begin? Let's go!</p>"},{"location":"chapters/01-intro-to-control-systems/#meet-gyra","title":"Meet Gyra","text":"<p>Gyra is a two-wheel, self-balancing robot who lives at the edge of stability. Left on her own, she wobbles, overcorrects, and eventually tips over\u2014not because she is broken, but because physics is unforgiving. Gyra responds to the world through sensors, motors, and feedback, and every choice made in her controller shapes how she behaves. Throughout this course, you will take on the role of Gyra\u2019s control engineer. Many concepts you learn will help her react faster, overshoot less, and recover more gracefully when disturbances occur. By the end of the book, Gyra may still lean and hum quietly as she balances, but she will do so with confidence\u2014because you designed the system that keeps her upright.</p>"},{"location":"chapters/01-intro-to-control-systems/#what-is-a-control-system","title":"What Is a Control System?","text":"<p>A control system is an interconnection of components designed to achieve a desired behavior or output. Control systems are everywhere in engineering\u2014from the thermostat in your home that maintains a comfortable temperature to the autopilot systems that guide aircraft through complex flight paths. The fundamental purpose of any control system is to make a physical process behave in a predictable, desired manner, even in the presence of external disturbances or internal uncertainties.</p> <p>Control systems can be characterized by how they respond to commands and disturbances. At the most basic level, engineers distinguish between two fundamental architectures:</p> <ul> <li>Open-loop control systems that execute pre-planned actions without monitoring the result</li> <li>Closed-loop control systems (also called feedback control systems) that continuously measure the output and adjust their behavior accordingly</li> </ul> <p>Understanding this distinction forms the foundation for everything that follows in control systems engineering.</p>"},{"location":"chapters/01-intro-to-control-systems/#diagram-control-system-examples-in-daily-life","title":"Diagram: Control System Examples in Daily Life","text":"Control System Examples in Daily Life <p>Type: infographic</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: identify, exemplify</p> <p>Learning Objective: Students will identify control systems in everyday contexts and classify them as open-loop or closed-loop, building intuition before formal definitions.</p> <p>Layout: Interactive grid of 6-8 clickable icons representing common systems</p> <p>Examples to include:</p> <ol> <li>Toaster (open-loop) - timer-based, no measurement of bread color</li> <li>Thermostat/HVAC (closed-loop) - temperature sensor provides feedback</li> <li>Washing machine timer (open-loop) - fixed cycle regardless of cleanliness</li> <li>Cruise control (closed-loop) - speedometer provides feedback to throttle</li> <li>Traffic light with fixed timing (open-loop) - no traffic measurement</li> <li>Traffic light with sensors (closed-loop) - detects vehicles waiting</li> </ol> <p>Interactive elements: - Click on each icon to reveal: system name, input, output, whether feedback is present - Hover shows brief description - Color coding: blue border for closed-loop, orange border for open-loop</p> <p>Visual style: Clean icons with modern flat design, arranged in 2 rows of 3-4</p> <p>Implementation: HTML/CSS/JavaScript with click handlers revealing info panels</p> <p>For a longer list of consumer products that use control theory see our Appendix: Consumer Products that Use Control Theory</p>"},{"location":"chapters/01-intro-to-control-systems/#open-loop-control","title":"Open-Loop Control","text":"<p>An open-loop control system operates without measuring or using information about its actual output. The controller generates a command signal based solely on the input and a predetermined relationship (often a model or calibration) between input and expected output. Because there is no feedback path from the output to the input, the system cannot automatically compensate for disturbances or modeling errors.</p> <p>Consider a simple toaster as an example of open-loop control. You set a timer (the input), and the heating element runs for that duration regardless of whether the bread is actually toasted to your preference. If the bread is thicker than usual or the starting temperature is different, the output quality varies\u2014but the toaster has no way to detect or correct for these conditions. This is why we've all experienced the tragedy of charcoal bread or the disappointment of warm, pale slices that still dream of becoming toast.</p> <p>The block diagram for an open-loop system is straightforward:</p> Component Role Reference Input The desired setpoint or command Controller Converts the reference into an actuation signal Plant The physical system being controlled Output The actual system response <p>Open-loop systems are simpler and less expensive than closed-loop alternatives. However, they are vulnerable to:</p> <ul> <li>Disturbances that push the output away from the desired value</li> <li>Model inaccuracies where the assumed input-output relationship is imperfect</li> <li>Parameter variations as system characteristics change over time</li> </ul> <p>Open-loop control is appropriate when disturbances are small, the system model is accurate and stable, and precision requirements are modest.</p>"},{"location":"chapters/01-intro-to-control-systems/#closed-loop-control-and-feedback","title":"Closed-Loop Control and Feedback","text":"<p>The key innovation of closed-loop control is the addition of feedback\u2014a measurement of the actual output that is compared to the desired reference input. This comparison produces an error signal, which the controller uses to adjust its output and drive the system toward the desired behavior.</p> <p>Feedback is the defining characteristic of closed-loop control. By continuously measuring the output and comparing it to the reference, the system can:</p> <ul> <li>Reject disturbances by automatically compensating for their effects</li> <li>Reduce sensitivity to parameter variations and modeling errors</li> <li>Track changing reference inputs more accurately</li> </ul> <p>The concept of feedback appears throughout nature and engineering. Biological systems use feedback extensively\u2014your body regulates temperature, blood sugar, and countless other variables through feedback mechanisms. Engineers have formalized these principles to create robust control systems for industrial, aerospace, automotive, and consumer applications.</p> <p>Why Feedback Matters</p> <p>Feedback allows a control system to be \"self-correcting.\" Even if the controller doesn't have a perfect model of the plant, or if unexpected disturbances occur, the feedback loop enables the system to detect and reduce errors automatically.</p>"},{"location":"chapters/01-intro-to-control-systems/#the-standard-feedback-control-loop","title":"The Standard Feedback Control Loop","text":"<p>The standard closed-loop feedback system consists of several interconnected components, each with a specific role. Understanding these components and how they interact is essential for analyzing and designing control systems.</p>"},{"location":"chapters/01-intro-to-control-systems/#diagram-standard-feedback-control-loop-block-diagram","title":"Diagram: Standard Feedback Control Loop Block Diagram","text":"Standard Feedback Control Loop Block Diagram <p>Type: diagram</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: explain, describe</p> <p>Learning Objective: Students will trace signal flow through a complete feedback control system, identifying each component's role and how signals transform as they propagate through the loop.</p> <p>Components to show (left to right): 1. Reference Input r(t) - arrow entering from left 2. Summing Junction (circle with +/- signs) - where error is computed 3. Error Signal e(t) = r(t) - y(t) - arrow from summing junction 4. Controller block - labeled \"Controller G_c(s)\" 5. Control signal u(t) - arrow from controller 6. Actuator block - labeled \"Actuator\" 7. Actuator output - arrow to plant 8. Plant block - labeled \"Plant G_p(s)\" 9. Output y(t) - arrow to right (system response) 10. Disturbance d(t) - arrow entering at plant (from above) 11. Sensor block - labeled \"Sensor H(s)\" - in feedback path 12. Measured output - arrow from sensor back to summing junction (negative input)</p> <p>Signal labels at each connection point with clear notation.</p> <p>Visual style: Clean block diagram with: - Rectangular blocks for components - Circular summing junction with + at reference input, - at feedback - Arrows showing signal direction - Labels for all signals: r(t), e(t), u(t), d(t), y(t)</p> <p>Color scheme: - Reference/command path: blue - Feedback path: green - Disturbance: red - Plant/actuator: gray</p> <p>Interactive features: - Hover over any block to see detailed description - Hover over any signal arrow to see what that signal represents - Click on blocks to highlight the signal path through that component</p> <p>Implementation: vis-network or custom SVG with JavaScript hover handlers Canvas size: 800x400px, responsive width</p>"},{"location":"chapters/01-intro-to-control-systems/#reference-input","title":"Reference Input","text":"<p>The reference input \\(r(t)\\) represents the desired output or setpoint of the control system. In engineering notation, this signal specifies what we want the system output to be. For a temperature control system, the reference input would be the desired temperature setting. For a motor speed controller, it would be the commanded velocity.</p> <p>The reference input may be:</p> <ul> <li>A constant value (regulation problem)</li> <li>A time-varying trajectory (tracking problem)</li> <li>A step change from one setpoint to another</li> <li>A complex profile such as a ramp or sinusoidal pattern</li> </ul>"},{"location":"chapters/01-intro-to-control-systems/#the-summing-junction-and-error-signal","title":"The Summing Junction and Error Signal","text":"<p>The summing junction compares the reference input with the measured output to produce the error signal \\(e(t)\\). Mathematically:</p> \\[e(t) = r(t) - y_m(t)\\] <p>where \\(y_m(t)\\) is the measured output from the sensor. The error signal quantifies the difference between what we want (the reference) and what we have (the measured output). The controller's job is to drive this error toward zero.</p> <p>The summing junction is represented in block diagrams as a circle with plus and minus signs indicating how the inputs combine. The reference input enters with a positive sign, while the feedback signal enters with a negative sign, hence the term \"negative feedback.\" (Don't worry\u2014unlike the kind you might get on a group project, this type of negative feedback is actually helpful!)</p>"},{"location":"chapters/01-intro-to-control-systems/#controller","title":"Controller","text":"<p>The controller (sometimes called the compensator) processes the error signal and generates a command to the actuator. The controller embodies the control strategy\u2014the algorithm or transfer function that determines how the system should respond to errors. If the plant is the star of the show, the controller is the director\u2014making sure everything hits its mark and the performance goes smoothly.</p> <p>Controllers range from simple proportional amplifiers to sophisticated algorithms that incorporate:</p> <ul> <li>Proportional action (responding to current error)</li> <li>Integral action (responding to accumulated error)</li> <li>Derivative action (responding to rate of change of error)</li> <li>More advanced structures covered in later chapters</li> </ul> <p>The controller transfer function is often denoted \\(G_c(s)\\) in the Laplace domain, where \\(s\\) is the complex frequency variable.</p>"},{"location":"chapters/01-intro-to-control-systems/#actuator","title":"Actuator","text":"<p>The actuator converts the controller's command signal into physical action on the plant. Actuators bridge the gap between the electrical signals in the control system and the mechanical, thermal, or other physical quantities being controlled. They're the \"muscle\" of the operation\u2014all the controller's brilliant ideas mean nothing if the actuator can't make them happen in the real world.</p> <p>Common actuator examples include:</p> Application Actuator Type Motor control Power amplifier and electric motor Valve control Pneumatic or hydraulic servo Thermal control Heating element or cooling fan Flight control Hydraulic servo driving control surfaces Robotic arm Electric servomotor at each joint <p>In many analyses, the actuator dynamics are combined with the plant dynamics, but for high-performance systems, actuator limitations (bandwidth, saturation, slew rate) must be modeled explicitly.</p>"},{"location":"chapters/01-intro-to-control-systems/#plant","title":"Plant","text":"<p>The plant is the physical system or process being controlled. (And no, we're not talking about your succulent on the windowsill\u2014though keeping that alive is its own control challenge!) The plant is what we ultimately want to regulate or manipulate. Everything else in the control loop\u2014controller, actuator, sensor\u2014exists to make the plant behave as desired.</p> <p>The plant transfer function \\(G_p(s)\\) characterizes how the plant output responds to its input. This mathematical model captures the plant's dynamics: how fast it responds, whether it oscillates, and how it settles to steady state.</p> <p>Examples of plants include:</p> <ul> <li>A DC motor (input: voltage, output: angular position or velocity)</li> <li>A heating system (input: power, output: temperature)</li> <li>An aircraft (input: control surface deflection, output: pitch angle)</li> <li>A chemical reactor (input: reactant flow rate, output: product concentration)</li> </ul>"},{"location":"chapters/01-intro-to-control-systems/#sensor","title":"Sensor","text":"<p>The sensor measures the plant output and converts it to a form suitable for comparison with the reference input. Sensors close the feedback loop by providing information about the actual system state. Think of the sensor as the system's eyes and ears\u2014constantly watching, always reporting. It's the control system equivalent of that friend who notices everything.</p> <p>Real sensors introduce their own dynamics and imperfections:</p> <ul> <li>Measurement noise: Random fluctuations in the measured signal</li> <li>Bias errors: Systematic offsets between true and measured values</li> <li>Dynamic response: Finite bandwidth limiting how fast changes can be tracked</li> <li>Quantization: Discrete steps when using digital sensors</li> </ul> <p>The sensor transfer function \\(H(s)\\) captures these dynamics. In ideal analyses, \\(H(s) = 1\\) (perfect measurement), but practical design must account for sensor limitations.</p>"},{"location":"chapters/01-intro-to-control-systems/#system-response","title":"System Response","text":"<p>The system response \\(y(t)\\) is the actual output of the plant\u2014the quantity we are trying to control. The goal of the feedback control system is to make this response track the reference input as closely as possible, despite disturbances and model uncertainties.</p> <p>System response characteristics include:</p> <ul> <li>Transient response: How the output behaves as it moves from one state to another</li> <li>Steady-state response: The final value the output settles to</li> <li>Tracking accuracy: How well the output follows a changing reference</li> <li>Disturbance rejection: How effectively the system suppresses unwanted inputs</li> </ul> <p>Later chapters will develop quantitative measures for these characteristics, but the fundamental goal remains the same: make \\(y(t)\\) follow \\(r(t)\\) as closely as possible.</p>"},{"location":"chapters/01-intro-to-control-systems/#diagram-interactive-feedback-loop-simulator","title":"Diagram: Interactive Feedback Loop Simulator","text":"Interactive Feedback Loop Simulator <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: demonstrate, execute</p> <p>Learning Objective: Students will observe how changing the controller gain affects closed-loop system response, developing intuition for the relationship between controller parameters and performance.</p> <p>Instructional Rationale: This Apply-level objective benefits from parameter exploration where students actively adjust the controller gain and observe the resulting system response in real-time, building intuition about feedback control behavior.</p> <p>Canvas layout: - Left side (500px): Time-domain plot showing reference input and system output - Right side (200px): Control panel with sliders and displays</p> <p>Visual elements: - Time-domain plot with:   - X-axis: Time (0-10 seconds)   - Y-axis: Amplitude (0-2)   - Blue dashed line: Reference input r(t) (step from 0 to 1 at t=1)   - Orange solid line: System output y(t)   - Shaded error region between reference and output - Block diagram schematic (small, at top) showing where gain K fits</p> <p>Interactive controls: - Slider: Controller gain K (range 0.5 to 10, default 2) - Slider: Plant time constant \u03c4 (range 0.5 to 3, default 1) - Button: \"Run Simulation\" - Button: \"Reset\" - Checkbox: \"Show error signal\" - Display: Final steady-state error value - Display: Approximate settling time</p> <p>Plant model: First-order system \\(G_p(s) = \\frac{1}{\\tau s + 1}\\) Controller: Proportional controller \\(G_c(s) = K\\) Closed-loop transfer function: \\(\\frac{K}{(\\tau s + 1) + K} = \\frac{K}{\\tau s + (1 + K)}\\)</p> <p>Default parameters: - K = 2 - \u03c4 = 1 second - Reference step magnitude = 1</p> <p>Behavior: - When \"Run Simulation\" clicked, animate the step response - Show how increasing K reduces steady-state error but may increase overshoot (for this first-order system, no overshoot, but faster response) - Display calculated steady-state error: \\(e_{ss} = \\frac{1}{1+K}\\) - Update settling time estimate as parameters change</p> <p>Data visibility requirements: - Show K value prominently - Show calculated closed-loop time constant: \\(\\tau_{CL} = \\frac{\\tau}{1+K}\\) - Show steady-state value: \\(y_{ss} = \\frac{K}{1+K}\\)</p> <p>Implementation: p5.js with canvas-based controls Canvas size: 700x400px, responsive width</p>"},{"location":"chapters/01-intro-to-control-systems/#disturbances","title":"Disturbances","text":"<p>A disturbance \\(d(t)\\) is any unwanted input that affects the system output without being commanded by the controller. In other words, disturbances are the universe's way of saying \"not so fast!\" to your carefully designed system. Disturbances represent the primary reason why feedback control is necessary\u2014if there were no disturbances and our plant model were perfect, open-loop control would suffice. But this is reality, and reality loves to throw curveballs.</p> <p>Disturbances can enter the system at various points:</p> <ul> <li>Load disturbances: External forces or demands acting on the plant</li> <li>Process disturbances: Internal variations in plant parameters</li> <li>Measurement noise: Corrupting the feedback signal</li> <li>Command disturbances: Errors in the reference input</li> </ul> <p>For the temperature control example, disturbances include:</p> <ul> <li>Opening a window (heat loss)</li> <li>Adding occupants to a room (heat gain)</li> <li>Changes in outdoor temperature</li> <li>Solar radiation through windows</li> </ul> <p>One of the key advantages of feedback control is disturbance rejection\u2014the ability to maintain the desired output despite disturbances. The feedback loop detects the effect of disturbances on the output and automatically adjusts the control action to compensate.</p>"},{"location":"chapters/01-intro-to-control-systems/#comparing-open-loop-and-closed-loop-systems","title":"Comparing Open-Loop and Closed-Loop Systems","text":"<p>The table below summarizes the key differences between open-loop and closed-loop control architectures:</p> Characteristic Open-Loop Control Closed-Loop Control Feedback None Output is measured and compared to reference Disturbance handling Cannot compensate Automatically rejects disturbances Accuracy Depends entirely on model accuracy Less sensitive to model errors Complexity Simpler More complex Cost Generally lower Generally higher Stability concerns Inherently stable if plant is stable Can become unstable if poorly designed Example Toaster, washing machine timer Thermostat, cruise control <p>The choice between open-loop and closed-loop control depends on the application requirements:</p> <ul> <li>Choose open-loop when the plant model is accurate, disturbances are minimal, precision requirements are modest, and cost is a primary constraint</li> <li>Choose closed-loop when high precision is required, significant disturbances are present, plant parameters vary, and the increased complexity is justified</li> </ul> <p>Most industrial and high-performance systems use closed-loop control because the benefits of disturbance rejection and robustness outweigh the added complexity. In the eternal battle between simplicity and capability, feedback usually wins\u2014it's worth the extra effort to have a system that actually knows what it's doing!</p>"},{"location":"chapters/01-intro-to-control-systems/#diagram-open-loop-vs-closed-loop-comparison","title":"Diagram: Open-Loop vs Closed-Loop Comparison","text":"Open-Loop vs Closed-Loop Comparison Simulator <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: compare, differentiate</p> <p>Learning Objective: Students will compare the behavior of open-loop and closed-loop systems when subjected to the same disturbance, analyzing why feedback provides superior disturbance rejection.</p> <p>Instructional Rationale: This Analyze-level objective requires students to observe both systems under identical conditions and identify the structural difference (feedback) that causes the performance difference. Side-by-side comparison enables direct differentiation.</p> <p>Canvas layout: - Top half: Two parallel system plots (Open-Loop left, Closed-Loop right) - Bottom: Shared control panel</p> <p>Visual elements for each system: - Time-domain plot showing output y(t) - Reference line at y = 1 (dashed blue) - Output trajectory (solid orange for open-loop, solid green for closed-loop) - Disturbance indicator showing when d(t) is applied</p> <p>Interactive controls: - Button: \"Apply Step Disturbance\" - adds disturbance at t = 3 seconds - Slider: Disturbance magnitude (range -0.5 to +0.5, default 0.3) - Button: \"Reset Both Systems\" - Slider: Controller gain K for closed-loop system (range 1 to 10, default 5)</p> <p>Plant model for both: \\(G_p(s) = \\frac{1}{s + 1}\\)</p> <p>Open-loop controller: Fixed gain \\(G_c = 1\\) (calibrated for unity output with no disturbance)</p> <p>Closed-loop controller: Proportional gain \\(G_c = K\\)</p> <p>Behavior: - Initially, both systems are at steady state with output \u2248 1 - When disturbance is applied, open-loop output shifts by the disturbance amount and stays there - Closed-loop output is deflected but recovers toward the reference - Show steady-state error for each system after disturbance</p> <p>Data visibility: - Steady-state error displayed numerically for each system - Percent reduction in error for closed-loop vs open-loop</p> <p>Implementation: p5.js with dual canvas regions Canvas size: 750x450px, responsive width</p>"},{"location":"chapters/01-intro-to-control-systems/#real-world-control-system-examples","title":"Real-World Control System Examples","text":"<p>Control systems appear in virtually every domain of engineering. Understanding these examples helps ground abstract concepts in practical applications.</p>"},{"location":"chapters/01-intro-to-control-systems/#automotive-cruise-control","title":"Automotive Cruise Control","text":"<p>Cruise control maintains vehicle speed at a driver-selected setpoint. The components map directly to our control system framework:</p> <ul> <li>Reference input: Desired speed set by driver</li> <li>Controller: Electronic control unit (ECU) implementing the control law</li> <li>Actuator: Throttle servo adjusting engine power</li> <li>Plant: Vehicle dynamics (engine, transmission, vehicle mass)</li> <li>Sensor: Wheel speed sensor or GPS-based speedometer</li> <li>Disturbances: Hills, wind, road surface changes</li> </ul> <p>When driving uphill, the vehicle tends to slow down. The feedback loop detects the speed reduction (error becomes positive) and commands more throttle to maintain the setpoint. It's like having a very attentive co-pilot who never gets tired, never gets distracted by good music, and definitely won't eat your road trip snacks.</p>"},{"location":"chapters/01-intro-to-control-systems/#hvac-temperature-control","title":"HVAC Temperature Control","text":"<p>Building climate control is a classic feedback control application:</p> <ul> <li>Reference input: Thermostat setpoint</li> <li>Controller: Thermostat logic (often with hysteresis or PID)</li> <li>Actuator: Furnace, air conditioner, or heat pump</li> <li>Plant: Building thermal dynamics</li> <li>Sensor: Temperature sensor</li> <li>Disturbances: Outdoor temperature, occupancy, solar gain, appliance heat</li> </ul> <p>The large thermal mass of buildings makes temperature dynamics relatively slow, with time constants measured in minutes to hours depending on construction. This explains why cranking the thermostat to 85\u00b0F won't heat your house any faster\u2014a fact that has sparked countless roommate arguments and family \"thermostat wars\" throughout history.</p>"},{"location":"chapters/01-intro-to-control-systems/#flight-control","title":"Flight Control","text":"<p>Aircraft autopilot systems control attitude, altitude, heading, and speed:</p> <ul> <li>Reference input: Commanded pitch angle, roll angle, or altitude</li> <li>Controller: Flight control computer</li> <li>Actuators: Hydraulic servos driving control surfaces (elevator, ailerons, rudder)</li> <li>Plant: Aircraft dynamics</li> <li>Sensors: Gyroscopes, accelerometers, air data sensors, GPS</li> <li>Disturbances: Wind gusts, turbulence, changes in aircraft weight</li> </ul> <p>Flight control systems often include multiple nested feedback loops\u2014inner loops for attitude stabilization and outer loops for navigation. It's loops within loops, like engineering Inception. And just like that movie, the deeper you go, the more interesting it gets!</p>"},{"location":"chapters/01-intro-to-control-systems/#summary-and-key-takeaways","title":"Summary and Key Takeaways","text":"<p>This chapter introduced the fundamental concepts of control systems that will be developed throughout this textbook.</p> <p>Key concepts:</p> <ul> <li>A control system is an interconnection of components designed to achieve a desired output behavior</li> <li>Open-loop control operates without feedback and cannot automatically compensate for disturbances</li> <li>Closed-loop control uses feedback to measure the output and adjust the control action accordingly</li> <li>The error signal is the difference between the reference input and the measured output</li> <li>Key components include the controller, actuator, plant, and sensor</li> <li>Disturbances are unwanted inputs that affect system output; feedback enables disturbance rejection</li> <li>The system response characterizes how the output behaves over time</li> </ul> <p>Looking Ahead</p> <p>Subsequent chapters will develop mathematical tools for modeling and analyzing control systems, including transfer functions, block diagrams, time-domain specifications, stability analysis, and controller design methods.</p>"},{"location":"chapters/01-intro-to-control-systems/#concept-verification-checklist","title":"Concept Verification Checklist","text":"<p>All 12 concepts from this chapter have been covered:</p> <ul> <li> Control System - Defined in opening section</li> <li> Feedback - Explained as the defining characteristic of closed-loop systems</li> <li> Open-Loop Control - Described with examples and limitations</li> <li> Closed-Loop Control - Explained with block diagram and signal flow</li> <li> Plant - Defined as the physical system being controlled</li> <li> Controller - Described as the component implementing the control strategy</li> <li> Actuator - Explained as the bridge between controller signals and physical action</li> <li> Sensor - Defined as the measurement device closing the feedback loop</li> <li> Reference Input - Described as the desired setpoint</li> <li> Error Signal - Defined mathematically and conceptually</li> <li> Disturbance - Explained with examples and relationship to feedback</li> <li> System Response - Defined and characterized</li> </ul>"},{"location":"chapters/02-dynamic-system-properties/","title":"Dynamic System Properties","text":""},{"location":"chapters/02-dynamic-system-properties/#summary","title":"Summary","text":"<p>This chapter establishes the essential mathematical properties that characterize dynamic systems suitable for control analysis. Students will learn the definitions of linearity, time-invariance, and the combined LTI (Linear Time-Invariant) property that underlies most classical control theory. The chapter also covers superposition, homogeneity, causality, and the role of differential equations in describing system dynamics. These properties form the foundation for all subsequent analysis techniques.</p>"},{"location":"chapters/02-dynamic-system-properties/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 8 concepts from the learning graph:</p> <ol> <li>Dynamic System</li> <li>Linear System</li> <li>Time-Invariant System</li> <li>LTI System</li> <li>Superposition Principle</li> <li>Homogeneity</li> <li>Causality</li> <li>Differential Equation</li> </ol>"},{"location":"chapters/02-dynamic-system-properties/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Introduction to Control Systems</li> </ul>"},{"location":"chapters/02-dynamic-system-properties/#the-quest-for-mathematical-tractability","title":"The Quest for Mathematical Tractability","text":"<p>In Chapter 1, we learned what control systems do\u2014they regulate, they stabilize, they make things behave. But now comes an important question: how do we actually analyze these systems mathematically? After all, control engineering would be a rather frustrating profession if we had to build every system first and then just hope it works!</p> <p>The good news is that most systems we care about share certain beautiful mathematical properties that make analysis not only possible but (dare we say it?) elegant. The bad news? These properties come with some Greek letters and formal definitions. But stick with us\u2014once you understand these concepts, they become powerful tools for predicting system behavior without ever touching a screwdriver.</p> <p>This chapter introduces the key properties that separate \"nice\" systems (ones we can analyze) from \"wild\" systems (ones that make mathematicians weep). By the end, you'll understand why the phrase \"LTI system\" makes control engineers smile with relief.</p>"},{"location":"chapters/02-dynamic-system-properties/#what-is-a-dynamic-system","title":"What Is a Dynamic System?","text":"<p>A dynamic system is any system whose output depends not only on the current input but also on the history of inputs and the system's internal state. In other words, dynamic systems have memory\u2014what happened in the past affects what happens now.</p> <p>Compare this to a simple resistor, where the current depends only on the voltage applied right now (Ohm's law: \\(I = V/R\\)). That's a static or memoryless system. But consider a capacitor: the voltage across it depends on how much charge has accumulated over time. The capacitor \"remembers\" all the current that has flowed through it. That's dynamic behavior!</p> System Type Memory Example Static None Resistor, lever, gear ratio Dynamic Has memory Capacitor, mass on spring, thermal system <p>Dynamic systems are described by differential equations because these equations capture how quantities change over time. The relationship between input and output involves derivatives\u2014rates of change\u2014rather than just instantaneous values.</p> <p>Why Dynamic Systems Matter</p> <p>Almost every interesting physical system is dynamic. Motors don't instantly reach their commanded speed. Ovens don't instantly reach their set temperature. Aircraft don't instantly change altitude. Understanding dynamic behavior is essential for designing controllers that work in the real world, where everything takes time.</p>"},{"location":"chapters/02-dynamic-system-properties/#differential-equations-the-language-of-dynamics","title":"Differential Equations: The Language of Dynamics","text":"<p>Differential equations are the mathematical language we use to describe dynamic systems. They relate the input, output, and their various derivatives (rates of change) to each other.</p> <p>For a simple RC circuit, the relationship between input voltage \\(v_{in}(t)\\) and output voltage \\(v_{out}(t)\\) across the capacitor is:</p> \\[RC\\frac{dv_{out}}{dt} + v_{out} = v_{in}\\] <p>This is a first-order ordinary differential equation (ODE). The \"order\" refers to the highest derivative present\u2014in this case, the first derivative \\(dv_{out}/dt\\).</p> <p>For a mass-spring-damper system with mass \\(m\\), damping coefficient \\(b\\), and spring constant \\(k\\):</p> \\[m\\frac{d^2y}{dt^2} + b\\frac{dy}{dt} + ky = F(t)\\] <p>This is a second-order ODE because it contains a second derivative \\(d^2y/dt^2\\).</p> <p>The order of the differential equation tells us something important about the system's complexity:</p> <ul> <li>First-order systems: One energy storage element (like a capacitor or thermal mass)</li> <li>Second-order systems: Two energy storage elements (like an RLC circuit or mass-spring-damper)</li> <li>Higher-order systems: Three or more energy storage elements</li> </ul> <p>Think of differential equations as the system's \"rulebook\"\u2014they encode how the system evolves over time. If you know the differential equation and the initial conditions, you can (in principle) predict the output for any input. That's powerful stuff! It's like having a crystal ball, except this one runs on calculus.</p>"},{"location":"chapters/02-dynamic-system-properties/#diagram-differential-equation-forms","title":"Diagram: Differential Equation Forms","text":"Differential Equation Forms <p>Type: infographic</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: classify, compare</p> <p>Learning Objective: Students will classify differential equations by their order and identify corresponding physical systems.</p> <p>Layout: Three columns showing first-order, second-order, and general nth-order forms</p> <p>Column 1 - First-Order: - General form: \\(a_1\\frac{dy}{dt} + a_0 y = b_0 u\\) - Physical examples: RC circuit, thermal system, fluid tank - Schematic: Simple RC circuit diagram - Key feature: \"One energy storage element\"</p> <p>Column 2 - Second-Order: - General form: \\(a_2\\frac{d^2y}{dt^2} + a_1\\frac{dy}{dt} + a_0 y = b_0 u\\) - Physical examples: RLC circuit, mass-spring-damper - Schematic: Mass-spring-damper diagram - Key feature: \"Two energy storage elements\"</p> <p>Column 3 - Higher-Order: - General form: \\(\\sum_{k=0}^{n} a_k\\frac{d^k y}{dt^k} = \\sum_{j=0}^{m} b_j\\frac{d^j u}{dt^j}\\) - Physical examples: Cascaded systems, complex mechanisms - Schematic: Cascaded tanks diagram - Key feature: \"n energy storage elements\"</p> <p>Interactive elements: - Hover over each schematic to see the corresponding differential equation - Click to reveal example numerical values</p> <p>Visual style: Clean mathematical notation with corresponding circuit/mechanical diagrams Color coding: Blue for first-order, green for second-order, orange for higher-order</p> <p>Instructional Rationale: Side-by-side comparison helps students see the pattern as order increases and connect abstract equations to physical systems.</p> <p>Implementation: HTML/CSS/JavaScript with MathJax for equations</p>"},{"location":"chapters/02-dynamic-system-properties/#linear-systems-the-gift-that-keeps-on-giving","title":"Linear Systems: The Gift That Keeps on Giving","text":"<p>A linear system is one that satisfies two fundamental properties: additivity and homogeneity. Together, these properties enable the powerful superposition principle, which is arguably the most useful concept in all of control systems analysis.</p> <p>Before diving into the formal definitions, here's the intuitive version: in a linear system, effects add up in a predictable, proportional way. Double the input, double the output. Add two inputs together, get the sum of their individual outputs. No surprises, no weird interactions, no chaos. Linear systems are the \"well-behaved children\" of the mathematical world\u2014they do what you expect!</p>"},{"location":"chapters/02-dynamic-system-properties/#homogeneity-scaling-property","title":"Homogeneity (Scaling Property)","text":"<p>Homogeneity means that if you scale the input by a constant factor, the output scales by the same factor. Mathematically, if input \\(u(t)\\) produces output \\(y(t)\\), then input \\(\\alpha u(t)\\) produces output \\(\\alpha y(t)\\) for any constant \\(\\alpha\\).</p> \\[\\text{If } u(t) \\rightarrow y(t), \\text{ then } \\alpha u(t) \\rightarrow \\alpha y(t)\\] <p>In plain English: if you push twice as hard, you get twice the response. If you apply half the voltage, you get half the current (in a linear resistor). This is incredibly useful because it means we can analyze a system's response to a \"unit\" input and then scale the result for any input magnitude.</p> <p>Real-world example: An ideal amplifier with gain \\(K\\) satisfies homogeneity\u2014input 1 volt, get \\(K\\) volts out; input 2 volts, get \\(2K\\) volts out. But a real amplifier eventually saturates (clips), violating homogeneity. When you crank your guitar amp to 11, the output doesn't scale linearly anymore\u2014you get that glorious distortion. Great for rock music, terrible for control systems!</p>"},{"location":"chapters/02-dynamic-system-properties/#additivity-superposition-of-inputs","title":"Additivity (Superposition of Inputs)","text":"<p>Additivity means that the response to a sum of inputs equals the sum of the individual responses. If input \\(u_1(t)\\) produces output \\(y_1(t)\\) and input \\(u_2(t)\\) produces output \\(y_2(t)\\), then input \\(u_1(t) + u_2(t)\\) produces output \\(y_1(t) + y_2(t)\\).</p> \\[\\text{If } u_1(t) \\rightarrow y_1(t) \\text{ and } u_2(t) \\rightarrow y_2(t), \\text{ then } u_1(t) + u_2(t) \\rightarrow y_1(t) + y_2(t)\\] <p>This means effects don't interfere with each other in unexpected ways. You can analyze each input separately and then add up the results. Divide and conquer!</p>"},{"location":"chapters/02-dynamic-system-properties/#the-superposition-principle","title":"The Superposition Principle","text":"<p>The superposition principle combines homogeneity and additivity into one powerful statement: for a linear system, the response to any linear combination of inputs equals the same linear combination of the individual responses.</p> \\[\\alpha_1 u_1(t) + \\alpha_2 u_2(t) \\rightarrow \\alpha_1 y_1(t) + \\alpha_2 y_2(t)\\] <p>Why is superposition such a big deal? Because it lets us break complex problems into simpler pieces:</p> <ul> <li>Analyze the response to simple inputs (steps, impulses, sinusoids)</li> <li>Build up the response to complex inputs by adding these simple responses</li> <li>Study forced and natural responses separately, then combine them</li> <li>Decompose any input into a sum of simpler components</li> </ul> <p>Without superposition, we'd have to analyze every possible input scenario individually. With superposition, we can study a system's response to a few canonical inputs and understand its behavior under any input. It's like getting the answer key to an infinite number of problems by solving just a few!</p>"},{"location":"chapters/02-dynamic-system-properties/#diagram-superposition-principle-visualizer","title":"Diagram: Superposition Principle Visualizer","text":"Superposition Principle Visualizer <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: demonstrate, apply</p> <p>Learning Objective: Students will demonstrate the superposition principle by observing how the response to combined inputs equals the sum of individual responses.</p> <p>Canvas layout: - Top section (60%): Three time-response plots stacked vertically   - Plot 1: Input u\u2081(t) and its response y\u2081(t)   - Plot 2: Input u\u2082(t) and its response y\u2082(t)   - Plot 3: Combined input u\u2081+u\u2082 and combined response y\u2081+y\u2082 - Bottom section (40%): Controls and equations display</p> <p>Visual elements: - Each plot shows input (dashed line) and output (solid line) - Plot 3 shows superposition equation: y\u2081(t) + y\u2082(t) = y_total(t) - Color coding: Input 1 in blue, Input 2 in green, Combined in purple - Animated drawing of responses when simulation runs</p> <p>Interactive controls: - Dropdown: Input 1 type (step, ramp, pulse) - Slider: Input 1 magnitude \u03b1\u2081 (-2 to 2, default 1) - Dropdown: Input 2 type (step, ramp, pulse) - Slider: Input 2 magnitude \u03b1\u2082 (-2 to 2, default 0.5) - Slider: System time constant \u03c4 (0.5 to 3, default 1) - Button: \"Run Simulation\" - Button: \"Reset\" - Toggle: \"Show component responses on Plot 3\" (overlay individual y\u2081, y\u2082 on combined plot)</p> <p>System model: First-order system G(s) = 1/(\u03c4s + 1)</p> <p>Data Visibility Requirements: - Display \u03b1\u2081, \u03b1\u2082, and \u03c4 values - Show mathematical statement: \u03b1\u2081u\u2081 + \u03b1\u2082u\u2082 \u2192 \u03b1\u2081y\u2081 + \u03b1\u2082y\u2082 - When toggle is on, show how y\u2081 and y\u2082 \"stack up\" to form y_total</p> <p>Behavior: - Plots update in real-time as sliders change - \"Run Simulation\" animates the responses over time - When inputs are combined, visually show the addition of responses - Demonstrate that scaling inputs scales outputs proportionally</p> <p>Instructional Rationale: Interactive visualization makes the abstract superposition principle concrete. Students can experiment with different input combinations and magnitudes to verify that superposition holds.</p> <p>Implementation: p5.js with canvas-based controls and multi-plot display</p>"},{"location":"chapters/02-dynamic-system-properties/#testing-for-linearity","title":"Testing for Linearity","text":"<p>How do you determine whether a system is linear? The formal test involves checking both homogeneity and additivity. However, there's a practical shortcut for systems described by differential equations.</p> <p>A system is linear if its governing differential equation has the form:</p> \\[a_n\\frac{d^n y}{dt^n} + a_{n-1}\\frac{d^{n-1} y}{dt^{n-1}} + \\cdots + a_1\\frac{dy}{dt} + a_0 y = b_m\\frac{d^m u}{dt^m} + \\cdots + b_1\\frac{du}{dt} + b_0 u\\] <p>where the coefficients \\(a_i\\) and \\(b_j\\) depend only on time (or are constants), NOT on \\(y\\), \\(u\\), or their derivatives.</p> <p>Red flags for nonlinearity:</p> Nonlinear Feature Example Why It's Nonlinear Products of variables \\(y \\cdot \\frac{dy}{dt}\\) Output appears multiplicatively Powers other than 1 \\(y^2\\), \\(\\sqrt{y}\\) Scaling doesn't preserve the power Transcendental functions \\(\\sin(y)\\), \\(e^y\\) These don't scale linearly Variable coefficients depending on output \\((1+y)\\frac{dy}{dt}\\) Coefficient changes with output <p>Most Real Systems Are Nonlinear</p> <p>Here's a humbling truth: strictly speaking, almost every real physical system is nonlinear! Springs become nonlinear at large deflections. Amplifiers saturate. Friction is often nonlinear. So why do we obsess over linear systems? Because many systems behave approximately linear over a limited operating range\u2014and that approximation unlocks an entire universe of powerful analysis tools. It's like how we use flat-Earth approximations for local navigation\u2014technically wrong, but practically useful!</p> <p>Helping Gyra</p> <p>Gyra knows all about nonlinearity. When she's nearly upright, small corrections work beautifully\u2014double the tilt error, double the motor response. But when she's falling over badly? Her motors hit their limits and saturate. She's giving everything she's got, but it's not twice as much as before\u2014it's just... everything. This is why we try to keep Gyra in her \"linear zone\" where corrections are proportional. Once she leaves that zone, our nice LTI analysis goes out the window and things get unpredictable fast.</p>"},{"location":"chapters/02-dynamic-system-properties/#time-invariant-systems-the-same-today-as-tomorrow","title":"Time-Invariant Systems: The Same Today as Tomorrow","text":"<p>A time-invariant system (also called a shift-invariant system) is one whose behavior doesn't change over time. If you apply the same input today, tomorrow, or next year, you get the same output (shifted in time accordingly).</p> <p>Mathematically, if input \\(u(t)\\) produces output \\(y(t)\\), then the delayed input \\(u(t - T)\\) produces the delayed output \\(y(t - T)\\) for any time shift \\(T\\).</p> \\[\\text{If } u(t) \\rightarrow y(t), \\text{ then } u(t-T) \\rightarrow y(t-T)\\] <p>In plain English: the system doesn't \"know\" what time it is. It doesn't behave differently on Tuesdays or during leap years. It responds to inputs based purely on their shape, not when they occur.</p> <p>Examples of time-invariant systems:</p> <ul> <li>A resistor (Ohm's law doesn't change with the calendar)</li> <li>An ideal mass-spring-damper (assuming the spring doesn't fatigue)</li> <li>A well-maintained motor (before bearings wear out)</li> </ul> <p>Examples of time-varying systems:</p> <ul> <li>A rocket (mass decreases as fuel burns)</li> <li>A system with scheduled parameter changes</li> <li>An aging component (characteristics drift over time)</li> <li>A satellite's control system as it orbits (gravitational field changes)</li> </ul> <p>Time-invariance is crucial for analysis because it means we can characterize a system with a single set of equations that apply for all time. If the system were time-varying, we'd need different equations for different moments\u2014a much harder problem!</p>"},{"location":"chapters/02-dynamic-system-properties/#diagram-time-invariance-test","title":"Diagram: Time Invariance Test","text":"Time Invariance Test <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: compare, differentiate</p> <p>Learning Objective: Students will differentiate between time-invariant and time-varying systems by comparing responses to time-shifted inputs.</p> <p>Canvas layout: - Left (50%): Two overlapping plots showing original and shifted responses - Right (50%): Control panel and explanation</p> <p>Visual elements: - Plot showing u(t) and y(t) in solid lines (original input-output pair) - Plot showing u(t-T) and y(t-T) in dashed lines (shifted pair) - Overlay to compare if shifted input produces shifted output - Vertical markers showing the time shift T - \"Time Invariant: YES/NO\" indicator based on comparison</p> <p>Interactive controls: - Dropdown: System type (time-invariant first-order, time-varying example) - Slider: Time shift T (0 to 3 seconds, default 1) - Slider: System parameter (time constant for time-invariant, or varying parameter for time-varying example) - Button: \"Apply Shift and Compare\" - Button: \"Reset\"</p> <p>Time-invariant system: G(s) = 1/(\u03c4s + 1) with constant \u03c4 Time-varying example: System with \u03c4(t) = \u03c4\u2080(1 + 0.2t), where time constant increases over time</p> <p>Data Visibility Requirements: - Show the original input u(t) and output y(t) - Show shifted input u(t-T) and the actual response (not necessarily y(t-T)) - Display whether y(t-T) matches the actual response to u(t-T) - For time-varying system, show how the response shape changes</p> <p>Behavior: - For time-invariant system: shifted input produces exactly shifted output - For time-varying system: shifted input produces different shape output - Visual highlight when responses don't match (indicating time-varying behavior)</p> <p>Instructional Rationale: Side-by-side comparison of shifted signals makes the abstract time-invariance property visually concrete. Seeing a time-varying system violate the property reinforces understanding.</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/02-dynamic-system-properties/#the-holy-grail-lti-systems","title":"The Holy Grail: LTI Systems","text":"<p>An LTI system (Linear Time-Invariant system) is one that satisfies both linearity and time-invariance. This combination is the foundation of classical control theory and the reason we can do so much powerful analysis.</p> <p>LTI systems are special because:</p> <ol> <li>Superposition applies: We can decompose complex inputs and add up the responses</li> <li>Time-shift invariance applies: The system behaves consistently regardless of when we observe it</li> <li>Transfer functions exist: We can characterize the entire system with a single rational function of \\(s\\)</li> <li>Convolution works: Output is the convolution of input with the impulse response</li> <li>Frequency response is meaningful: Sinusoids in \u2192 sinusoids out (same frequency, different amplitude and phase)</li> </ol> <p>Think of LTI systems as the \"sweet spot\" of control engineering. They're complex enough to model real dynamic behavior, but structured enough to permit elegant mathematical analysis. When control engineers see \"LTI,\" they breathe a sigh of relief\u2014the full toolkit is available!</p> Property What It Means What It Enables Linear Effects add proportionally Superposition, decomposition Time-Invariant Behavior is constant over time Single transfer function, consistent analysis LTI (Both) Best of both worlds Transfer functions, Bode plots, root locus, all classical methods <p>The LTI Assumption</p> <p>Throughout most of this textbook, we assume systems are LTI. This isn't because real systems are perfectly LTI\u2014they're not! It's because the LTI assumption provides such powerful analytical tools that engineers find it worthwhile to linearize around operating points and treat systems as approximately LTI. When in doubt, verify the assumption experimentally!</p> <p>Helping Gyra</p> <p>Good news: Gyra is (approximately) an LTI system! Her dynamics don't change whether it's Tuesday or Saturday, and small tilts produce proportionally small motor corrections. This means all the powerful tools we're developing\u2014transfer functions, frequency response, stability analysis\u2014apply directly to helping her stay upright. Of course, if you push her too hard, her motors saturate and linearity breaks down. But within her normal operating range? LTI all the way. That's why we can actually design her controller mathematically instead of just guessing.</p>"},{"location":"chapters/02-dynamic-system-properties/#causality-no-crystal-balls-allowed","title":"Causality: No Crystal Balls Allowed","text":"<p>A causal system (also called a non-anticipatory or physical system) is one whose output at any time depends only on current and past inputs, never on future inputs.</p> \\[y(t) \\text{ depends only on } u(\\tau) \\text{ for } \\tau \\leq t\\] <p>This might seem obvious\u2014of course a physical system can't respond to an input before the input happens! That would require time travel, and last we checked, physics still frowns upon that.</p> <p>However, causality becomes important when we're doing mathematical analysis. Some perfectly valid mathematical operations can produce non-causal results. For example:</p> <ul> <li>The inverse of a system might be non-causal</li> <li>Certain ideal filters are non-causal</li> <li>Optimization over entire time signals can yield non-causal controllers</li> </ul> <p>Causality is a physical constraint that all implementable control systems must satisfy. A controller that needs tomorrow's error signal to compute today's control action isn't going to work in practice\u2014no matter how good its transfer function looks on paper!</p> <p>Why causality matters in control:</p> <ul> <li>Realizability: Only causal systems can be built and operated in real time</li> <li>Stability analysis: Causality affects the conditions for stable behavior</li> <li>Implementation: Digital controllers must be causal to run in real time</li> </ul> <p>Causal vs. Non-Causal</p> <p>In theoretical analysis, non-causal systems sometimes appear as mathematical constructs. They're useful for understanding limits of performance or as stepping stones in derivations. But when it's time to build something, causality is non-negotiable. The future is, inconveniently, still unknown.</p>"},{"location":"chapters/02-dynamic-system-properties/#diagram-causality-concept-illustration","title":"Diagram: Causality Concept Illustration","text":"Causality Concept Illustration <p>Type: infographic</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: explain, interpret</p> <p>Learning Objective: Students will explain the concept of causality by visualizing how a causal system's output depends only on past and present inputs.</p> <p>Layout: Timeline visualization with input and output signals</p> <p>Visual elements: - Horizontal timeline with \"Past,\" \"Present (t),\" and \"Future\" regions - Input signal u(\u03c4) shown as a waveform across the timeline - Output y(t) shown at the present moment - Shaded region showing \"inputs that affect y(t)\" (past and present only) - Crossed-out \"forbidden\" region showing future inputs that cannot affect y(t) - \"Crystal ball\" icon with X through it for humor</p> <p>Two scenarios: 1. Causal system: Output arrow points only to past/present input region 2. Non-causal (hypothetical): Output arrow also points to future (marked as \"impossible in real systems\")</p> <p>Interactive elements: - Slider: Move the \"present\" moment along the timeline - The \"affects output\" region updates to show causality - Hover over regions for explanation text</p> <p>Color scheme: - Past: Blue (accessible) - Present: Green (current) - Future: Gray with red X (inaccessible)</p> <p>Instructional Rationale: Visual timeline makes the abstract causality concept intuitive. The \"forbidden future\" visualization emphasizes that physical systems cannot peek ahead in time.</p> <p>Implementation: HTML/CSS/JavaScript with SVG timeline</p>"},{"location":"chapters/02-dynamic-system-properties/#connecting-the-concepts","title":"Connecting the Concepts","text":"<p>The properties we've covered\u2014dynamic behavior, linearity, time-invariance, causality\u2014work together to define the class of systems that classical control theory handles best.</p> <p>Here's how they fit together:</p> <pre><code>Dynamic System\n    \u2502\n    \u251c\u2500\u2500 Linear?\n    \u2502     \u2502\n    \u2502     \u251c\u2500\u2500 Yes: Superposition applies\n    \u2502     \u2502     \u2502\n    \u2502     \u2502     \u2514\u2500\u2500 Time-Invariant?\n    \u2502     \u2502           \u2502\n    \u2502     \u2502           \u251c\u2500\u2500 Yes: LTI System! \ud83c\udf89\n    \u2502     \u2502           \u2502     (Transfer functions, Bode plots, all the good stuff)\n    \u2502     \u2502           \u2502\n    \u2502     \u2502           \u2514\u2500\u2500 No: Linear Time-Varying (LTV)\n    \u2502     \u2502                 (Still useful, but more complex analysis)\n    \u2502     \u2502\n    \u2502     \u2514\u2500\u2500 No: Nonlinear System\n    \u2502           (Linearize around operating point, or use advanced methods)\n    \u2502\n    \u2514\u2500\u2500 Causal?\n          \u2502\n          \u251c\u2500\u2500 Yes: Physically realizable\n          \u2502\n          \u2514\u2500\u2500 No: Mathematical abstraction only\n</code></pre> <p>The ideal scenario for control analysis is an LTI causal system described by a known differential equation. This is the setting where transfer functions, Bode plots, root locus, and all the classical techniques apply directly.</p>"},{"location":"chapters/02-dynamic-system-properties/#diagram-system-properties-classification","title":"Diagram: System Properties Classification","text":"System Properties Classification <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: classify, organize</p> <p>Learning Objective: Students will classify systems by their properties (linear/nonlinear, time-invariant/time-varying, causal/non-causal) using a decision tree interface.</p> <p>Canvas layout: - Left (60%): Interactive decision tree diagram - Right (40%): Example system input and classification result</p> <p>Visual elements: - Decision tree with nodes for each property test - Current path highlighted as user clicks through - Final classification box showing system type and available analysis tools - Examples panel showing a specific system and its classification</p> <p>Interactive controls: - Dropdown: Select example system (RC circuit, saturating amplifier, aging battery, etc.) - Click on decision tree nodes to navigate classification - Each terminal node shows: system type, applicable analysis tools, limitations</p> <p>Example systems: 1. RC circuit (\u03c4 constant) \u2192 LTI causal 2. Amplifier with saturation \u2192 Nonlinear, time-invariant, causal 3. Rocket (decreasing mass) \u2192 Linear but time-varying, causal 4. Ideal filter (sin(x)/x impulse response) \u2192 LTI but non-causal</p> <p>Data Visibility Requirements: - Show the governing equation for each example - Highlight which property tests pass/fail - Display final classification prominently</p> <p>Behavior: - Selecting an example pre-populates the decision path - Users can also manually navigate the tree - Tooltips explain each property test</p> <p>Instructional Rationale: Decision tree format organizes the classification process systematically. Working through examples reinforces understanding of each property.</p> <p>Implementation: p5.js or vis-network for interactive tree</p>"},{"location":"chapters/02-dynamic-system-properties/#why-these-properties-matter-for-control-design","title":"Why These Properties Matter for Control Design","text":"<p>Understanding system properties isn't just academic\u2014it directly impacts how you approach control design:</p> <p>For LTI systems:</p> <ul> <li>Use transfer functions and block diagram algebra</li> <li>Apply frequency-domain design (Bode, Nyquist)</li> <li>Use root locus for gain selection</li> <li>Design PID controllers with standard tuning rules</li> <li>Predict closed-loop behavior analytically</li> </ul> <p>For nonlinear systems:</p> <ul> <li>Linearize around operating points</li> <li>Use describing functions (advanced)</li> <li>Apply nonlinear control techniques (beyond this course)</li> <li>Rely more heavily on simulation</li> </ul> <p>For time-varying systems:</p> <ul> <li>Parameters may need adaptive adjustment</li> <li>Gain scheduling may be required</li> <li>Analysis is more complex (often numerical)</li> </ul> <p>For all real systems:</p> <ul> <li>Verify the LTI assumption is reasonable</li> <li>Check that the operating range supports linear approximation</li> <li>Validate models against experimental data</li> <li>Be prepared for real-world nonlinearities and variations</li> </ul>"},{"location":"chapters/02-dynamic-system-properties/#key-takeaways","title":"Key Takeaways","text":"<p>This chapter established the mathematical foundation for control systems analysis:</p> <ul> <li> <p>Dynamic systems have memory\u2014their outputs depend on input history, captured by differential equations</p> </li> <li> <p>Differential equations are the mathematical language of dynamics, relating inputs, outputs, and their rates of change</p> </li> <li> <p>Linear systems satisfy homogeneity (scaling) and additivity, enabling the powerful superposition principle</p> </li> <li> <p>Time-invariant systems behave the same regardless of when you observe them\u2014the system doesn't \"know\" what time it is</p> </li> <li> <p>LTI systems (Linear Time-Invariant) combine both properties and form the foundation of classical control theory\u2014when you see \"LTI,\" celebrate!</p> </li> <li> <p>Causality ensures the system can't respond to future inputs\u2014no time machines allowed in real control systems</p> </li> <li> <p>Most real systems are approximately LTI within some operating range, which is why we study LTI theory so extensively\u2014it's not perfect, but it's remarkably useful</p> </li> </ul> <p>These properties determine which analysis tools apply to a given system. The LTI assumption, in particular, unlocks the entire toolkit of transfer functions, frequency response, and root locus that we'll develop in subsequent chapters.</p> Self-Check: Can You Answer These? <ol> <li>What two properties must a system satisfy to be classified as linear?</li> <li>If a system's output at time \\(t\\) depends on the input at time \\(t+1\\), is the system causal?</li> <li>A motor's resistance increases as it heats up during operation. Is this system time-invariant?</li> <li>Why is the superposition principle so valuable for analyzing complex inputs?</li> <li>You discover that doubling the input to your system more than doubles the output. Is the system linear?</li> </ol>"},{"location":"chapters/03-time-domain-response/","title":"Time-Domain Response Fundamentals","text":""},{"location":"chapters/03-time-domain-response/#summary","title":"Summary","text":"<p>This chapter is all about watching systems evolve over time\u2014the drama, the oscillations, and the eventual calm. You'll learn to distinguish between natural and forced responses, transient and steady-state behavior, and the personalities of first-order and second-order systems. We'll introduce the key parameters that control engineers obsess over: time constant, damping ratio, and natural frequency. By the end, you'll be able to look at a system and predict whether it'll be smooth and boring, or oscillate like it's had too much coffee. These concepts are essential for predicting and specifying system performance\u2014and for impressing your colleagues at technical meetings.</p>"},{"location":"chapters/03-time-domain-response/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 20 concepts from the learning graph:</p> <ol> <li>First-Order System</li> <li>Second-Order System</li> <li>Higher-Order System</li> <li>Order of a System</li> <li>Initial Conditions</li> <li>Natural Response</li> <li>Forced Response</li> <li>Total Response</li> <li>Zero-Input Response</li> <li>Zero-State Response</li> <li>Transient Response</li> <li>Steady-State Response</li> <li>Time Constant</li> <li>Damping Ratio</li> <li>Natural Frequency</li> <li>Damped Frequency</li> <li>Undamped System</li> <li>Underdamped System</li> <li>Critically Damped System</li> <li>Overdamped System</li> </ol>"},{"location":"chapters/03-time-domain-response/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Introduction to Control Systems</li> <li>Chapter 2: Dynamic System Properties</li> </ul>"},{"location":"chapters/03-time-domain-response/#understanding-system-responses-in-time","title":"Understanding System Responses in Time","text":"<p>Flick a light switch and the light appears to turn on instantly. Step on your car's accelerator, though, and you won't teleport to highway speed\u2014you'll accelerate gradually until you settle at the velocity you wanted. This difference in behavior is the essence of time-domain response: how systems evolve from one state to another as the clock ticks.</p> <p>Here's the thing: every dynamic system takes time to respond to changes. Whether you're designing a temperature controller for a chemical reactor or tuning the suspension on a race car (or just wondering why your shower takes forever to get hot), understanding how fast and in what manner a system responds is crucial. Will it be smooth and graceful, or will it oscillate like a caffeinated hummingbird before settling down? These are the questions that keep control engineers employed\u2014and that we'll tackle in this chapter.</p> <p>The time-domain perspective gives us something precious: an intuitive, physical understanding of system behavior. Unlike frequency-domain methods (patience\u2014we'll get there), time-domain analysis lets us directly watch what happens to a system's output as the seconds tick by. It's like having a front-row seat to the drama of transient phenomena. And when your boss asks \"how long until this thing settles down?\"\u2014you'll have an answer.</p>"},{"location":"chapters/03-time-domain-response/#the-order-of-a-system","title":"The Order of a System","text":"<p>The order of a system is one of the most fundamental classifications in control theory\u2014think of it as the system's \"complexity rating.\" It tells us how intricate the dynamics will be and is determined by the highest power of the differentiation operator (or equivalently, the highest power of \\(s\\) in the denominator of the transfer function).</p> <p>Here's the beautiful part: a system's order corresponds to three equivalent things:</p> <ul> <li>The number of independent energy storage elements</li> <li>The highest derivative in the governing differential equation</li> <li>The number of initial conditions needed to specify the system's state</li> </ul> System Order Energy Storage Elements Example First-order 1 (capacitor OR inductor) RC circuit, thermal mass Second-order 2 (capacitor AND inductor) RLC circuit, mass-spring-damper Higher-order 3 or more Complex mechanical systems <p>Understanding system order helps you predict response complexity: first-order systems exhibit simple exponential behavior (the reliable workhorse), while second-order systems can oscillate (the dramatic performer). Higher-order systems (order 3 and above) exhibit increasingly complex dynamics\u2014but here's the good news: they can often be approximated by lower-order models for design purposes. Nature may be complex, but we engineers are clever simplifiers.</p>"},{"location":"chapters/03-time-domain-response/#diagram-system-order-classification","title":"Diagram: System Order Classification","text":"System Order Classification <p>Type: infographic</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: classify, identify</p> <p>Learning Objective: Students will classify systems by their order based on the number of energy storage elements and understand the implications for response complexity.</p> <p>Layout: Three columns showing first-order, second-order, and higher-order systems</p> <p>Column 1 - First-Order: - Schematic: RC circuit with single capacitor - Differential equation: \\(\\tau \\frac{dy}{dt} + y = Ku\\) - Response sketch: Simple exponential curve - Characteristic: \"Single energy storage element\"</p> <p>Column 2 - Second-Order: - Schematic: Mass-spring-damper system - Differential equation: \\(m\\frac{d^2y}{dt^2} + b\\frac{dy}{dt} + ky = F\\) - Response sketch: Oscillatory decay curve - Characteristic: \"Two energy storage elements\"</p> <p>Column 3 - Higher-Order: - Schematic: Cascaded tanks or multi-mass system - Note: \"Order \u2265 3\" - Response sketch: Complex multi-mode response - Characteristic: \"Three or more storage elements\"</p> <p>Interactive elements: - Hover over each schematic to see physical interpretation - Click to reveal example transfer functions</p> <p>Visual style: Clean engineering diagrams with equations, color-coded by order (blue for 1st, green for 2nd, orange for higher)</p> <p>Instructional Rationale: Classification infographic helps students build mental categories for system types before diving into detailed analysis.</p> <p>Implementation: HTML/CSS/JavaScript with SVG schematics</p>"},{"location":"chapters/03-time-domain-response/#initial-conditions-where-the-story-begins","title":"Initial Conditions: Where the Story Begins","text":"<p>Initial conditions describe the state of a system at time \\(t = 0\\)\u2014the instant before we apply an input or begin our analysis. For a capacitor, this is the initial voltage; for a mass in motion, it's the initial position and velocity. Think of initial conditions as the system's \"backstory\"\u2014the history encoded in its energy storage elements.</p> <p>Why do initial conditions matter? Consider approaching a traffic light in your car. Whether you're cruising at 30 mph or racing at 60 mph when the light turns red completely changes how hard you must brake and how long it takes to stop. The initial velocity is an initial condition, and it profoundly affects everything that follows. (Also, maybe slow down a bit.)</p> <p>For an \\(n\\)th-order system, we need \\(n\\) initial conditions to uniquely determine the solution:</p> <ul> <li>First-order systems: 1 initial condition (e.g., \\(y(0)\\))</li> <li>Second-order systems: 2 initial conditions (e.g., \\(y(0)\\) and \\(\\dot{y}(0)\\))</li> <li>\\(n\\)th-order systems: \\(n\\) initial conditions</li> </ul> <p>Engineering Intuition</p> <p>Initial conditions represent energy already stored in the system. A charged capacitor, a compressed spring, or a moving mass all carry energy that will influence how the system responds\u2014even with no external input. The system doesn't care whether you're paying attention; it's going to release that energy regardless.</p>"},{"location":"chapters/03-time-domain-response/#natural-response-and-forced-response","title":"Natural Response and Forced Response","text":"<p>Here's where things get interesting. A system's total behavior can be decomposed into two distinct components: the natural response and the forced response. This decomposition is one of our most powerful analytical superpowers\u2014divide and conquer at its finest.</p> <p>The natural response (also called the homogeneous response) is how the system behaves due solely to its initial conditions, with no external input applied. Imagine pushing a child on a swing and then letting go\u2014the swing continues to oscillate, gradually losing amplitude until it stops. That decaying oscillation is a natural response, arising purely from the initial energy you imparted. You've stopped participating, but the system hasn't stopped performing.</p> <p>The forced response (also called the particular response) is how the system reacts to external inputs, assuming zero initial conditions. If you rhythmically push the swing in time with its natural period, the resulting motion is the forced response to your periodic input. Now you're driving the show.</p> Response Type Caused By Physical Meaning Natural Response Initial conditions Release of stored energy Forced Response External input System tracking the input Total Response Both combined What actually happens <p>The total response is simply the sum of these two components\u2014a direct consequence of the superposition principle for linear systems:</p> \\[y(t) = y_{\\text{natural}}(t) + y_{\\text{forced}}(t)\\]"},{"location":"chapters/03-time-domain-response/#diagram-natural-vs-forced-response-decomposition","title":"Diagram: Natural vs. Forced Response Decomposition","text":"Natural vs. Forced Response Decomposition <p>Type: microsim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: explain, interpret</p> <p>Learning Objective: Students will explain how total response combines natural and forced components by observing concrete examples with adjustable parameters.</p> <p>Canvas layout: - Top section (60%): Three stacked time-response plots - Bottom section (40%): Controls and parameter display</p> <p>Visual elements: - Plot 1: Natural response (blue curve) with label \"Natural Response (from initial conditions)\" - Plot 2: Forced response (green curve) with label \"Forced Response (from input)\" - Plot 3: Total response (red/magenta curve) with label \"Total Response = Natural + Forced\" - Vertical dashed line at t=0 - Grid lines for reference - Axis labels with units</p> <p>Interactive controls: - Slider: Initial condition y(0) from -2 to 2 (default: 1) - Slider: Initial velocity dy/dt(0) from -5 to 5 (default: 0) - Slider: Step input amplitude from 0 to 2 (default: 1) - Dropdown: System type (first-order, underdamped second-order) - Button: Reset to defaults</p> <p>Data Visibility Requirements: - Show numerical values of initial conditions next to sliders - Display the current time constant or damping ratio - Show steady-state value on the total response plot - Annotate key features (peak, settling)</p> <p>Behavior: - When parameters change, all three plots update simultaneously - Natural response shows exponential decay (1st order) or damped oscillation (2nd order) - Forced response shows system responding from rest to input - Total response clearly shows sum of components - Color-coded to match the decomposition equation</p> <p>Instructional Rationale: Seeing natural and forced responses separated then summed builds intuition for superposition. Adjustable parameters let students explore how each component contributes.</p> <p>Implementation: p5.js with canvas-based sliders and dropdown</p>"},{"location":"chapters/03-time-domain-response/#zero-input-and-zero-state-responses","title":"Zero-Input and Zero-State Responses","text":"<p>\"Wait,\" you might be thinking, \"didn't we just cover this?\" Not quite. Here's an alternative but equivalent decomposition that splits the total response into zero-input response and zero-state response. Same math, different perspective.</p> <p>The zero-input response is the system's output when the input is zero (hence the name) but initial conditions are non-zero. This is identical to the natural response\u2014it's what the system does on its own, releasing stored energy like a wound-up toy.</p> <p>The zero-state response is the output when initial conditions are all zero (the system starts in a \"zero state\") but an input is applied. This matches the forced response\u2014it's how the system responds to external stimulation starting from rest.</p> <p>So why do we have two names for the same concepts? Because engineers love precision (and sometimes redundancy). The terminology serves different purposes:</p> <ul> <li>Natural/Forced: Emphasizes the physical origin (internal energy vs. external driving)</li> <li>Zero-Input/Zero-State: Emphasizes the mathematical conditions (which term is \"zeroed out\")</li> </ul> <p>Both lead to the same total response through superposition:</p> \\[y(t) = y_{\\text{zero-input}}(t) + y_{\\text{zero-state}}(t)\\] Terminology What's Zero? What Drives the Response? Zero-Input Response Input \\(u(t) = 0\\) Initial conditions only Zero-State Response All \\(y^{(k)}(0) = 0\\) External input only"},{"location":"chapters/03-time-domain-response/#transient-response-and-steady-state-response","title":"Transient Response and Steady-State Response","text":"<p>While natural/forced decomposition separates responses by cause, transient and steady-state decomposition separates them by time behavior. This perspective is often more useful when your boss asks, \"When will this thing settle down?\"</p> <p>The transient response is the portion of the output that eventually dies out as time marches toward infinity. It represents the system \"settling down\" from initial disturbances or adjusting to new inputs. Think of it as the drama phase\u2014the oscillations, overshoots, and adjustments that characterize the system's journey to equilibrium. Eventually, the drama ends.</p> <p>The steady-state response is what remains after all transient effects have vanished. It's the long-term behavior\u2014the value (or pattern) the output approaches as \\(t \\to \\infty\\). For a step input, the steady-state response is typically a constant value. For a sinusoidal input, it's a sinusoid at the same frequency (though possibly with different amplitude and phase). This is where the system finally chills out.</p> <p>Consider the eternal battle of office thermostat wars\u2014you set it to 72\u00b0F:</p> <ul> <li>Transient response: The temperature climbs (possibly overshoots to 74\u00b0F), then settles</li> <li>Steady-state response: The temperature stabilizes at 72\u00b0F (with minor fluctuations from the on-off controller)</li> </ul> <p>The total response combines both:</p> \\[y(t) = y_{\\text{transient}}(t) + y_{\\text{steady-state}}(t)\\] <p>where \\(\\lim_{t \\to \\infty} y_{\\text{transient}}(t) = 0\\) for stable systems.</p> <p>For Stable Systems Only</p> <p>The transient response decays to zero only for stable systems. Unstable systems have transient components that grow without bound\u2014a critical distinction we'll explore in the stability chapter.</p>"},{"location":"chapters/03-time-domain-response/#first-order-systems","title":"First-Order Systems","text":"<p>A first-order system is the simplest dynamic system you'll encounter\u2014characterized by a single energy storage element and governed by a first-order differential equation. If systems were coffee drinks, first-order would be black coffee: straightforward, dependable, no frills.</p> <p>The standard form of a first-order transfer function is:</p> \\[G(s) = \\frac{K}{\\tau s + 1}\\] <p>where:</p> <ul> <li>\\(K\\) is the DC gain (steady-state output per unit input)</li> <li>\\(\\tau\\) (tau) is the time constant (with units of time)</li> </ul> <p>The step response of a first-order system is elegantly simple\u2014memorize this one:</p> \\[y(t) = K \\cdot (1 - e^{-t/\\tau})\\] <p>This exponential approach to the final value \\(K\\) is the hallmark of first-order behavior. There's no oscillation, no overshoot, no drama\u2014just a smooth, monotonic rise (or fall). It's the Steady Eddie of system responses.</p> Time Output Value Percentage of Final \\(t = \\tau\\) \\(0.632K\\) 63.2% \\(t = 2\\tau\\) \\(0.865K\\) 86.5% \\(t = 3\\tau\\) \\(0.950K\\) 95.0% \\(t = 4\\tau\\) \\(0.982K\\) 98.2% \\(t = 5\\tau\\) \\(0.993K\\) 99.3% <p>The time constant \\(\\tau\\) has several equivalent interpretations:</p> <ul> <li>Time to reach 63.2% of the final value</li> <li>Time it would take to reach the final value if the initial rate of change continued</li> <li>The reciprocal of the pole location (pole at \\(s = -1/\\tau\\))</li> </ul> <p>The Rule of Five Tau</p> <p>Engineers live by the \"5\u03c4 rule\": a first-order system is considered to have reached steady state after approximately \\(5\\tau\\) seconds, when it's within 1% of the final value. Commit this to memory\u2014it'll serve you well in exams and in life.</p> <p>Helping Gyra</p> <p>Gyra's time constant determines how quickly she responds to disturbances. A small \\(\\tau\\) means she reacts fast\u2014great for quick corrections, but potentially twitchy. A large \\(\\tau\\) means she responds slowly\u2014smooth and graceful, but maybe too slow to catch herself when pushed. When we tune Gyra's controller, we're effectively choosing her time constant. The 5\u03c4 rule tells us how long to wait after a disturbance before we can say \"okay, she's settled.\" If \\(\\tau = 0.2\\) seconds, Gyra settles in about 1 second. If \\(\\tau = 2\\) seconds, we're waiting 10 seconds. For a robot fighting gravity, that difference matters!</p>"},{"location":"chapters/03-time-domain-response/#diagram-first-order-step-response-explorer","title":"Diagram: First-Order Step Response Explorer","text":"First-Order Step Response Explorer <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: demonstrate, calculate</p> <p>Learning Objective: Students will predict and verify first-order step response behavior by adjusting the time constant and observing the effect on response speed.</p> <p>Canvas layout: - Left side (65%): Time response plot with animated curve - Right side (35%): Control panel and key values display</p> <p>Visual elements: - Step response curve (blue line) - Horizontal dashed line at final value K - Vertical dashed lines at \u03c4, 2\u03c4, 3\u03c4, 4\u03c4, 5\u03c4 - Dots marking 63.2%, 86.5%, 95%, 98.2%, 99.3% points - Tangent line at t=0 showing initial slope - Axis labels: \"Time (seconds)\" and \"Output y(t)\"</p> <p>Interactive controls: - Slider: Time constant \u03c4 from 0.1 to 5 seconds (default: 1.0) - Slider: DC gain K from 0.5 to 3 (default: 1.0) - Button: \"Animate Response\" - draws curve progressively - Button: \"Reset\" - Toggle: Show/hide construction lines (tangent, tau markers)</p> <p>Data Visibility Requirements: - Display current \u03c4 and K values - Show \"Time to 63.2%: \u03c4 = [value] s\" - Show \"Time to 95%: 3\u03c4 = [value] s\" - Show \"Approximate settling time: 5\u03c4 = [value] s\" - Display pole location: \"Pole at s = [value]\"</p> <p>Behavior: - Curve updates in real-time as sliders change - Animate mode draws the curve left-to-right to show temporal evolution - Tangent line at origin extends to intersect final value line at t=\u03c4 - Grid snaps to \u03c4 units for easy reading</p> <p>Instructional Rationale: Direct manipulation of \u03c4 with immediate visual feedback builds intuition for the relationship between time constant and response speed. Showing multiple \u03c4 markers reinforces the \"rule of five tau.\"</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/03-time-domain-response/#second-order-systems","title":"Second-Order Systems","text":"<p>Now we're getting to the good stuff. Second-order systems are the workhorses of control systems analysis\u2014the Swiss Army knife of dynamic modeling. With two energy storage elements, they exhibit richer dynamics than first-order systems, including the possibility of oscillation. If first-order systems are black coffee, second-order systems are espresso with a twist: more complex, more interesting, and occasionally capable of surprising you.</p> <p>The standard form of a second-order transfer function is beautifully compact:</p> \\[G(s) = \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2}\\] <p>This elegant formulation introduces two crucial parameters\u2014learn to love them:</p> <ul> <li>\\(\\omega_n\\): the natural frequency (rad/s)</li> <li>\\(\\zeta\\) (zeta): the damping ratio (dimensionless)</li> </ul> <p>These two parameters completely characterize the dynamic behavior of any second-order system. That's it. Two numbers tell the whole story. The natural frequency \\(\\omega_n\\) determines how fast the system responds, while the damping ratio \\(\\zeta\\) determines whether the response oscillates and how quickly those oscillations decay.</p> <p>The characteristic equation \\(s^2 + 2\\zeta\\omega_n s + \\omega_n^2 = 0\\) has roots:</p> \\[s_{1,2} = -\\zeta\\omega_n \\pm \\omega_n\\sqrt{\\zeta^2 - 1}\\] <p>The nature of these roots\u2014whether real or complex\u2014depends entirely on \\(\\zeta\\). And that's where the fun begins.</p>"},{"location":"chapters/03-time-domain-response/#natural-frequency","title":"Natural Frequency","text":"<p>The natural frequency \\(\\omega_n\\) represents the frequency at which the system would oscillate if there were no damping whatsoever. It's called \"natural\" because it's an intrinsic property of the system, determined purely by its physical parameters\u2014like how some people are naturally morning people (and some of us aren't).</p> <p>For a mass-spring system: \\(\\(\\omega_n = \\sqrt{\\frac{k}{m}}\\)\\)</p> <p>where \\(k\\) is the spring stiffness and \\(m\\) is the mass. Stiffer spring or lighter mass? Higher natural frequency\u2014the system oscillates faster. It's intuitive once you think about it: a trampoline bounces at a different frequency than a car suspension.</p> <p>For an LC circuit: \\(\\(\\omega_n = \\frac{1}{\\sqrt{LC}}\\)\\)</p> <p>The natural frequency has units of radians per second (rad/s). To convert to hertz (cycles per second), divide by \\(2\\pi\\):</p> \\[f_n = \\frac{\\omega_n}{2\\pi} \\text{ Hz}\\] <p>Natural \u2260 Actual</p> <p>Here's a common gotcha: the natural frequency \\(\\omega_n\\) is the oscillation frequency only for undamped systems. Real systems with damping oscillate at the damped frequency \\(\\omega_d\\), which is always less than \\(\\omega_n\\). Reality, it seems, is always a bit slower than the ideal.</p>"},{"location":"chapters/03-time-domain-response/#damping-ratio","title":"Damping Ratio","text":"<p>The damping ratio \\(\\zeta\\) (that's the Greek letter \"zeta\"\u2014you'll be writing it a lot) quantifies how much energy dissipation exists relative to the energy storage in the system. It's a dimensionless number, which means it's the same whether you're measuring in metric or imperial, and it determines the qualitative nature of the system's response.</p> <p>For a mass-spring-damper: \\(\\(\\zeta = \\frac{b}{2\\sqrt{km}}\\)\\)</p> <p>where \\(b\\) is the damping coefficient. The denominator \\(2\\sqrt{km}\\) represents the critical damping value\u2014the exact amount of damping that separates oscillatory from non-oscillatory behavior. Think of it as the Goldilocks point: not too bouncy, not too sluggish.</p> <p>The damping ratio creates a classification scheme for second-order systems\u2014and this table is worth memorizing:</p> Damping Ratio Classification Pole Type Response Character \\(\\zeta = 0\\) Undamped Purely imaginary Perpetual oscillation \\(0 &lt; \\zeta &lt; 1\\) Underdamped Complex conjugate Decaying oscillation \\(\\zeta = 1\\) Critically damped Repeated real Fastest non-oscillatory \\(\\zeta &gt; 1\\) Overdamped Distinct real Sluggish, no oscillation <p>This classification is fundamental\u2014it tells us whether a system will ring like a bell, how fast it will settle, and whether it will overshoot its target. Master this table, and you've got a superpower for predicting system behavior.</p> <p>Helping Gyra</p> <p>Gyra lives and breathes damping ratio. When her controller is underdamped, she wobbles back and forth before settling\u2014annoying but eventually stable. When she's overdamped, she corrects so sluggishly that a gust of wind might knock her over before she finishes responding. But when she's critically damped? That's the sweet spot. She returns to upright quickly without any wobble. Finding Gyra's \"just right\" damping is one of our main jobs as her control engineers. Too twitchy? Lower the gain. Too sluggish? Speed her up. Goldilocks would approve.</p>"},{"location":"chapters/03-time-domain-response/#damped-frequency","title":"Damped Frequency","text":"<p>For underdamped systems (\\(0 &lt; \\zeta &lt; 1\\)), oscillations occur at the damped frequency \\(\\omega_d\\), not the natural frequency \\(\\omega_n\\). The damped frequency is:</p> \\[\\omega_d = \\omega_n\\sqrt{1 - \\zeta^2}\\] <p>Since \\(\\sqrt{1-\\zeta^2} &lt; 1\\) for any \\(\\zeta &gt; 0\\), we always have \\(\\omega_d &lt; \\omega_n\\). Damping slows down the oscillation.</p> <p>The relationship is geometric: if we plot \\(\\omega_n\\) as the hypotenuse of a right triangle, then \\(\\omega_d\\) is one leg and \\(\\zeta\\omega_n\\) (the real part of the poles) is the other.</p> <p>For small damping ratios, \\(\\omega_d \\approx \\omega_n\\). For example:</p> <ul> <li>\\(\\zeta = 0.1\\): \\(\\omega_d = 0.995\\omega_n\\) (only 0.5% reduction)</li> <li>\\(\\zeta = 0.5\\): \\(\\omega_d = 0.866\\omega_n\\) (13.4% reduction)</li> <li>\\(\\zeta = 0.9\\): \\(\\omega_d = 0.436\\omega_n\\) (56.4% reduction)</li> </ul>"},{"location":"chapters/03-time-domain-response/#diagram-damping-ratio-classification","title":"Diagram: Damping Ratio Classification","text":"Damping Ratio Classification <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: differentiate, compare</p> <p>Learning Objective: Students will differentiate between underdamped, critically damped, and overdamped responses by observing how changing the damping ratio transforms the step response.</p> <p>Canvas layout: - Left side (60%): Time response plot - Right side (40%): S-plane pole plot and controls</p> <p>Visual elements: Time Response Plot: - Step response curve (color changes based on damping classification) - Horizontal line at steady-state value - Envelope curves for underdamped case (showing exponential decay) - Grid with labeled axes</p> <p>S-Plane Plot: - Unit circle (dashed) - Real and imaginary axes - Poles marked with X symbols (color-coded) - Constant damping ratio lines (radial lines from origin) - Constant natural frequency arcs (circles centered at origin)</p> <p>Interactive controls: - Slider: Damping ratio \u03b6 from 0 to 2 (default: 0.5) - Slider: Natural frequency \u03c9n from 0.5 to 5 rad/s (default: 2) - Buttons: Preset values for \u03b6 = 0.1, 0.5, 0.707, 1.0, 2.0 - Toggle: Show/hide envelope curves</p> <p>Data Visibility Requirements: - Display current \u03b6 and \u03c9n values - Show classification label: \"Underdamped\", \"Critically Damped\", or \"Overdamped\" - For underdamped: show \u03c9d = [value] rad/s - Show pole locations: s\u2081,\u2082 = [values] - Display percent overshoot (for underdamped)</p> <p>Behavior: - Response curve color: blue for underdamped, green for critically damped, orange for overdamped - Poles move smoothly on s-plane as \u03b6 changes - At \u03b6=1, two poles merge on real axis - For \u03b6&gt;1, poles split apart on real axis - Classification label updates dynamically</p> <p>Instructional Rationale: Side-by-side view of time response and pole locations connects abstract s-plane concepts to concrete response behavior. Smooth slider interaction reveals the continuous nature of the transition between damping regimes.</p> <p>Implementation: p5.js with dual canvas areas and canvas-based controls</p>"},{"location":"chapters/03-time-domain-response/#undamped-systems","title":"Undamped Systems","text":"<p>An undamped system has \\(\\zeta = 0\\), meaning there is zero energy dissipation. The poles lie exactly on the imaginary axis at \\(s = \\pm j\\omega_n\\), and the system oscillates forever at the natural frequency. Forever. Like that song stuck in your head.</p> <p>The step response for an undamped system is:</p> \\[y(t) = K(1 - \\cos(\\omega_n t))\\] <p>This represents perpetual oscillation between 0 and \\(2K\\), with the output never settling to a steady value. While theoretically interesting (and great for exam problems), truly undamped systems are rare in practice\u2014there's almost always some mechanism for energy loss. The universe, it turns out, is full of friction.</p> <p>Real-world examples that approximate undamped behavior:</p> <ul> <li>A pendulum in a vacuum (no air resistance)</li> <li>A frictionless mass on an ideal spring (good luck finding one)</li> <li>An LC circuit with superconducting components (now we're talking)</li> </ul>"},{"location":"chapters/03-time-domain-response/#underdamped-systems","title":"Underdamped Systems","text":"<p>Underdamped systems (\\(0 &lt; \\zeta &lt; 1\\)) are the most common in practice\u2014and often the most fun to analyze. They exhibit damped oscillations: the response overshoots the target, oscillates back and forth like it can't make up its mind, and gradually settles to the steady-state value.</p> <p>The step response for an underdamped second-order system is:</p> \\[y(t) = K\\left[1 - \\frac{e^{-\\zeta\\omega_n t}}{\\sqrt{1-\\zeta^2}}\\sin(\\omega_d t + \\phi)\\right]\\] <p>where \\(\\phi = \\cos^{-1}(\\zeta)\\) and \\(\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\).</p> <p>Key features of the underdamped response\u2014watch for these:</p> <ul> <li>Overshoot: The response exceeds the final value before settling (sometimes dramatically)</li> <li>Ringing: Multiple oscillations occur before settling (the system is indecisive)</li> <li>Exponential envelope: Oscillation amplitude decays as \\(e^{-\\zeta\\omega_n t}\\) (eventually, calm prevails)</li> </ul> <p>The complex conjugate poles at \\(s = -\\zeta\\omega_n \\pm j\\omega_d\\) lie in the left half of the s-plane (for stability), with:</p> <ul> <li>Real part \\(-\\zeta\\omega_n\\) determining decay rate</li> <li>Imaginary part \\(\\omega_d\\) determining oscillation frequency</li> </ul> <p>Here's a practical insight: many engineered systems are deliberately designed to be slightly underdamped (\\(\\zeta \\approx 0.4\\) to \\(0.7\\)) because this provides a sweet spot\u2014fast response with acceptable overshoot. It's a conscious design choice, not a failure.</p> <p>Helping Gyra</p> <p>When Gyra overshoots, she leans past vertical, catches herself, swings back, overshoots the other way, and gradually settles down. It looks like she's panicking, but she's actually following the math perfectly\u2014this is underdamped second-order behavior in action. The overshoot percentage tells us how far past vertical she'll swing. The ringing frequency tells us how fast she'll wobble. Once you can predict these from \\(\\zeta\\) and \\(\\omega_n\\), you can tune her controller to minimize the drama while keeping her responsive. A little wobble is often acceptable; falling over is not.</p>"},{"location":"chapters/03-time-domain-response/#critically-damped-systems","title":"Critically Damped Systems","text":"<p>A critically damped system has \\(\\zeta = 1\\), representing the boundary between oscillatory and non-oscillatory behavior\u2014the knife's edge. The characteristic equation has a repeated real root at \\(s = -\\omega_n\\).</p> <p>The step response for a critically damped system is:</p> \\[y(t) = K[1 - (1 + \\omega_n t)e^{-\\omega_n t}]\\] <p>Critical damping is special\u2014it's the Goldilocks of damping:</p> <ul> <li>It's the fastest response that doesn't overshoot</li> <li>Any less damping would cause oscillation</li> <li>Any more damping would slow the response</li> </ul> <p>This makes critically damped systems ideal for applications where overshoot is unacceptable but fast response is still desired\u2014such as the needle on an analog measuring instrument or a door closer mechanism. When precision matters and you can't afford any \"oops, went too far,\" critical damping is your friend.</p> <p>The Door Closer Analogy</p> <p>A well-adjusted door closer is critically damped: the door swings closed quickly without bouncing back. An underdamped closer would let the door swing past closed and oscillate (bang-bang-bang). An overdamped closer would close the door so slowly you'd grow old waiting. Next time you're at a well-designed building, appreciate the engineering.</p>"},{"location":"chapters/03-time-domain-response/#overdamped-systems","title":"Overdamped Systems","text":"<p>Overdamped systems (\\(\\zeta &gt; 1\\)) have two distinct real poles, both in the left half-plane. The response is a sum of two decaying exponentials with no oscillation whatsoever\u2014it's the slow-and-steady approach to life.</p> <p>The step response involves two time constants:</p> \\[y(t) = K\\left[1 - \\frac{\\tau_1}{\\tau_1-\\tau_2}e^{-t/\\tau_1} + \\frac{\\tau_2}{\\tau_1-\\tau_2}e^{-t/\\tau_2}\\right]\\] <p>where \\(\\tau_1\\) and \\(\\tau_2\\) are related to the two pole locations.</p> <p>Characteristics of overdamped response:</p> <ul> <li>No overshoot (monotonic approach to final value\u2014boring but reliable)</li> <li>Slower than critically damped for the same \\(\\omega_n\\)</li> <li>Response dominated by the slower pole (the slowpoke sets the pace)</li> </ul> <p>Overdamped systems are often used when oscillation must be absolutely prevented, even at the cost of slower response. Sometimes \"boring\" is exactly what you want:</p> <ul> <li>Heavy vehicle suspensions (smooth ride priority over sporty handling)</li> <li>Some thermal systems (gradual temperature changes preferred\u2014no thermal shock)</li> <li>Systems where oscillation could cause mechanical damage or operator discomfort</li> </ul>"},{"location":"chapters/03-time-domain-response/#diagram-second-order-response-comparison","title":"Diagram: Second-Order Response Comparison","text":"Second-Order Response Comparison <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: compare, contrast</p> <p>Learning Objective: Students will compare and contrast underdamped, critically damped, and overdamped step responses by viewing them simultaneously on the same axes.</p> <p>Canvas layout: - Main area (75%): Time response plot with multiple curves - Right panel (25%): Controls and legend</p> <p>Visual elements: - Three step response curves plotted simultaneously:   - Blue: Underdamped (\u03b6 &lt; 1)   - Green: Critically damped (\u03b6 = 1)   - Orange: Overdamped (\u03b6 &gt; 1) - Horizontal dashed line at final value - Time axis marked with \u03c4 units where \u03c4 = 1/\u03c9n - Clear legend identifying each curve</p> <p>Interactive controls: - Slider: Natural frequency \u03c9n from 1 to 5 rad/s (default: 2) - Slider: Underdamped \u03b6 from 0.1 to 0.9 (default: 0.5) - Slider: Overdamped \u03b6 from 1.1 to 3.0 (default: 1.5) - Toggle: Show/hide individual curves - Button: Reset to defaults</p> <p>Data Visibility Requirements: - Display settling time for each response - Show percent overshoot for underdamped case - Display rise time for each response - Show pole locations for each case</p> <p>Behavior: - All three curves share the same \u03c9n (only damping differs) - Curves update in real-time as \u03c9n changes - Underdamped and overdamped curves update as their respective \u03b6 sliders change - Critical damping curve always shows \u03b6 = 1</p> <p>Instructional Rationale: Direct visual comparison on the same axes makes the trade-offs between response types immediately apparent. Students can see that critical damping is the \"goldilocks\" case\u2014fastest without overshoot.</p> <p>Implementation: p5.js with canvas-based controls and multi-curve plotting</p>"},{"location":"chapters/03-time-domain-response/#higher-order-systems","title":"Higher-Order Systems","text":"<p>Real-world systems often have more than two energy storage elements, leading to higher-order systems (order 3 and above). Don't panic. While the mathematical analysis becomes more complex, the fundamental concepts of transient and steady-state response still apply\u2014you've already learned the hard parts.</p> <p>A third-order system, for example, might have three poles arranged as:</p> <ul> <li>One real pole plus a complex conjugate pair</li> <li>Three distinct real poles</li> <li>One real pole plus a repeated pair</li> </ul> <p>Here's the good news (and it's really good): higher-order systems can often be approximated by lower-order models. The key insight is the concept of dominant poles\u2014the poles that contribute most significantly to the response.</p> <p>Think of it this way: poles far to the left in the s-plane (large negative real parts) correspond to fast-decaying transients that die out quickly\u2014blink and you'll miss them. The poles closest to the imaginary axis decay slowest and therefore dominate the long-term behavior. It's like a race where the slowest runner determines when the group finishes.</p> Pole Location Decay Rate Impact on Response Near imaginary axis Slow Dominates transient Far left in s-plane Fast Quickly negligible Very far left Very fast Often ignored <p>The Factor of 5-10 Rule</p> <p>If a pole is 5-10 times farther from the imaginary axis than the dominant poles, its contribution decays so fast that it can often be neglected for design purposes. This is engineering pragmatism at its finest\u2014ignore the details that don't matter.</p>"},{"location":"chapters/03-time-domain-response/#diagram-dominant-poles-visualization","title":"Diagram: Dominant Poles Visualization","text":"Dominant Poles Visualization <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: differentiate, attribute</p> <p>Learning Objective: Students will identify dominant poles in a higher-order system by observing how individual pole contributions combine to form the total response.</p> <p>Canvas layout: - Left (50%): S-plane showing multiple poles - Right (50%): Time response showing individual and total responses</p> <p>Visual elements: S-Plane: - Complex plane with real and imaginary axes - Three poles (one pair complex conjugate, one real) marked with X - Draggable poles - Region shading showing \"dominant\" vs \"fast\" zones</p> <p>Time Response: - Individual contributions from each pole/pair (thin dashed lines) - Total response (thick solid line) - Axis labels and grid</p> <p>Interactive controls: - Drag poles on s-plane to reposition them - Toggle: Show/hide individual contributions - Button: Reset to default configuration - Button: \"Make pole dominant\" (moves selected pole toward imaginary axis)</p> <p>Data Visibility Requirements: - Show pole values (real and imaginary parts) - Display time constants for each pole - Indicate which pole(s) are currently \"dominant\" - Show percentage contribution to total response at t=settling</p> <p>Behavior: - As poles are dragged, time responses update in real-time - Poles farther left contribute faster-decaying exponentials - Visual highlighting when a pole becomes dominant (closest to imaginary axis) - Total response clearly shows sum of individual components</p> <p>Instructional Rationale: Interactive pole placement with decomposed responses demonstrates why certain poles dominate. Students develop intuition for which poles matter most without complex mathematics.</p> <p>Implementation: p5.js with draggable elements and multi-curve plotting</p>"},{"location":"chapters/03-time-domain-response/#time-constant","title":"Time Constant","text":"<p>The time constant \\(\\tau\\) is a fundamental parameter for characterizing response speed\u2014and one of those concepts that pops up everywhere in engineering. For first-order systems, it's beautifully simple:</p> \\[\\tau = \\frac{1}{|p|}\\] <p>where \\(p\\) is the pole location. For higher-order systems, each pole contributes its own time constant.</p> <p>Here's what makes the time constant so satisfying\u2014it has profound physical meaning across completely different domains:</p> <ul> <li>In an RC circuit: \\(\\tau = RC\\) (resistance \u00d7 capacitance)</li> <li>In a thermal system: \\(\\tau = \\rho C_p V / hA\\) (thermal mass / heat transfer rate)</li> <li>In a mechanical system: \\(\\tau = m/b\\) (mass / damping coefficient)</li> </ul> <p>For second-order underdamped systems, the concept extends through the decay time constant:</p> \\[\\tau_d = \\frac{1}{\\zeta\\omega_n}\\] <p>This is the time constant of the exponential envelope that bounds the oscillations. After \\(5\\tau_d\\) seconds, the oscillations have decayed to less than 1% of their initial amplitude.</p> System Type Time Constant Formula Physical Meaning First-order $\\tau = 1/ p Underdamped 2nd-order \\(\\tau_d = 1/(\\zeta\\omega_n)\\) Envelope decay rate Overdamped 2nd-order \\(\\tau_1, \\tau_2\\) Two decay rates"},{"location":"chapters/03-time-domain-response/#putting-it-all-together-the-total-response","title":"Putting It All Together: The Total Response","text":"<p>Now let's step back and see the big picture. The concepts in this chapter combine to give us a complete analytical framework for system behavior. For any linear time-invariant system, here's your game plan:</p> <ol> <li>Classify the system by order and damping</li> <li>Identify initial conditions and inputs</li> <li>Decompose the response:</li> <li>Natural + Forced (or Zero-Input + Zero-State)</li> <li>Transient + Steady-State</li> <li>Characterize using key parameters (\\(\\tau\\), \\(\\zeta\\), \\(\\omega_n\\), \\(\\omega_d\\))</li> <li>Predict qualitative and quantitative behavior</li> </ol> <p>This framework applies whether you're analyzing a simple RC circuit or a complex multi-degree-of-freedom mechanical system. The mathematical details differ, but the conceptual structure remains the same. Learn this once, use it forever\u2014that's the beauty of classical control theory.</p>"},{"location":"chapters/03-time-domain-response/#diagram-response-analysis-workflow","title":"Diagram: Response Analysis Workflow","text":"Response Analysis Workflow <p>Type: workflow</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: execute, implement</p> <p>Learning Objective: Students will apply the systematic workflow for analyzing time-domain response of a given system.</p> <p>Purpose: Show the step-by-step process for analyzing any system's time response</p> <p>Visual style: Flowchart with decision diamonds and process rectangles</p> <p>Steps: 1. Start: \"Given: System G(s), Input u(t), Initial Conditions\"    Hover text: \"Start with transfer function, input signal, and initial state\"</p> <ol> <li> <p>Process: \"Determine System Order\"    Hover text: \"Find highest power of s in denominator\"</p> </li> <li> <p>Decision: \"Order = ?\"    Hover text: \"Branch based on system order\"</p> </li> </ol> <p>4a. Process: \"First-Order Analysis\" (if Order = 1)     Hover text: \"Find \u03c4 and K, calculate y(t) = K(1-e^(-t/\u03c4))\"</p> <p>4b. Process: \"Second-Order Analysis\" (if Order = 2)     Hover text: \"Calculate \u03b6 and \u03c9n from characteristic equation\"</p> <p>4c. Process: \"Higher-Order Analysis\" (if Order \u2265 3)     Hover text: \"Identify dominant poles, approximate if appropriate\"</p> <ol> <li> <p>Decision: \"\u03b6 &lt; 1, = 1, or &gt; 1?\" (for second-order)    Hover text: \"Classify damping type\"</p> </li> <li> <p>Process: \"Calculate Response Parameters\"    Hover text: \"Determine overshoot, settling time, rise time, etc.\"</p> </li> <li> <p>Process: \"Decompose Response\"    Hover text: \"Separate natural/forced and transient/steady-state\"</p> </li> <li> <p>End: \"Complete Response y(t)\"    Hover text: \"Total response with all characteristics identified\"</p> </li> </ol> <p>Color coding: - Blue: Classification steps - Green: Analysis steps - Yellow: Decision points - Purple: Parameter calculation</p> <p>Interactive elements: - Hover over each box for detailed explanation - Click to expand with example calculations</p> <p>Implementation: HTML/CSS/JavaScript with SVG flowchart</p>"},{"location":"chapters/03-time-domain-response/#key-takeaways","title":"Key Takeaways","text":"<p>Congratulations\u2014you've just acquired a powerful toolkit for understanding how systems behave over time. Here's what you can now do:</p> <ul> <li> <p>System order determines the complexity of response behavior\u2014more energy storage elements mean more complex dynamics (but don't panic about higher orders)</p> </li> <li> <p>The natural response arises from initial conditions; the forced response arises from external inputs; their sum gives the total response. Divide and conquer!</p> </li> <li> <p>Transient response is the drama that eventually dies out; steady-state response is the calm that remains after transients decay</p> </li> <li> <p>First-order systems exhibit simple exponential behavior characterized by a single time constant \\(\\tau\\)\u2014remember the 5\u03c4 rule!</p> </li> <li> <p>Second-order systems are characterized by natural frequency \\(\\omega_n\\) and damping ratio \\(\\zeta\\), which together tell the whole story of oscillation and decay</p> </li> <li> <p>The damping ratio classifies second-order systems (memorize this!):</p> </li> <li>\\(\\zeta = 0\\): Undamped (perpetual oscillation)</li> <li>\\(0 &lt; \\zeta &lt; 1\\): Underdamped (damped oscillation\u2014the common case)</li> <li>\\(\\zeta = 1\\): Critically damped (fastest non-oscillatory\u2014the Goldilocks case)</li> <li> <p>\\(\\zeta &gt; 1\\): Overdamped (sluggish, no oscillation\u2014slow but steady)</p> </li> <li> <p>Higher-order systems can often be approximated by focusing on dominant poles\u2014those closest to the imaginary axis. Simplify wisely!</p> </li> </ul> <p>These concepts form the vocabulary and mental models that control engineers use daily. When you see \\(\\zeta\\) and \\(\\omega_n\\) in someone's notes, you'll know exactly what they're talking about. In the next chapter, we'll apply this understanding to analyze standard test inputs and define precise performance specifications\u2014because \"fast enough\" isn't a spec.</p> Self-Check: Test Your Understanding <p>Before moving on, see if you can answer these without peeking at the chapter:</p> <ol> <li>A system has poles at \\(s = -2\\) and \\(s = -10\\). Which pole dominates the response? (Hint: think about which one decays slower)</li> <li>For a second-order system with \\(\\zeta = 0.6\\) and \\(\\omega_n = 5\\) rad/s, what is the damped frequency \\(\\omega_d\\)?</li> <li>True or false: A critically damped system reaches steady-state faster than an underdamped system with the same natural frequency. (This one's trickier than it looks!)</li> <li>What happens to the step response if you double the time constant of a first-order system?</li> </ol> <p>If you got all four, you're ready for the next chapter. If not, that's what the MicroSims are for\u2014play with them!</p>"},{"location":"chapters/04-transient-response-specs/","title":"Transient Response Specifications","text":""},{"location":"chapters/04-transient-response-specs/#summary","title":"Summary","text":"<p>This chapter focuses on quantitative measures used to specify and evaluate transient response performance. Students will learn to calculate and interpret key metrics including overshoot, percent overshoot, settling time, rise time, peak time, and delay time. The chapter also introduces the standard test inputs (step, impulse, ramp, parabolic, and sinusoidal) used throughout control systems analysis. By the end of this chapter, students will be able to specify performance requirements and evaluate whether a system meets those requirements.</p>"},{"location":"chapters/04-transient-response-specs/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 15 concepts from the learning graph:</p> <ol> <li>Overshoot</li> <li>Percent Overshoot</li> <li>Settling Time</li> <li>Rise Time</li> <li>Peak Time</li> <li>Delay Time</li> <li>Step Input</li> <li>Impulse Input</li> <li>Ramp Input</li> <li>Parabolic Input</li> <li>Sinusoidal Input</li> <li>Unit Step Response</li> <li>Impulse Response</li> <li>Ramp Response</li> <li>Standard Test Inputs</li> </ol>"},{"location":"chapters/04-transient-response-specs/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 3: Time-Domain Response Fundamentals</li> </ul>"},{"location":"chapters/04-transient-response-specs/#from-qualitative-to-quantitative-specifying-performance","title":"From Qualitative to Quantitative: Specifying Performance","text":"<p>In the previous chapter, we watched systems respond to inputs\u2014some oscillated, some crept smoothly toward their targets, and some charged forward with varying degrees of enthusiasm. We learned to classify systems by their damping ratio and natural frequency. But here's the thing: \"underdamped\" and \"oscillatory\" are descriptions, not specifications. Your boss doesn't want to hear \"it oscillates a bit and then settles down eventually.\" They want numbers.</p> <p>Welcome to the world of transient response specifications\u2014the engineering language for describing exactly how a system should behave. These metrics let us write precise requirements (\"percent overshoot shall not exceed 10%\") and verify that our designs meet them. They transform vague notions like \"responsive but stable\" into testable criteria that can be put into contracts, verified in testing, and argued about in meetings.</p> <p>Gyra Moment</p> <p>\"When my engineers say 'settle down faster,' I have no idea what that means. But when they say 'settling time under 0.5 seconds with less than 5% overshoot'\u2014that I can work with. Give me numbers, and I'll give you results.\"</p> <p>The metrics we'll cover in this chapter are standard across industries\u2014from aerospace to automotive to biomedical systems. Learn them once, and you'll speak the universal language of control system performance.</p>"},{"location":"chapters/04-transient-response-specs/#standard-test-inputs","title":"Standard Test Inputs","text":"<p>Before we can measure system performance, we need to agree on what we're measuring the response to. This is where standard test inputs come in\u2014a collection of mathematically simple signals that serve as benchmarks for system analysis. Using standardized inputs allows engineers worldwide to compare systems fairly: my step response and your step response should mean the same thing.</p> <p>Why these particular inputs? Because they represent fundamental classes of real-world disturbances and commands, and because they have convenient mathematical properties (especially in the Laplace domain). Each reveals different aspects of system behavior.</p> Test Input Time Domain Laplace Transform What It Reveals Impulse \\(\\delta(t)\\) \\(1\\) Natural dynamics, stability Step \\(u(t)\\) \\(1/s\\) Tracking, steady-state error Ramp \\(t \\cdot u(t)\\) \\(1/s^2\\) Velocity tracking error Parabolic \\(\\frac{1}{2}t^2 \\cdot u(t)\\) \\(1/s^3\\) Acceleration tracking error Sinusoidal \\(\\sin(\\omega t)\\) \\(\\omega/(s^2 + \\omega^2)\\) Frequency response"},{"location":"chapters/04-transient-response-specs/#diagram-standard-test-input-signals","title":"Diagram: Standard Test Input Signals","text":"Standard Test Input Signals <p>Type: microsim</p> <p>Bloom Taxonomy: Remember (L1) Bloom Verb: identify, recognize</p> <p>Learning Objective: Students will identify and distinguish between the five standard test inputs by their characteristic shapes and mathematical representations.</p> <p>Canvas layout: - Main area (70%): Plot area showing selected input signal - Right panel (30%): Input selector and information display</p> <p>Visual elements: - Time-domain plot with clearly labeled axes - Input signal displayed with thick colored line - Mathematical expression shown above or beside plot - Laplace transform shown in info panel - Grid lines for reference</p> <p>Interactive controls: - Radio buttons or dropdown: Select input type (Impulse, Step, Ramp, Parabolic, Sinusoidal) - Slider (for sinusoidal only): Frequency \u03c9 from 0.5 to 5 rad/s - Button: \"Compare All\" - shows all inputs on same axes with different colors/scales</p> <p>Data Visibility Requirements: - Display time-domain expression: u(t), t\u00b7u(t), etc. - Display Laplace transform: 1/s, 1/s\u00b2, etc. - For sinusoidal: show current frequency value - Annotation: Key feature of each signal (e.g., \"Instantaneous spike at t=0\" for impulse)</p> <p>Behavior: - When input type changes, plot updates smoothly - Impulse shown as tall narrow spike at t=0 (with note that it's theoretically infinite) - Step shows clean transition from 0 to 1 at t=0 - Ramp shows linear increase starting at t=0 - Parabolic shows curved increase (t\u00b2 shape) - Sinusoidal oscillates with adjustable frequency - Compare mode overlays scaled versions for shape comparison</p> <p>Instructional Rationale: Visual identification builds pattern recognition for test inputs that students will encounter throughout the course. Direct comparison helps distinguish similar-looking signals.</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/04-transient-response-specs/#the-step-input-and-unit-step-response","title":"The Step Input and Unit Step Response","text":"<p>The step input is the workhorse of control systems testing\u2014and for good reason. It represents an instantaneous change in setpoint or command, which is exactly what happens when you flip a switch, punch in a new temperature setting, or stomp on the gas pedal. It's mathematically simple (a jump from 0 to 1 at \\(t = 0\\)), yet it exercises the system's dynamics thoroughly.</p>"},{"location":"chapters/04-transient-response-specs/#the-unit-step-function","title":"The Unit Step Function","text":"<p>The unit step function \\(u(t)\\) is defined as:</p> <p>\\(u(t) = \\begin{cases} 0, &amp; t &lt; 0 \\\\ 1, &amp; t \\geq 0 \\end{cases}\\)</p> <p>In the Laplace domain:</p> <p>\\(\\mathcal{L}\\{u(t)\\} = \\frac{1}{s}\\)</p> <p>The unit step response is the system's output when a unit step is applied as the input, typically assuming zero initial conditions. This single response curve contains a wealth of information about system dynamics\u2014it's like a system's fingerprint.</p> <p>Why is the step response so popular?</p> <ul> <li>It tests both transient and steady-state behavior</li> <li>It's easy to apply experimentally (flip a switch!)</li> <li>The response directly reveals key performance metrics</li> <li>Most transient specifications are defined in terms of step response</li> </ul> <p>Practical Note</p> <p>In the real world, a \"perfect\" step is impossible\u2014every physical actuator has finite slew rate. But if the input transition is much faster than the system's response, it's effectively a step. And when testing real hardware, you'll often see engineers use a square wave and analyze the rising edges as repeated step inputs.</p>"},{"location":"chapters/04-transient-response-specs/#diagram-annotated-step-response-with-specifications","title":"Diagram: Annotated Step Response with Specifications","text":"Annotated Step Response with Specifications <p>Type: microsim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: interpret, explain</p> <p>Learning Objective: Students will explain how each transient specification (overshoot, settling time, rise time, peak time, delay time) is defined and measured from a step response curve.</p> <p>Canvas layout: - Left side (65%): Step response plot with annotations - Right side (35%): Specification values and definitions</p> <p>Visual elements: - Step response curve for second-order underdamped system - Horizontal dashed lines at: 0, 10%, 50%, 90%, 100% (final value), overshoot peak, \u00b12% settling bands - Vertical dashed lines at: delay time, rise time, peak time, settling time - Color-coded annotations linking lines to specification names - Final value clearly marked as y_ss - Input step shown as separate small plot or overlay</p> <p>Interactive controls: - Slider: Damping ratio \u03b6 from 0.1 to 1.0 (default: 0.5) - Slider: Natural frequency \u03c9n from 1 to 5 rad/s (default: 2) - Checkboxes: Show/hide each specification annotation - Button: \"Show All\" / \"Hide All\" toggle</p> <p>Data Visibility Requirements: - Display numerical values for each specification:   - Rise time: tr = [value] s   - Peak time: tp = [value] s   - Settling time (2%): ts = [value] s   - Delay time: td = [value] s   - Percent overshoot: %OS = [value]%   - Peak value: Mp = [value] - Show formulas relating specs to \u03b6 and \u03c9n</p> <p>Behavior: - Annotations update dynamically as \u03b6 and \u03c9n change - Hovering over an annotation highlights its definition in the side panel - Toggling checkboxes shows/hides individual annotations - Color coding consistent throughout (e.g., red for overshoot, blue for rise time)</p> <p>Instructional Rationale: Seeing all specifications on a single annotated plot clarifies what each metric measures. Interactive adjustment reveals how damping and frequency affect each specification differently.</p> <p>Implementation: p5.js with canvas-based controls and annotation rendering</p>"},{"location":"chapters/04-transient-response-specs/#overshoot-and-percent-overshoot","title":"Overshoot and Percent Overshoot","text":"<p>Overshoot is exactly what it sounds like: the system \"overshoots\" its target before settling down. For underdamped systems responding to a step input, the output exceeds the final steady-state value before oscillating back. It's like arriving at a stop sign and sliding a bit past it before backing up. (Please don't actually do this.)</p> <p>The percent overshoot (%OS) quantifies this behavior as a percentage of the final value:</p>"},{"location":"chapters/04-transient-response-specs/#percent-overshoot-formula","title":"Percent Overshoot Formula","text":"<p>\\(\\%OS = \\frac{M_p - y_{ss}}{y_{ss}} \\times 100\\%\\)</p> <p>where:</p> <ul> <li>\\(M_p\\) is the peak value (maximum overshoot)</li> <li>\\(y_{ss}\\) is the steady-state (final) value</li> </ul> <p>For a standard second-order underdamped system, percent overshoot depends only on the damping ratio:</p>"},{"location":"chapters/04-transient-response-specs/#percent-overshoot-vs-damping-ratio","title":"Percent Overshoot vs. Damping Ratio","text":"<p>\\(\\%OS = e^{-\\pi\\zeta/\\sqrt{1-\\zeta^2}} \\times 100\\%\\)</p> <p>where:</p> <ul> <li>\\(\\zeta\\) is the damping ratio (must be \\(0 &lt; \\zeta &lt; 1\\))</li> </ul> <p>This elegant formula reveals a key insight: percent overshoot is determined entirely by damping ratio, independent of natural frequency. A system with \\(\\zeta = 0.5\\) will have the same percent overshoot whether \\(\\omega_n\\) is 1 rad/s or 100 rad/s\u2014the oscillations will just happen faster in the latter case.</p> Damping Ratio \\(\\zeta\\) Percent Overshoot 0.1 72.9% 0.3 37.2% 0.5 16.3% 0.7 4.6% 0.9 0.2% 1.0 0% (critically damped) <p>The inverse relationship is also useful\u2014given a desired percent overshoot, you can calculate the required damping ratio:</p>"},{"location":"chapters/04-transient-response-specs/#required-damping-ratio-from-overshoot-spec","title":"Required Damping Ratio from Overshoot Spec","text":"<p>\\(\\zeta = \\frac{-\\ln(\\%OS/100)}{\\sqrt{\\pi^2 + \\ln^2(\\%OS/100)}}\\)</p> <p>where:</p> <ul> <li>\\(\\%OS\\) is the desired percent overshoot (as a percentage, e.g., 10 for 10%)</li> </ul> <p>Helping Gyra</p> <p>Overshoot is Gyra's \"overreaction coefficient.\" When she corrects a tilt, a high overshoot means she swings past vertical to the other side\u2014sometimes dramatically. With 50% overshoot, if she was tilted 10\u00b0 forward, she'd correct past vertical and end up 5\u00b0 backward before swinging back. That's alarming! With 5% overshoot, that 10\u00b0 forward tilt only produces a 0.5\u00b0 backward swing. Much calmer. Setting Gyra's overshoot specification is about choosing how dramatic we'll allow her corrections to be.</p>"},{"location":"chapters/04-transient-response-specs/#diagram-percent-overshoot-vs-damping-ratio","title":"Diagram: Percent Overshoot vs. Damping Ratio","text":"Percent Overshoot vs. Damping Ratio <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: calculate, use</p> <p>Learning Objective: Students will calculate damping ratio from a given percent overshoot specification and verify the relationship graphically.</p> <p>Canvas layout: - Left side (50%): Step response plot - Right side (50%): %OS vs. \u03b6 curve with current point highlighted</p> <p>Visual elements: Left plot: - Step response curve with overshoot clearly marked - Horizontal line at final value - Vertical measurement showing overshoot amount - Peak labeled with Mp value</p> <p>Right plot: - Exponential decay curve showing %OS vs. \u03b6 (from \u03b6=0 to \u03b6=1) - Current operating point marked with dot - Crosshairs or guidelines to axes - Axis labels: \"Damping Ratio \u03b6\" and \"Percent Overshoot %\"</p> <p>Interactive controls: - Slider: Damping ratio \u03b6 from 0.05 to 0.99 (default: 0.5) - Number input: Target %OS with \"Calculate \u03b6\" button - Toggle: Show formula overlay</p> <p>Data Visibility Requirements: - Display current \u03b6 value - Display calculated %OS for current \u03b6 - When target %OS entered, display required \u03b6 - Show the formula: %OS = exp(-\u03c0\u03b6/\u221a(1-\u03b6\u00b2)) \u00d7 100%</p> <p>Behavior: - Moving \u03b6 slider updates both plots simultaneously - Point on %OS curve moves along the curve as \u03b6 changes - Entering target %OS and clicking calculate: highlights required \u03b6 on curve and updates slider - Real-time calculation as slider moves</p> <p>Instructional Rationale: Dual visualization connects the abstract formula to concrete step response. Bidirectional calculation (\u03b6\u2192%OS and %OS\u2192\u03b6) reinforces practical design use.</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/04-transient-response-specs/#peak-time","title":"Peak Time","text":"<p>Peak time (\\(t_p\\)) is the time required for the response to reach its first (and largest) peak\u2014the moment of maximum overshoot. For underdamped systems, this is when the response hits \\(M_p\\) before beginning to oscillate back toward the final value.</p>"},{"location":"chapters/04-transient-response-specs/#peak-time-formula","title":"Peak Time Formula","text":"<p>\\(t_p = \\frac{\\pi}{\\omega_d} = \\frac{\\pi}{\\omega_n\\sqrt{1-\\zeta^2}}\\)</p> <p>where:</p> <ul> <li>\\(\\omega_d\\) is the damped frequency</li> <li>\\(\\omega_n\\) is the natural frequency</li> <li>\\(\\zeta\\) is the damping ratio</li> </ul> <p>Notice that peak time is one half-period of the damped oscillation frequency\u2014which makes physical sense. The response starts at zero, rises through the final value, and reaches its peak when it has completed half of its first oscillation cycle.</p> <p>Key observations about peak time:</p> <ul> <li>Peak time decreases as \\(\\omega_n\\) increases (faster systems peak sooner)</li> <li>Peak time increases as \\(\\zeta\\) increases (more damping slows the approach)</li> <li>Peak time is inversely proportional to \\(\\omega_d\\)</li> </ul> Parameter Change Effect on Peak Time Increase \\(\\omega_n\\) Decreases \\(t_p\\) Increase \\(\\zeta\\) Increases \\(t_p\\) Increase both equally Complex interaction <p>Critically and Overdamped Systems</p> <p>Peak time is undefined for critically damped (\\(\\zeta = 1\\)) and overdamped (\\(\\zeta &gt; 1\\)) systems because they don't overshoot\u2014they approach the final value monotonically. No overshoot means no peak beyond the final value to time.</p>"},{"location":"chapters/04-transient-response-specs/#rise-time","title":"Rise Time","text":"<p>Rise time (\\(t_r\\)) measures how quickly the response rises from a low value to a high value. There are two common definitions\u2014make sure you know which one is being used in any given context:</p> <ul> <li>10% to 90% definition (most common): Time to go from 10% to 90% of the final value</li> <li>0% to 100% definition: Time to first reach 100% of the final value</li> </ul> <p>The 10%-90% definition is preferred for practical measurements because it avoids sensitivity to initial transients (near 0%) and overshoot behavior (near 100%).</p> <p>For a second-order underdamped system, an approximate formula using the 10%-90% definition is:</p>"},{"location":"chapters/04-transient-response-specs/#rise-time-approximation-10-90","title":"Rise Time Approximation (10%-90%)","text":"<p>\\(t_r \\approx \\frac{1.8}{\\omega_n}\\)</p> <p>This approximation works well for damping ratios in the range \\(0.3 &lt; \\zeta &lt; 0.8\\), which covers most practical designs.</p> <p>A more accurate (but more complex) formula that accounts for damping ratio:</p>"},{"location":"chapters/04-transient-response-specs/#rise-time-formula-0-100","title":"Rise Time Formula (0%-100%)","text":"<p>\\(t_r = \\frac{1}{\\omega_d}\\left(\\pi - \\tan^{-1}\\frac{\\omega_d}{\\zeta\\omega_n}\\right)\\)</p> <p>where:</p> <ul> <li>\\(\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\) is the damped frequency</li> <li>The inverse tangent is in radians</li> </ul> <p>Rise time is particularly important for systems where rapid response to setpoint changes is critical\u2014think flight control systems, anti-lock brakes, or any application where \"getting there quickly\" matters.</p>"},{"location":"chapters/04-transient-response-specs/#delay-time","title":"Delay Time","text":"<p>Delay time (\\(t_d\\)) is the time required for the response to reach 50% of its final value. It provides a measure of how long the system \"hesitates\" before substantially responding to the input.</p> <p>For a second-order underdamped system, delay time can be approximated as:</p>"},{"location":"chapters/04-transient-response-specs/#delay-time-approximation","title":"Delay Time Approximation","text":"<p>\\(t_d \\approx \\frac{1 + 0.7\\zeta}{\\omega_n}\\)</p> <p>where:</p> <ul> <li>\\(\\omega_n\\) is the natural frequency</li> <li>\\(\\zeta\\) is the damping ratio</li> </ul> <p>Delay time is less commonly specified than rise time or settling time, but it's useful for characterizing the initial phase of system response. In some applications\u2014like human-machine interfaces\u2014perceived \"lag\" correlates strongly with delay time.</p> <p>The relationship between delay time and rise time is worth noting: for a typical underdamped system, \\(t_d\\) is roughly half of \\(t_r\\) (though the exact ratio depends on \\(\\zeta\\)).</p>"},{"location":"chapters/04-transient-response-specs/#settling-time","title":"Settling Time","text":"<p>Settling time (\\(t_s\\)) is the time required for the response to settle within a specified tolerance band around the final value and stay there. It's perhaps the most practically important specification because it tells you when the transient is \"done\" and the system has effectively reached steady state.</p> <p>Common tolerance bands are:</p> <ul> <li>2% settling time: Response stays within \\(\\pm 2\\%\\) of final value</li> <li>5% settling time: Response stays within \\(\\pm 5\\%\\) of final value</li> </ul>"},{"location":"chapters/04-transient-response-specs/#settling-time-formulas","title":"Settling Time Formulas","text":"<p>For 2% settling time:</p> <p>\\(t_s \\approx \\frac{4}{\\zeta\\omega_n}\\)</p> <p>For 5% settling time:</p> <p>\\(t_s \\approx \\frac{3}{\\zeta\\omega_n}\\)</p> <p>where:</p> <ul> <li>\\(\\zeta\\) is the damping ratio</li> <li>\\(\\omega_n\\) is the natural frequency</li> </ul> <p>These formulas arise from the exponential envelope \\(e^{-\\zeta\\omega_n t}\\) that bounds the oscillations. When this envelope decays to 2% (about 4 time constants) or 5% (about 3 time constants), the oscillations are within the tolerance band.</p> <p>Key insights about settling time:</p> <ul> <li>Settling time depends on the product \\(\\zeta\\omega_n\\) (the real part of the poles)</li> <li>Increasing \\(\\zeta\\) decreases settling time (more damping = faster decay)</li> <li>Increasing \\(\\omega_n\\) decreases settling time (faster overall dynamics)</li> <li>There's a trade-off with rise time: faster rise often means longer settling</li> </ul> Specification 2% Criterion 5% Criterion Number of time constants ~4 ~3 Settling time formula \\(4/(\\zeta\\omega_n)\\) \\(3/(\\zeta\\omega_n)\\) Residual error \u22642% \u22645% <p>The Settling Time Trap</p> <p>Be careful with lightly damped systems! If \\(\\zeta\\) is very small, the oscillations decay slowly even as the system initially responds quickly. You might have fast rise time but terrible settling time. This is why control design often involves trade-offs\u2014you can't optimize everything at once.</p> <p>Gyra Moment</p> <p>\"Settling time is my patience test. Sure, I might correct quickly when pushed\u2014but how long do I keep wobbling before I'm actually stable? A long settling time means I'm standing there oscillating like I can't make up my mind. Embarrassing. My engineers aim for settling time under a second\u2014because nobody wants to watch a robot wobble for five seconds wondering if it's going to fall over.\"</p>"},{"location":"chapters/04-transient-response-specs/#diagram-settling-time-and-tolerance-bands","title":"Diagram: Settling Time and Tolerance Bands","text":"Settling Time and Tolerance Bands <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: demonstrate, calculate</p> <p>Learning Objective: Students will determine settling time by identifying when the step response enters and remains within specified tolerance bands.</p> <p>Canvas layout: - Main area (70%): Step response with tolerance bands - Right panel (30%): Controls and settling time display</p> <p>Visual elements: - Step response curve - Shaded tolerance band around final value (2% or 5%) - Vertical line marking settling time - Exponential envelope curves (dashed) showing decay bound - Time axis with settling time marked - Horizontal line at final value</p> <p>Interactive controls: - Slider: Damping ratio \u03b6 from 0.2 to 1.0 (default: 0.5) - Slider: Natural frequency \u03c9n from 1 to 5 rad/s (default: 2) - Radio buttons: 2% or 5% tolerance band - Toggle: Show/hide exponential envelope</p> <p>Data Visibility Requirements: - Display settling time: ts = [value] s - Display formula used: ts = 4/(\u03b6\u03c9n) or ts = 3/(\u03b6\u03c9n) - Show tolerance band limits: \u00b1[2 or 5]% of final value - Display real part of poles: \u03c3 = \u03b6\u03c9n = [value]</p> <p>Behavior: - Tolerance band visually updates when switching between 2% and 5% - Settling time marker moves as \u03b6 or \u03c9n change - Envelope curves show why the formulas work (decay to tolerance level) - Highlight moment when response enters and stays in band</p> <p>Instructional Rationale: Visualizing tolerance bands demystifies the settling time definition. Connecting to the exponential envelope builds intuition for the formula derivation.</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/04-transient-response-specs/#the-impulse-input-and-impulse-response","title":"The Impulse Input and Impulse Response","text":"<p>The impulse input \\(\\delta(t)\\) is theoretically a signal of infinite amplitude and zero duration, with unit area\u2014a mathematical idealization that represents an instantaneous \"kick\" to the system. In the Laplace domain, it's beautifully simple:</p> <p>\\(\\mathcal{L}\\{\\delta(t)\\} = 1\\)</p> <p>This simplicity is precisely why the impulse is so important: the impulse response \\(h(t)\\) is the system output when the input is an impulse, and it equals the inverse Laplace transform of the transfer function itself:</p>"},{"location":"chapters/04-transient-response-specs/#impulse-response-relationship","title":"Impulse Response Relationship","text":"<p>\\(h(t) = \\mathcal{L}^{-1}\\{G(s)\\}\\)</p> <p>where:</p> <ul> <li>\\(h(t)\\) is the impulse response</li> <li>\\(G(s)\\) is the transfer function</li> </ul> <p>The impulse response reveals the system's natural dynamics directly\u2014it's the system's \"signature\" when excited and left alone. Every pole and zero of the transfer function manifests in the shape of \\(h(t)\\).</p> <p>For a first-order system with transfer function \\(G(s) = K/(\u03c4s + 1)\\):</p> <p>\\(h(t) = \\frac{K}{\\tau}e^{-t/\\tau}\\)</p> <p>For a second-order underdamped system:</p> <p>\\(h(t) = \\frac{\\omega_n}{\\sqrt{1-\\zeta^2}}e^{-\\zeta\\omega_n t}\\sin(\\omega_d t)\\)</p> <p>Practical Impulses</p> <p>A true impulse is impossible to generate physically, but we can approximate it with a short, sharp pulse. If the pulse duration is much shorter than the system's time constant, the response will closely match the theoretical impulse response. Striking a tuning fork, firing a spark plug, or tapping a microphone are all practical impulse-like excitations.</p> <p>The impulse response and step response are intimately related:</p>"},{"location":"chapters/04-transient-response-specs/#step-impulse-relationship","title":"Step-Impulse Relationship","text":"<p>\\(y_{step}(t) = \\int_0^t h(\\tau) d\\tau\\)</p> <p>and conversely:</p> <p>\\(h(t) = \\frac{d}{dt}y_{step}(t)\\)</p> <p>This relationship is crucial: if you can measure one, you can compute the other.</p>"},{"location":"chapters/04-transient-response-specs/#the-ramp-input-and-ramp-response","title":"The Ramp Input and Ramp Response","text":"<p>A ramp input increases linearly with time, representing a commanded velocity or a steadily changing setpoint:</p> <p>\\(r(t) = t \\cdot u(t)\\)</p> <p>In the Laplace domain:</p> <p>\\(\\mathcal{L}\\{t \\cdot u(t)\\} = \\frac{1}{s^2}\\)</p> <p>The ramp response reveals how well a system can track a constantly changing reference. This is critical for servo systems, motor drives, and any application where the system must follow a moving target.</p> <p>For a first-order system with DC gain \\(K\\) and time constant \\(\\tau\\):</p>"},{"location":"chapters/04-transient-response-specs/#first-order-ramp-response","title":"First-Order Ramp Response","text":"<p>\\(y(t) = K\\left(t - \\tau + \\tau e^{-t/\\tau}\\right)\\)</p> <p>As \\(t \\to \\infty\\), the response approaches:</p> <p>\\(y(t) \\approx K(t - \\tau)\\)</p> <p>This reveals a steady-state velocity error: the output tracks the ramp but lags behind by \\(K\\tau\\) seconds. The system is always \"behind\" the reference by a fixed amount. This lag is the velocity error that we'll explore more in the chapter on steady-state error.</p> <p>For second-order systems, the ramp response is more complex, but the key insight remains: systems with limited bandwidth cannot perfectly track a changing reference\u2014there will always be some lag.</p>"},{"location":"chapters/04-transient-response-specs/#the-parabolic-input","title":"The Parabolic Input","text":"<p>A parabolic input represents constant acceleration:</p> <p>\\(r(t) = \\frac{1}{2}t^2 \\cdot u(t)\\)</p> <p>In the Laplace domain:</p> <p>\\(\\mathcal{L}\\left\\{\\frac{1}{2}t^2 \\cdot u(t)\\right\\} = \\frac{1}{s^3}\\)</p> <p>Parabolic inputs test a system's ability to track accelerating references\u2014think of a missile interceptor tracking a maneuvering target, or a telescope tracking a celestial object with varying angular rate.</p> <p>The parabolic response reveals the acceleration error coefficient and becomes important when analyzing higher-order system types. Most basic control systems cannot track a parabolic input without growing error; this limitation motivates the design of higher-type controllers.</p>"},{"location":"chapters/04-transient-response-specs/#the-sinusoidal-input","title":"The Sinusoidal Input","text":"<p>The sinusoidal input is fundamentally different from the others\u2014it's a steady-state test signal rather than a transient one:</p> <p>\\(r(t) = A\\sin(\\omega t)\\)</p> <p>In the Laplace domain:</p> <p>\\(\\mathcal{L}\\{A\\sin(\\omega t)\\} = \\frac{A\\omega}{s^2 + \\omega^2}\\)</p> <p>When a sinusoidal input is applied to a stable linear system, the output eventually settles into a sinusoid at the same frequency but potentially with different amplitude and phase. This behavior is the foundation of frequency response analysis, which we'll explore in later chapters.</p> <p>Key properties of sinusoidal steady-state response:</p> <ul> <li>Output frequency equals input frequency (no frequency change for LTI systems)</li> <li>Amplitude ratio depends on \\(|G(j\\omega)|\\)</li> <li>Phase shift depends on \\(\\angle G(j\\omega)\\)</li> <li>Transients die out; sinusoidal pattern persists</li> </ul>"},{"location":"chapters/04-transient-response-specs/#diagram-test-input-response-comparison","title":"Diagram: Test Input Response Comparison","text":"Test Input Response Comparison <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: compare, differentiate</p> <p>Learning Objective: Students will compare how a given system responds differently to step, impulse, ramp, and sinusoidal inputs, identifying the distinct information revealed by each.</p> <p>Canvas layout: - Top row: Two plots side by side (input and output) - Bottom section: Controls and system parameters</p> <p>Visual elements: - Left plot: Selected input signal - Right plot: System response to that input - Clear axis labels with units - Legend identifying signal type</p> <p>Interactive controls: - Radio buttons: Select input type (Step, Impulse, Ramp, Sinusoidal) - Slider (for sinusoidal): Input frequency from 0.5 to 5 rad/s - Slider: System damping ratio \u03b6 from 0.3 to 0.9 - Slider: System natural frequency \u03c9n from 1 to 5 rad/s - Button: \"Animate\" - shows response evolving over time</p> <p>Data Visibility Requirements: - Display input type and parameters - Display system parameters (\u03b6, \u03c9n) - For step: show overshoot and settling time - For impulse: show peak value and decay - For ramp: show steady-state error - For sinusoidal: show amplitude ratio and phase shift</p> <p>Behavior: - Switching input type updates both plots - System parameters affect response shape but not input - Animation mode shows response building up over time - For sinusoidal, steady-state is reached after transients decay</p> <p>Instructional Rationale: Direct comparison of responses to different inputs reveals what each test signal uniquely probes. Students see that the same system behaves very differently depending on what you ask it to do.</p> <p>Implementation: p5.js with canvas-based controls</p>"},{"location":"chapters/04-transient-response-specs/#the-complete-picture-relating-specifications-to-design","title":"The Complete Picture: Relating Specifications to Design","text":"<p>Now that we've defined all the key specifications, let's see how they connect to form a coherent design framework. The beauty of second-order system analysis is that just two parameters\u2014\\(\\zeta\\) and \\(\\omega_n\\)\u2014determine all transient specifications.</p> Specification Formula Depends On Percent Overshoot \\(e^{-\\pi\\zeta/\\sqrt{1-\\zeta^2}} \\times 100\\%\\) \\(\\zeta\\) only Peak Time \\(\\pi/(\\omega_n\\sqrt{1-\\zeta^2})\\) \\(\\omega_n\\) and \\(\\zeta\\) Rise Time (approx) \\(1.8/\\omega_n\\) Primarily \\(\\omega_n\\) Settling Time (2%) \\(4/(\\zeta\\omega_n)\\) \\(\\zeta\\omega_n\\) product Delay Time (approx) \\((1 + 0.7\\zeta)/\\omega_n\\) \\(\\omega_n\\) and \\(\\zeta\\) <p>This table reveals important trade-offs:</p> <ul> <li>Overshoot vs. Settling Time: Lower \\(\\zeta\\) means more overshoot but can mean faster settling (if \\(\\omega_n\\) is high enough). It's complicated.</li> <li>Rise Time vs. Overshoot: Faster rise (higher \\(\\omega_n\\)) doesn't directly affect overshoot, but systems designed for very fast rise often end up underdamped.</li> <li>Speed vs. Stability: Aggressive designs (low \\(\\zeta\\), high \\(\\omega_n\\)) are fast but oscillatory; conservative designs are slow but smooth.</li> </ul> <p>The Magical Number 0.707</p> <p>The damping ratio \\(\\zeta = 1/\\sqrt{2} \\approx 0.707\\) is special. At this value, the second-order system achieves a good balance: about 4.3% overshoot with relatively fast settling. This is often called optimal damping or Butterworth damping and appears frequently in filter design and control specifications. When in doubt, 0.7 is a reasonable starting point.</p>"},{"location":"chapters/04-transient-response-specs/#diagram-specification-trade-off-explorer","title":"Diagram: Specification Trade-off Explorer","text":"Specification Trade-off Explorer <p>Type: microsim</p> <p>Bloom Taxonomy: Evaluate (L5) Bloom Verb: assess, judge</p> <p>Learning Objective: Students will assess the trade-offs between different transient specifications by observing how changing one specification affects others.</p> <p>Canvas layout: - Left (55%): Step response plot with all specifications annotated - Right (45%): Radar/spider chart showing normalized specifications plus controls</p> <p>Visual elements: Step response plot: - Response curve with overshoot, settling time, rise time marked - Tolerance bands - Peak time marker - All annotations color-coded</p> <p>Radar chart: - Five axes: Rise Time, Peak Time, Settling Time, %OS, Delay Time - Normalized values (smaller = better for time specs; smaller = better for overshoot) - Filled area showing current \"performance profile\" - Reference circle for comparison</p> <p>Interactive controls: - Slider: Damping ratio \u03b6 from 0.2 to 1.0 (default: 0.5) - Slider: Natural frequency \u03c9n from 1 to 5 rad/s (default: 2) - Preset buttons: \"Fast Response\", \"Low Overshoot\", \"Balanced (\u03b6=0.707)\" - Toggle: Lock overshoot at [value]% while adjusting \u03c9n</p> <p>Data Visibility Requirements: - Display all five specification values numerically - Show current \u03b6 and \u03c9n - Highlight which specs improve/worsen as parameters change - Display trade-off hints (e.g., \"Lower \u03b6: faster rise but more overshoot\")</p> <p>Behavior: - Moving sliders updates both plots in real-time - Radar chart shape changes to show trade-off profile - Preset buttons jump to specific parameter combinations - Lock mode demonstrates how specs can be adjusted independently (partially)</p> <p>Instructional Rationale: The radar chart visualization makes multi-objective trade-offs tangible. Students can \"see\" the shape of a design choice and understand why no single design optimizes everything.</p> <p>Implementation: p5.js with canvas-based radar chart and response plot</p>"},{"location":"chapters/04-transient-response-specs/#design-specifications-to-system-parameters","title":"Design Specifications to System Parameters","text":"<p>In practice, design often works backward: you're given specifications and must determine the system parameters that achieve them. Here's the systematic approach:</p> <p>Given: Desired %OS and settling time \\(t_s\\)</p> <p>Find: Required \\(\\zeta\\) and \\(\\omega_n\\)</p> <p>Step 1: From %OS, calculate required \\(\\zeta\\):</p> <p>\\(\\zeta = \\frac{-\\ln(\\%OS/100)}{\\sqrt{\\pi^2 + \\ln^2(\\%OS/100)}}\\)</p> <p>Step 2: From settling time and \\(\\zeta\\), calculate required \\(\\omega_n\\):</p> <p>\\(\\omega_n = \\frac{4}{\\zeta \\cdot t_s}\\) (for 2% criterion)</p> <p>Step 3: Verify other specifications are acceptable:</p> <ul> <li>Calculate \\(t_r\\), \\(t_p\\), \\(t_d\\) using formulas above</li> <li>Check that all specs meet requirements</li> </ul> <p>Design Example</p> <p>Requirement: %OS \u2264 10%, settling time (2%) \u2264 1 second</p> <p>Step 1: From 10% overshoot: \\(\\zeta = \\frac{-\\ln(0.10)}{\\sqrt{\\pi^2 + \\ln^2(0.10)}} = \\frac{2.303}{\\sqrt{9.87 + 5.30}} = 0.591\\)</p> <p>Step 2: From \\(t_s = 1\\) second: \\(\\omega_n = \\frac{4}{0.591 \\times 1} = 6.77\\) rad/s</p> <p>Step 3: Verify rise time: \\(t_r \\approx \\frac{1.8}{6.77} = 0.27\\) seconds (acceptable)</p> <p>This design methodology is the bread and butter of control engineering. Given performance requirements, you can immediately determine what pole locations are needed\u2014which then informs your controller design.</p>"},{"location":"chapters/04-transient-response-specs/#practical-measurement-considerations","title":"Practical Measurement Considerations","text":"<p>In the laboratory or in the field, measuring transient specifications from real data requires some care. Here are practical considerations:</p> <p>Noise and Ripple: Real signals are noisy. Settling time measurements are particularly sensitive\u2014a noisy signal may repeatedly exit and re-enter the tolerance band. Filtering or averaging may be needed.</p> <p>Initial Conditions: For valid step response measurements, ensure the system starts at true steady state. Any residual dynamics from previous tests will contaminate results.</p> <p>Input Fidelity: Real step inputs have finite rise time. If the input transition time is comparable to the system's rise time, your measurements will be affected. Use the fastest actuator available.</p> <p>Sampling Rate: For accurate peak time and overshoot measurements, sample fast enough to capture the peak. A rule of thumb: sample at least 10\u00d7 the expected oscillation frequency.</p> <p>Steady-State Identification: Settling time requires knowing the final value. In practice, wait several settling times and average the output, or use the DC gain if known.</p> Challenge Mitigation Strategy Noise obscuring peaks Low-pass filter before analysis Slow input rise Use faster actuator or deconvolve Non-zero initial conditions Wait for true steady state before test Unknown final value Estimate from long-time average"},{"location":"chapters/04-transient-response-specs/#summary-and-key-takeaways","title":"Summary and Key Takeaways","text":"<p>You've now mastered the vocabulary and mathematics of transient response specifications\u2014the quantitative tools that turn qualitative observations into engineering requirements.</p> <p>Standard Test Inputs provide benchmarks for system evaluation:</p> <ul> <li>Step input: workhorse of transient testing, reveals tracking and overshoot</li> <li>Impulse input: reveals natural dynamics directly</li> <li>Ramp input: tests velocity tracking capability</li> <li>Parabolic input: tests acceleration tracking</li> <li>Sinusoidal input: foundation of frequency response analysis</li> </ul> <p>Transient Specifications quantify step response behavior:</p> <ul> <li>Percent Overshoot: How far past the target? Determined by \\(\\zeta\\) alone.</li> <li>Peak Time: When does max overshoot occur? Depends on \\(\\omega_d\\).</li> <li>Rise Time: How fast to get there? Roughly \\(1.8/\\omega_n\\).</li> <li>Settling Time: When is the drama over? Approximately \\(4/(\\zeta\\omega_n)\\) for 2%.</li> <li>Delay Time: Initial responsiveness. About \\((1+0.7\\zeta)/\\omega_n\\).</li> </ul> <p>Key Relationships:</p> <ul> <li>Only two parameters (\\(\\zeta\\), \\(\\omega_n\\)) determine all second-order specs</li> <li>Trade-offs are unavoidable: you can't optimize everything simultaneously</li> <li>\\(\\zeta \\approx 0.7\\) often provides a good balance</li> <li>Design works backward: specs \u2192 \\(\\zeta\\) and \\(\\omega_n\\) \u2192 pole placement</li> </ul> <p>Gyra's Design Summary</p> <p>\"My engineers don't say 'make me stable.' They say: 'percent overshoot under 5%, settling time under 0.8 seconds, rise time under 0.3 seconds.' Now those are specs I can work with. And when I meet them? That's when I know I'm properly tuned.\"</p> <p>In the next chapter, we'll explore what happens when the transient is over\u2014steady-state behavior and the errors that persist even after all the oscillations have died away. Because getting close to your target isn't the same as getting exactly there.</p> Self-Check: Test Your Understanding <p>Before moving on, see if you can answer these:</p> <ol> <li>A system has 20% overshoot. What is its approximate damping ratio?</li> <li>If you double \\(\\omega_n\\) while keeping \\(\\zeta\\) constant, what happens to: (a) percent overshoot, (b) settling time, (c) rise time?</li> <li>Two systems have the same settling time but different overshoot. Which has higher \\(\\omega_n\\)\u2014the one with more overshoot or less? (Think carefully!)</li> <li>You measure a step response and see that the output first reaches the final value at \\(t = 0.5\\) seconds, then overshoots to 110% of final at \\(t = 0.8\\) seconds. Estimate the damping ratio and natural frequency.</li> </ol> <p>Work through these before checking your answers with the MicroSims!</p>"},{"location":"chapters/05-laplace-transform-methods/","title":"Laplace Transform Methods","text":""},{"location":"chapters/05-laplace-transform-methods/#summary","title":"Summary","text":"<p>This chapter introduces the Laplace transform as a powerful tool for analyzing control systems. Students will learn to transform differential equations into algebraic equations in the s-domain, work with transfer functions, and use inverse Laplace transforms to find time-domain solutions. Key techniques including partial fraction expansion, residue calculation, and the cover-up method are developed. The initial and final value theorems provide shortcuts for determining system behavior without complete inverse transformation.</p>"},{"location":"chapters/05-laplace-transform-methods/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 13 concepts from the learning graph:</p> <ol> <li>Transfer Function</li> <li>Laplace Transform</li> <li>Inverse Laplace Transform</li> <li>S-Domain</li> <li>Time Domain</li> <li>Frequency Domain</li> <li>Initial Value Theorem</li> <li>Final Value Theorem</li> <li>Partial Fraction Expansion</li> <li>Residue Calculation</li> <li>Cover-Up Method</li> <li>Convolution Integral</li> <li>Convolution in S-Domain</li> </ol>"},{"location":"chapters/05-laplace-transform-methods/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 2: Dynamic System Properties</li> <li>Chapter 3: Time-Domain Response Fundamentals</li> <li>Chapter 4: Transient Response Specifications</li> </ul>"},{"location":"chapters/05-laplace-transform-methods/#why-we-need-the-laplace-transform","title":"Why We Need the Laplace Transform","text":"<p>Differential equations are the natural language of dynamic systems\u2014but solving them directly can be tedious, error-prone, and offers limited insight into system behavior. The Laplace transform provides an elegant escape route: it converts differential equations into algebraic equations, which are far easier to manipulate. Think of it as a translation device that takes us from a difficult problem domain to an easier one, lets us solve the problem there, and then translates the answer back.</p> <p>Here's the magic: differentiation in the time domain becomes multiplication in the s-domain. Integration becomes division. Convolution\u2014that nasty integral you might remember from signals and systems\u2014becomes simple multiplication. This isn't just a mathematical trick; it's a conceptual framework that reveals the fundamental structure of linear systems.</p> <p>For control engineers, the Laplace transform is indispensable. It gives us the transfer function, which encapsulates everything about how a system responds to inputs. It enables us to analyze stability, predict transient behavior, and design controllers\u2014all without solving a single differential equation the hard way. If you master the techniques in this chapter, you'll have a toolkit that applies to virtually any linear time-invariant system you'll encounter.</p>"},{"location":"chapters/05-laplace-transform-methods/#the-time-domain","title":"The Time Domain","text":"<p>The time domain is where we live and where physical systems operate. When you watch Gyra wobble after being pushed, you're observing time-domain behavior. Variables in the time domain are functions of time \\(t\\), typically denoted as \\(f(t)\\), \\(x(t)\\), or \\(y(t)\\).</p> <p>In the time domain, we describe systems using differential equations. For a simple mass-spring-damper:</p>"},{"location":"chapters/05-laplace-transform-methods/#mass-spring-damper-differential-equation","title":"Mass-Spring-Damper Differential Equation","text":"<p>\\(m\\frac{d^2x}{dt^2} + b\\frac{dx}{dt} + kx = F(t)\\)</p> <p>where:</p> <ul> <li>\\(m\\) is the mass</li> <li>\\(b\\) is the damping coefficient</li> <li>\\(k\\) is the spring constant</li> <li>\\(x(t)\\) is the displacement</li> <li>\\(F(t)\\) is the applied force</li> </ul> <p>Time-domain analysis is intuitive\u2014you can directly observe cause and effect as time progresses. But solving these equations, especially for higher-order systems or complicated inputs, requires significant mathematical effort. And crucially, time-domain equations don't immediately reveal system properties like stability, natural frequency, or damping ratio.</p> Time Domain Characteristics Description Independent variable Time \\(t\\), typically \\(t \\geq 0\\) Signal representation \\(f(t)\\), real-valued functions System description Differential equations Key operations Differentiation, integration, convolution Intuition Direct physical interpretation"},{"location":"chapters/05-laplace-transform-methods/#the-s-domain","title":"The S-Domain","text":"<p>The s-domain (or complex frequency domain) is where the Laplace transform takes us. Here, the independent variable is \\(s\\), a complex number with real and imaginary parts: \\(s = \\sigma + j\\omega\\). Functions in the s-domain are denoted with capital letters: \\(F(s)\\), \\(X(s)\\), \\(Y(s)\\).</p> <p>In the s-domain, differential equations become algebraic equations. The mass-spring-damper equation transforms to:</p>"},{"location":"chapters/05-laplace-transform-methods/#mass-spring-damper-in-s-domain","title":"Mass-Spring-Damper in S-Domain","text":"<p>\\((ms^2 + bs + k)X(s) = F(s) + \\text{initial conditions}\\)</p> <p>where:</p> <ul> <li>\\(X(s)\\) is the Laplace transform of \\(x(t)\\)</li> <li>\\(F(s)\\) is the Laplace transform of the input force</li> <li>The polynomial \\((ms^2 + bs + k)\\) captures the system dynamics</li> </ul> <p>This is just algebra! No derivatives to deal with. The price we pay is working with complex numbers and polynomials\u2014but that's a trade most engineers are happy to make.</p> <p>The s-domain reveals system structure. The roots of the denominator polynomial (poles) tell us about stability and response characteristics. The relationship between input and output transforms gives us the transfer function. This representation is the foundation of classical control theory.</p> <p>S-Domain vs. Time Domain</p> <p>Think of the s-domain as a control room with dials and displays that show you what kind of behavior a system can exhibit. The time domain is the actual room where the system operates. Engineers work in the s-domain to design systems, then verify their designs by simulating or observing time-domain behavior.</p>"},{"location":"chapters/05-laplace-transform-methods/#the-frequency-domain","title":"The Frequency Domain","text":"<p>The frequency domain is closely related to the s-domain but focuses specifically on sinusoidal steady-state behavior. When we evaluate the transfer function at \\(s = j\\omega\\) (purely imaginary), we're asking: \"How does this system respond to a sinusoid of frequency \\(\\omega\\)?\"</p> <p>The frequency domain is particularly useful for:</p> <ul> <li>Analyzing steady-state response to periodic inputs</li> <li>Understanding system behavior across a range of frequencies</li> <li>Designing filters and compensators</li> <li>Assessing stability margins (gain and phase margins)</li> </ul> <p>We'll explore frequency-domain analysis in detail in later chapters with Bode plots and Nyquist diagrams. For now, understand that the s-domain is the general framework, and the frequency domain is the special case where \\(s = j\\omega\\).</p> Domain Variable Focus Primary Use Time \\(t\\) Transient + steady-state Simulation, observation S-Domain \\(s = \\sigma + j\\omega\\) Complete system behavior Analysis, design Frequency \\(j\\omega\\) Sinusoidal steady-state Filter design, stability margins"},{"location":"chapters/05-laplace-transform-methods/#the-laplace-transform","title":"The Laplace Transform","text":"<p>The Laplace transform converts a time-domain function \\(f(t)\\) into an s-domain function \\(F(s)\\). The definition is:</p>"},{"location":"chapters/05-laplace-transform-methods/#laplace-transform-definition","title":"Laplace Transform Definition","text":"<p>\\(F(s) = \\mathcal{L}\\{f(t)\\} = \\int_0^{\\infty} f(t)e^{-st}dt\\)</p> <p>where:</p> <ul> <li>\\(f(t)\\) is the original time-domain function (defined for \\(t \\geq 0\\))</li> <li>\\(F(s)\\) is the Laplace transform</li> <li>\\(s\\) is the complex frequency variable</li> <li>\\(\\mathcal{L}\\{\\cdot\\}\\) denotes the Laplace transform operator</li> </ul> <p>The integral essentially \"weighs\" \\(f(t)\\) against decaying exponentials \\(e^{-st}\\) for all values of \\(s\\). Functions that grow too fast (faster than any exponential) don't have Laplace transforms, but all physically realizable signals do.</p> <p>You rarely need to compute this integral directly. Instead, you'll use a table of transform pairs and properties. Here are the essential ones:</p> Time Function \\(f(t)\\) Laplace Transform \\(F(s)\\) Unit impulse \\(\\delta(t)\\) \\(1\\) Unit step \\(u(t)\\) \\(\\frac{1}{s}\\) Ramp \\(t\\) \\(\\frac{1}{s^2}\\) Exponential \\(e^{-at}\\) \\(\\frac{1}{s+a}\\) Sine \\(\\sin(\\omega t)\\) \\(\\frac{\\omega}{s^2+\\omega^2}\\) Cosine \\(\\cos(\\omega t)\\) \\(\\frac{s}{s^2+\\omega^2}\\) Damped exponential \\(te^{-at}\\) \\(\\frac{1}{(s+a)^2}\\) Damped sine \\(e^{-at}\\sin(\\omega t)\\) \\(\\frac{\\omega}{(s+a)^2+\\omega^2}\\) <p>The key properties that make the Laplace transform so useful:</p> Property Time Domain S-Domain Linearity \\(af(t) + bg(t)\\) \\(aF(s) + bG(s)\\) Differentiation \\(\\frac{df}{dt}\\) \\(sF(s) - f(0^-)\\) Integration \\(\\int_0^t f(\\tau)d\\tau\\) \\(\\frac{F(s)}{s}\\) Time shift \\(f(t-a)u(t-a)\\) \\(e^{-as}F(s)\\) Frequency shift \\(e^{-at}f(t)\\) \\(F(s+a)\\) Convolution \\(f(t)*g(t)\\) \\(F(s)G(s)\\) <p>Gyra Moment</p> <p>\"When my engineers write my differential equation of motion, it's a tangled mess of derivatives. But when they take the Laplace transform, suddenly everything becomes clear\u2014my dynamics become a transfer function, a simple ratio of polynomials. They can literally see where my poles are and predict whether I'll oscillate or settle smoothly. The s-domain is where they understand me best.\"</p>"},{"location":"chapters/05-laplace-transform-methods/#diagram-laplace-transform-visualization","title":"Diagram: Laplace Transform Visualization","text":"Laplace Transform Visualization <p>Type: microsim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: interpret, explain</p> <p>Learning Objective: Students will interpret the relationship between common time-domain signals and their Laplace transform representations.</p> <p>Canvas layout: - Left side (50%): Time domain plot showing f(t) - Right side (50%): S-domain representation showing F(s) as pole-zero plot</p> <p>Visual elements: Time Domain Plot: - X-axis: time t (0 to 5 seconds) - Y-axis: amplitude - Signal curve (blue line) - Grid lines</p> <p>S-Domain Plot: - Complex s-plane with real (\u03c3) and imaginary (j\u03c9) axes - Poles marked with X - Zeros marked with O - Unit circle for reference</p> <p>Interactive controls: - Dropdown: Select signal type (unit step, ramp, exponential, sine, damped sine, damped exponential) - Slider: Parameter a (for exponential decay rate, 0.1 to 5) - Slider: Parameter \u03c9 (for frequency, 0.5 to 10 rad/s) - Button: Reset</p> <p>Data Visibility Requirements: - Display f(t) equation - Display F(s) equation - Show pole locations numerically - Show zero locations if present</p> <p>Behavior: - When signal type changes, both plots update - When parameters change, time response and pole locations update - Poles move on s-plane as parameters change - Time domain shows corresponding waveform</p> <p>Instructional Rationale: Side-by-side visualization of time and s-domain representations builds intuition for the transform relationship. Students see how parameter changes affect both representations simultaneously.</p> <p>Implementation: p5.js with dual canvas areas</p>"},{"location":"chapters/05-laplace-transform-methods/#the-transfer-function","title":"The Transfer Function","text":"<p>The transfer function is the crown jewel of classical control theory. It completely characterizes a linear time-invariant (LTI) system's input-output relationship in the s-domain, assuming zero initial conditions.</p>"},{"location":"chapters/05-laplace-transform-methods/#transfer-function-definition","title":"Transfer Function Definition","text":"<p>\\(G(s) = \\frac{Y(s)}{U(s)}\\)</p> <p>where:</p> <ul> <li>\\(G(s)\\) is the transfer function</li> <li>\\(Y(s)\\) is the Laplace transform of the output</li> <li>\\(U(s)\\) is the Laplace transform of the input</li> </ul> <p>For a system described by the differential equation:</p> <p>\\(a_n\\frac{d^ny}{dt^n} + \\cdots + a_1\\frac{dy}{dt} + a_0y = b_m\\frac{d^mu}{dt^m} + \\cdots + b_1\\frac{du}{dt} + b_0u\\)</p> <p>The transfer function is:</p>"},{"location":"chapters/05-laplace-transform-methods/#general-transfer-function-form","title":"General Transfer Function Form","text":"<p>\\(G(s) = \\frac{b_ms^m + b_{m-1}s^{m-1} + \\cdots + b_1s + b_0}{a_ns^n + a_{n-1}s^{n-1} + \\cdots + a_1s + a_0}\\)</p> <p>The denominator polynomial determines system stability and dynamics. Its roots are the poles. The numerator polynomial affects how inputs couple to the system. Its roots are the zeros.</p> <p>For example, a simple first-order system with time constant \\(\\tau\\) has transfer function:</p>"},{"location":"chapters/05-laplace-transform-methods/#first-order-transfer-function","title":"First-Order Transfer Function","text":"<p>\\(G(s) = \\frac{K}{\\tau s + 1}\\)</p> <p>where:</p> <ul> <li>\\(K\\) is the DC gain</li> <li>\\(\\tau\\) is the time constant</li> <li>The pole is at \\(s = -1/\\tau\\)</li> </ul> <p>For a second-order system:</p>"},{"location":"chapters/05-laplace-transform-methods/#second-order-transfer-function","title":"Second-Order Transfer Function","text":"<p>\\(G(s) = \\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2}\\)</p> <p>where:</p> <ul> <li>\\(\\omega_n\\) is the natural frequency</li> <li>\\(\\zeta\\) is the damping ratio</li> <li>The poles are at \\(s = -\\zeta\\omega_n \\pm j\\omega_n\\sqrt{1-\\zeta^2}\\)</li> </ul> <p>The transfer function enables us to find the output for any input through multiplication:</p> <p>\\(Y(s) = G(s) \\cdot U(s)\\)</p> <p>This simple relationship is why control engineers live in the s-domain.</p> <p>Zero Initial Conditions</p> <p>The transfer function assumes the system starts at rest (zero initial conditions). When initial conditions are non-zero, additional terms appear in the s-domain equation. For controller design, we typically work with transfer functions and handle initial conditions separately.</p>"},{"location":"chapters/05-laplace-transform-methods/#the-inverse-laplace-transform","title":"The Inverse Laplace Transform","text":"<p>Finding the output in the s-domain is easy\u2014just multiply. But to know what actually happens over time, we need to transform back. The inverse Laplace transform converts \\(F(s)\\) back to \\(f(t)\\):</p>"},{"location":"chapters/05-laplace-transform-methods/#inverse-laplace-transform","title":"Inverse Laplace Transform","text":"<p>\\(f(t) = \\mathcal{L}^{-1}\\{F(s)\\}\\)</p> <p>The formal definition involves a complex contour integral, but in practice, we use tables and algebraic techniques. The key is to decompose complex s-domain expressions into simpler terms that match table entries.</p> <p>The most important technique is partial fraction expansion: breaking a ratio of polynomials into a sum of simpler fractions, each of which has a known inverse transform.</p> <p>For example, if:</p> <p>\\(F(s) = \\frac{3s + 5}{(s+1)(s+2)}\\)</p> <p>We can write:</p> <p>\\(F(s) = \\frac{A}{s+1} + \\frac{B}{s+2}\\)</p> <p>Finding \\(A\\) and \\(B\\), then inverting each term separately using the table:</p> <p>\\(f(t) = Ae^{-t} + Be^{-2t}\\)</p> <p>The next sections develop this technique in detail.</p>"},{"location":"chapters/05-laplace-transform-methods/#diagram-domain-transformation-workflow","title":"Diagram: Domain Transformation Workflow","text":"Domain Transformation Workflow <p>Type: workflow</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: explain, summarize</p> <p>Learning Objective: Students will explain the workflow of using Laplace transforms to solve differential equations.</p> <p>Purpose: Illustrate the three-step process of transform, solve, inverse transform</p> <p>Visual style: Horizontal workflow with three main blocks and arrows</p> <p>Steps: 1. Block: \"Time Domain Problem\"    - Contains: Differential equation + Initial conditions    - Color: Blue    - Hover text: \"Start with the physical system's differential equation\"</p> <ol> <li>Arrow: \"Laplace Transform\"</li> <li>Label: \"Differentiation \u2192 Multiplication\"</li> <li> <p>Hover text: \"Apply Laplace transform to convert derivatives to algebraic terms\"</p> </li> <li> <p>Block: \"S-Domain Problem\"</p> </li> <li>Contains: Algebraic equation in s</li> <li>Color: Green</li> <li> <p>Hover text: \"Now we have algebra, not calculus\"</p> </li> <li> <p>Arrow: \"Algebraic Solution\"</p> </li> <li>Label: \"Solve for Y(s)\"</li> <li> <p>Hover text: \"Use algebra to isolate the output transform\"</p> </li> <li> <p>Block: \"S-Domain Solution\"</p> </li> <li>Contains: Y(s) = expression</li> <li>Color: Green</li> <li> <p>Hover text: \"The output in the s-domain\"</p> </li> <li> <p>Arrow: \"Inverse Laplace Transform\"</p> </li> <li>Label: \"Partial fractions + Tables\"</li> <li> <p>Hover text: \"Convert back to time domain using known transform pairs\"</p> </li> <li> <p>Block: \"Time Domain Solution\"</p> </li> <li>Contains: y(t) = expression</li> <li>Color: Blue</li> <li>Hover text: \"The actual time behavior we wanted\"</li> </ol> <p>Interactive elements: - Hover over each block/arrow for detailed description - Click to see example at each stage</p> <p>Color coding: - Blue: Time domain - Green: S-domain - Arrows: Gray with black labels</p> <p>Implementation: HTML/CSS/JavaScript with SVG workflow</p>"},{"location":"chapters/05-laplace-transform-methods/#partial-fraction-expansion","title":"Partial Fraction Expansion","text":"<p>Partial fraction expansion (also called partial fraction decomposition) is the workhorse technique for inverse Laplace transforms. It breaks a complicated ratio of polynomials into a sum of simpler terms, each corresponding to a known transform pair.</p> <p>Given a proper rational function (numerator degree less than denominator degree):</p> <p>\\(F(s) = \\frac{N(s)}{D(s)}\\)</p> <p>We factor the denominator and express \\(F(s)\\) as a sum of simpler fractions.</p>"},{"location":"chapters/05-laplace-transform-methods/#case-1-distinct-real-poles","title":"Case 1: Distinct Real Poles","text":"<p>When the denominator has distinct real roots (simple poles):</p> <p>\\(F(s) = \\frac{N(s)}{(s+p_1)(s+p_2)\\cdots(s+p_n)} = \\frac{A_1}{s+p_1} + \\frac{A_2}{s+p_2} + \\cdots + \\frac{A_n}{s+p_n}\\)</p> <p>Each term inverts to an exponential: \\(\\mathcal{L}^{-1}\\{\\frac{A_k}{s+p_k}\\} = A_ke^{-p_kt}\\)</p>"},{"location":"chapters/05-laplace-transform-methods/#case-2-repeated-real-poles","title":"Case 2: Repeated Real Poles","text":"<p>When a pole is repeated \\(r\\) times:</p> <p>\\(F(s) = \\frac{N(s)}{(s+p)^r} = \\frac{A_1}{s+p} + \\frac{A_2}{(s+p)^2} + \\cdots + \\frac{A_r}{(s+p)^r}\\)</p> <p>These terms invert to terms involving \\(t^ke^{-pt}\\).</p>"},{"location":"chapters/05-laplace-transform-methods/#case-3-complex-conjugate-poles","title":"Case 3: Complex Conjugate Poles","text":"<p>When the denominator has complex roots (always in conjugate pairs for real systems):</p> <p>\\(F(s) = \\frac{N(s)}{(s+\\alpha)^2+\\omega^2}\\)</p> <p>This inverts to damped sinusoids: \\(e^{-\\alpha t}(A\\cos\\omega t + B\\sin\\omega t)\\)</p> Pole Type Partial Fraction Term Inverse Transform Simple real at \\(-p\\) \\(\\frac{A}{s+p}\\) \\(Ae^{-pt}\\) Repeated real (order 2) \\(\\frac{A}{(s+p)^2}\\) \\(Ate^{-pt}\\) Complex pair at \\(-\\alpha \\pm j\\omega\\) \\(\\frac{As+B}{(s+\\alpha)^2+\\omega^2}\\) \\(e^{-\\alpha t}(C\\cos\\omega t + D\\sin\\omega t)\\) <p>Example: Partial Fraction Expansion</p> <p>Find the inverse Laplace transform of:</p> <p>\\(F(s) = \\frac{2s + 10}{(s+1)(s+3)}\\)</p> <p>Expand into partial fractions:</p> <p>\\(F(s) = \\frac{A}{s+1} + \\frac{B}{s+3}\\)</p> <p>Solving: \\(A = 4\\), \\(B = -2\\)</p> <p>Therefore:</p> <p>\\(f(t) = 4e^{-t} - 2e^{-3t}\\)</p>"},{"location":"chapters/05-laplace-transform-methods/#residue-calculation","title":"Residue Calculation","text":"<p>The residues are the numerator coefficients \\(A_k\\) in the partial fraction expansion. Calculating them is straightforward for simple poles and requires more care for repeated or complex poles.</p>"},{"location":"chapters/05-laplace-transform-methods/#for-simple-poles","title":"For Simple Poles","text":"<p>For a simple pole at \\(s = -p_k\\):</p>"},{"location":"chapters/05-laplace-transform-methods/#residue-formula-for-simple-poles","title":"Residue Formula for Simple Poles","text":"<p>\\(A_k = \\lim_{s \\to -p_k} (s + p_k)F(s)\\)</p> <p>This \"multiplies away\" the factor \\((s + p_k)\\) from the denominator and evaluates what remains at the pole location.</p>"},{"location":"chapters/05-laplace-transform-methods/#for-repeated-poles","title":"For Repeated Poles","text":"<p>For a pole of order \\(r\\) at \\(s = -p\\), the residues are:</p>"},{"location":"chapters/05-laplace-transform-methods/#residue-formula-for-repeated-poles","title":"Residue Formula for Repeated Poles","text":"<p>\\(A_k = \\frac{1}{(r-k)!}\\lim_{s \\to -p}\\frac{d^{r-k}}{ds^{r-k}}[(s+p)^rF(s)]\\)</p> <p>where:</p> <ul> <li>\\(k\\) ranges from 1 to \\(r\\)</li> <li>\\(A_r\\) (the highest-order term) is found without differentiation</li> <li>Lower-order terms require successive derivatives</li> </ul>"},{"location":"chapters/05-laplace-transform-methods/#for-complex-poles","title":"For Complex Poles","text":"<p>For complex conjugate poles, we can either:</p> <ol> <li>Treat them as two complex simple poles and use the residue formula (result will be complex)</li> <li>Keep them as a quadratic factor and match coefficients</li> </ol> <p>Option 2 is usually easier for hand calculations and leads directly to real-valued expressions.</p> <p>Practical Approach for Complex Poles</p> <p>Rather than computing complex residues, write the partial fraction with a quadratic denominator:</p> <p>\\(\\frac{As + B}{s^2 + 2\\alpha s + (\\alpha^2 + \\omega^2)}\\)</p> <p>Then complete the square and use standard transform pairs for damped sinusoids.</p>"},{"location":"chapters/05-laplace-transform-methods/#the-cover-up-method","title":"The Cover-Up Method","text":"<p>The cover-up method (also known as Heaviside's method) provides a quick shortcut for finding residues of simple poles. It's faster than the formal residue formula for hand calculations.</p> <p>To find the residue \\(A_k\\) for a simple pole at \\(s = -p_k\\):</p> <ol> <li>\"Cover up\" the factor \\((s + p_k)\\) in the denominator with your thumb</li> <li>Evaluate what remains at \\(s = -p_k\\)</li> <li>The result is \\(A_k\\)</li> </ol>"},{"location":"chapters/05-laplace-transform-methods/#cover-up-method-example","title":"Cover-Up Method Example","text":"<p>For \\(F(s) = \\frac{2s + 10}{(s+1)(s+3)}\\):</p> <p>To find \\(A\\) (residue at \\(s = -1\\)): - Cover up \\((s+1)\\): \\(\\frac{2s + 10}{(s+3)}\\) - Evaluate at \\(s = -1\\): \\(\\frac{2(-1) + 10}{(-1+3)} = \\frac{8}{2} = 4\\)</p> <p>To find \\(B\\) (residue at \\(s = -3\\)): - Cover up \\((s+3)\\): \\(\\frac{2s + 10}{(s+1)}\\) - Evaluate at \\(s = -3\\): \\(\\frac{2(-3) + 10}{(-3+1)} = \\frac{4}{-2} = -2\\)</p> <p>The cover-up method is particularly efficient when you have many simple poles. Just work through each one mechanically: cover, substitute, evaluate.</p> <p>Limitation</p> <p>The cover-up method only works for simple (non-repeated) poles. For repeated poles, you must use the formal residue calculation with derivatives.</p>"},{"location":"chapters/05-laplace-transform-methods/#diagram-partial-fraction-step-through","title":"Diagram: Partial Fraction Step-Through","text":"Partial Fraction Step-Through <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: calculate, solve</p> <p>Learning Objective: Students will apply partial fraction expansion and the cover-up method to find inverse Laplace transforms step by step.</p> <p>Canvas layout: - Top (30%): Problem display showing F(s) - Middle (50%): Step-by-step working area - Bottom (20%): Controls and result</p> <p>Visual elements: Problem Display: - Original F(s) expression clearly formatted - Factored denominator shown</p> <p>Working Area: - Step-by-step panels that reveal one at a time - Highlighted \"covered\" terms during cover-up method - Intermediate calculations visible - Final partial fraction form - Inverse transform result</p> <p>Interactive controls: - Dropdown: Select example problem (3-4 different cases) - Button: \"Next Step\" to advance through solution - Button: \"Previous Step\" to go back - Button: \"Show All Steps\" to reveal complete solution - Button: \"New Problem\" to generate fresh example</p> <p>Data Visibility Requirements: Stage 1: Show original F(s) and ask \"What are the poles?\" Stage 2: Show factored denominator with poles labeled Stage 3: Show partial fraction template with unknown coefficients Stage 4: Demonstrate cover-up for first coefficient (highlight covered term) Stage 5: Show calculation and result for first coefficient Stage 6-7: Repeat for remaining coefficients Stage 8: Show complete partial fraction expansion Stage 9: Show inverse transform of each term Stage 10: Show final time-domain answer</p> <p>Behavior: - Each step reveals only when student advances - Cover-up visualization shows term being \"covered\" - Calculations are shown explicitly - Color coding: covered term in gray, result highlighted - Option to skip ahead or go back</p> <p>Instructional Rationale: Step-through with explicit data at each stage supports procedural learning. Students can pause to verify understanding before advancing. The cover-up visualization makes the technique tangible.</p> <p>Implementation: p5.js with canvas-based step controls and equation rendering</p>"},{"location":"chapters/05-laplace-transform-methods/#initial-value-theorem","title":"Initial Value Theorem","text":"<p>The initial value theorem provides a shortcut to find \\(f(0^+)\\)\u2014the value of a function immediately after \\(t = 0\\)\u2014directly from its Laplace transform, without computing the full inverse transform.</p>"},{"location":"chapters/05-laplace-transform-methods/#initial-value-theorem_1","title":"Initial Value Theorem","text":"<p>\\(f(0^+) = \\lim_{s \\to \\infty} sF(s)\\)</p> <p>where:</p> <ul> <li>\\(f(0^+)\\) is the value of \\(f(t)\\) as \\(t\\) approaches zero from the positive side</li> <li>\\(F(s)\\) is the Laplace transform of \\(f(t)\\)</li> <li>The limit is taken as \\(s\\) goes to infinity</li> </ul> <p>This theorem is valid when \\(f(t)\\) and its derivative are Laplace transformable, and when the limit exists.</p> <p>The intuition: as \\(s \\to \\infty\\), the transform \\(F(s)\\) is dominated by the behavior of \\(f(t)\\) near \\(t = 0\\). The factor \\(s\\) compensates for the \\(1/s\\) inherent in the transform.</p> <p>Example: For \\(F(s) = \\frac{5}{s+2}\\):</p> <p>\\(f(0^+) = \\lim_{s \\to \\infty} s \\cdot \\frac{5}{s+2} = \\lim_{s \\to \\infty} \\frac{5s}{s+2} = \\lim_{s \\to \\infty} \\frac{5}{1+2/s} = 5\\)</p> <p>We can verify: \\(f(t) = 5e^{-2t}\\), so \\(f(0) = 5\\). \u2713</p> Transform \\(F(s)\\) \\(\\lim_{s \\to \\infty} sF(s)\\) Actual \\(f(0^+)\\) \\(\\frac{1}{s+a}\\) 1 1 \\(\\frac{\\omega}{s^2+\\omega^2}\\) 0 0 (sine starts at 0) \\(\\frac{s}{s^2+\\omega^2}\\) 1 1 (cosine starts at 1) \\(\\frac{K}{s}\\) \\(K\\) \\(K\\) (step function)"},{"location":"chapters/05-laplace-transform-methods/#final-value-theorem","title":"Final Value Theorem","text":"<p>The final value theorem provides a shortcut to find the steady-state value \\(f(\\infty)\\)\u2014what \\(f(t)\\) approaches as time goes to infinity\u2014directly from its Laplace transform.</p>"},{"location":"chapters/05-laplace-transform-methods/#final-value-theorem_1","title":"Final Value Theorem","text":"<p>\\(f(\\infty) = \\lim_{s \\to 0} sF(s)\\)</p> <p>where:</p> <ul> <li>\\(f(\\infty) = \\lim_{t \\to \\infty} f(t)\\) is the final value</li> <li>The limit is taken as \\(s\\) approaches zero</li> </ul> <p>Critical requirement: The final value theorem is only valid if \\(f(t)\\) actually converges to a finite limit. Specifically, all poles of \\(sF(s)\\) must be in the left half-plane (except possibly a simple pole at the origin for \\(F(s)\\) itself). If \\(F(s)\\) has poles in the right half-plane or on the imaginary axis (except at the origin), the theorem doesn't apply because \\(f(t)\\) doesn't settle to a constant.</p> <p>Example: For \\(F(s) = \\frac{5}{s(s+2)}\\) (step response of a first-order system):</p> <p>\\(f(\\infty) = \\lim_{s \\to 0} s \\cdot \\frac{5}{s(s+2)} = \\lim_{s \\to 0} \\frac{5}{s+2} = \\frac{5}{2} = 2.5\\)</p> <p>We can verify: \\(f(t) = 2.5(1 - e^{-2t})\\), so \\(f(\\infty) = 2.5\\). \u2713</p> <p>When the Final Value Theorem Fails</p> <p>Don't use the final value theorem when:</p> <ul> <li>The system is unstable (poles in right half-plane)</li> <li>The response is oscillatory (poles on imaginary axis)</li> <li>The response is unbounded (ramp, etc.)</li> </ul> <p>The theorem gives a number even in these cases, but that number is meaningless!</p> <p>Gyra Moment</p> <p>\"The final value theorem is like a promise: 'This is where you'll end up... if you actually settle down.' For me, if my engineers get the controller right, the theorem tells them exactly where my angle will stabilize. But if my poles are in the wrong place and I'm unstable, the theorem's prediction is pure fiction\u2014I'll be on the floor long before 'infinity' arrives.\"</p>"},{"location":"chapters/05-laplace-transform-methods/#diagram-value-theorems-demonstration","title":"Diagram: Value Theorems Demonstration","text":"Value Theorems Demonstration <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: calculate, demonstrate</p> <p>Learning Objective: Students will apply the initial and final value theorems to predict system behavior and verify against actual time response.</p> <p>Canvas layout: - Left (60%): Time response plot with markers at t=0 and t\u2192\u221e - Right (40%): Calculation panel showing theorem application</p> <p>Visual elements: Time Response Plot: - Time axis 0 to 10 seconds (adjustable) - Response curve y(t) - Horizontal dashed line at initial value (green) - Horizontal dashed line at final value (red) - Markers showing actual values at t=0+ and near t=\u221e</p> <p>Calculation Panel: - F(s) expression - Initial value calculation: lim(s\u2192\u221e) sF(s) = [result] - Final value calculation: lim(s\u21920) sF(s) = [result] - Validity check for final value theorem</p> <p>Interactive controls: - Dropdown: Select system (first-order, second-order underdamped, integrator, unstable) - Slider: System parameters (gain, time constant, damping ratio) - Toggle: Show/hide calculation details - Button: Reset</p> <p>Data Visibility Requirements: - Display F(s) clearly - Show step-by-step limit calculation - Compare theorem prediction to actual value from plot - Warning if final value theorem is invalid</p> <p>Behavior: - Plots update as parameters change - Theorem calculations update in real-time - Warning message appears for invalid cases (unstable, oscillatory) - Visual comparison between predicted and actual values</p> <p>Instructional Rationale: Direct comparison between theorem predictions and actual time response validates the theorems and teaches when they apply. Warning for invalid cases prevents misapplication.</p> <p>Implementation: p5.js with equation display and responsive plotting</p>"},{"location":"chapters/05-laplace-transform-methods/#convolution-in-the-time-domain","title":"Convolution in the Time Domain","text":"<p>Convolution is a mathematical operation that describes how an LTI system transforms an input signal into an output signal. In the time domain, if a system has impulse response \\(h(t)\\) and input \\(u(t)\\), the output is:</p>"},{"location":"chapters/05-laplace-transform-methods/#convolution-integral","title":"Convolution Integral","text":"<p>\\(y(t) = h(t) * u(t) = \\int_0^t h(\\tau)u(t-\\tau)d\\tau\\)</p> <p>where:</p> <ul> <li>\\(h(t)\\) is the system's impulse response</li> <li>\\(u(t)\\) is the input signal</li> <li>\\(*\\) denotes convolution</li> <li>\\(\\tau\\) is the integration variable</li> </ul> <p>The convolution integral says: to find the output at time \\(t\\), look at how all past inputs (weighted by the impulse response) contribute to the current output. The impulse response essentially describes how the system \"remembers\" past inputs.</p> <p>Convolution has intuitive physical meaning:</p> <ul> <li>The impulse response \\(h(\\tau)\\) tells us how strongly an input at time \\(\\tau\\) in the past affects the output now</li> <li>We sum up all these contributions from \\(\\tau = 0\\) to \\(\\tau = t\\)</li> <li>Older inputs typically contribute less (for stable systems, \\(h(\\tau) \\to 0\\) as \\(\\tau \\to \\infty\\))</li> </ul> <p>While beautiful theoretically, convolution integrals are often tedious to evaluate directly. This is exactly why we use the Laplace transform.</p> <p>Visualizing Convolution</p> <p>Think of convolution as \"sliding\" the reversed impulse response \\(h(-\\tau)\\) across the input \\(u(\\tau)\\), multiplying at each position, and integrating. At each time \\(t\\), you get one value of the output. The animation of this process helps build intuition.</p>"},{"location":"chapters/05-laplace-transform-methods/#convolution-in-the-s-domain","title":"Convolution in the S-Domain","text":"<p>Here's where the Laplace transform truly shines. The convolution theorem states that convolution in the time domain becomes multiplication in the s-domain:</p>"},{"location":"chapters/05-laplace-transform-methods/#convolution-theorem","title":"Convolution Theorem","text":"<p>\\(\\mathcal{L}\\{h(t) * u(t)\\} = H(s) \\cdot U(s)\\)</p> <p>where:</p> <ul> <li>\\(H(s) = \\mathcal{L}\\{h(t)\\}\\) is the transfer function</li> <li>\\(U(s) = \\mathcal{L}\\{u(t)\\}\\) is the input transform</li> <li>The product \\(H(s)U(s)\\) is the output transform</li> </ul> <p>This is remarkable! That complicated integral becomes simple multiplication. To find the output:</p> <ol> <li>Transform the input: \\(u(t) \\to U(s)\\)</li> <li>Multiply by the transfer function: \\(Y(s) = H(s)U(s)\\)</li> <li>Inverse transform to get the output: \\(Y(s) \\to y(t)\\)</li> </ol> <p>This is the fundamental workflow of classical control analysis.</p> Operation Time Domain S-Domain System response Convolution integral Multiplication Difficulty Hard (integration) Easy (algebra) Insight Limited Reveals poles, zeros, stability <p>The transfer function \\(G(s)\\) is actually the Laplace transform of the impulse response \\(g(t)\\). This connects our s-domain representation directly to the system's fundamental behavior.</p>"},{"location":"chapters/05-laplace-transform-methods/#diagram-convolution-comparison","title":"Diagram: Convolution Comparison","text":"Convolution Comparison <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: compare, contrast</p> <p>Learning Objective: Students will analyze how convolution in the time domain corresponds to multiplication in the s-domain by viewing both operations side by side.</p> <p>Canvas layout: - Top row: Time domain operation (convolution) - Bottom row: S-domain operation (multiplication) - Each row shows: input, system, output</p> <p>Visual elements: Time Domain Row: - Left: Input signal u(t) plot - Center: Impulse response h(t) plot with convolution animation - Right: Output y(t) = h*u plot - Convolution integral shown below</p> <p>S-Domain Row: - Left: U(s) representation (poles/zeros or formula) - Center: H(s) transfer function - Right: Y(s) = H(s)U(s) result - Multiplication shown</p> <p>Connecting arrows: - Vertical arrows showing Laplace transform relationship - Labels: \"L{ }\" pointing down, \"L\u207b\u00b9{ }\" pointing up</p> <p>Interactive controls: - Dropdown: Input type (step, impulse, ramp, exponential) - Dropdown: System type (first-order, second-order) - Slider: System parameters - Toggle: Show/hide convolution animation - Button: Step through convolution</p> <p>Data Visibility Requirements: - Show u(t) and U(s) expressions - Show h(t) and H(s) expressions - Show convolution integral formula - Show multiplication formula - Final y(t) and Y(s)</p> <p>Behavior: - Convolution animation shows sliding and integrating - Both domain outputs update together - Demonstrates equivalence of results - Can pause/step through convolution animation</p> <p>Instructional Rationale: Parallel visualization of time-domain convolution and s-domain multiplication demonstrates that they produce the same result. The convolution animation makes the integral concrete while showing why the s-domain approach is preferred.</p> <p>Implementation: p5.js with dual-row layout and animation controls</p>"},{"location":"chapters/05-laplace-transform-methods/#putting-it-all-together-the-transform-method","title":"Putting It All Together: The Transform Method","text":"<p>Let's summarize the complete workflow for using Laplace transforms to analyze control systems.</p> <p>Step 1: Model the System Write the differential equation(s) describing the system, or obtain the transfer function directly from system analysis.</p> <p>Step 2: Transform Apply the Laplace transform to convert differential equations to algebraic equations. Include initial conditions if nonzero.</p> <p>Step 3: Solve Use algebra to solve for the output transform \\(Y(s)\\) in terms of the input transform \\(U(s)\\) and initial conditions.</p> <p>Step 4: Partial Fraction Expansion Decompose \\(Y(s)\\) into simpler terms using partial fractions. Use the cover-up method for simple poles.</p> <p>Step 5: Inverse Transform Use transform tables to find \\(y(t)\\) from each partial fraction term. Sum the results.</p> <p>Optional Shortcuts: - Use the initial value theorem to find \\(y(0^+)\\) without full inversion - Use the final value theorem to find steady-state \\(y(\\infty)\\) without full inversion</p> <p>This workflow applies whether you're finding step responses, analyzing stability, or designing controllers. The tools developed in this chapter are foundational for everything that follows.</p> <p>Key Insight</p> <p>The Laplace transform doesn't just make calculations easier\u2014it changes how we think about systems. Instead of asking \"what's the solution to this differential equation?\", we ask \"where are the poles?\" and \"what's the transfer function?\" These questions lead directly to insights about stability, speed, and control design.</p>"},{"location":"chapters/05-laplace-transform-methods/#key-takeaways","title":"Key Takeaways","text":"<p>This chapter introduced the essential mathematical machinery for classical control analysis. Here's what you should now be able to do:</p> <ul> <li> <p>Transform between domains: Use the Laplace transform to move from time-domain differential equations to s-domain algebraic equations, and back again using inverse transforms.</p> </li> <li> <p>Work with transfer functions: Understand that the transfer function \\(G(s) = Y(s)/U(s)\\) completely characterizes an LTI system's input-output behavior.</p> </li> <li> <p>Apply partial fraction expansion: Decompose complex rational functions into simpler terms suitable for inverse transformation. Handle distinct real poles, repeated poles, and complex conjugate poles.</p> </li> <li> <p>Use the cover-up method: Quickly find residues for simple poles by \"covering up\" factors and evaluating.</p> </li> <li> <p>Apply value theorems: Use the initial value theorem to find \\(f(0^+)\\) and the final value theorem to find \\(f(\\infty)\\) directly from \\(F(s)\\)\u2014but only when valid!</p> </li> <li> <p>Understand convolution: Recognize that time-domain convolution becomes s-domain multiplication, making system analysis vastly easier.</p> </li> </ul> <p>The s-domain is now your workspace. When you encounter a control problem, your first instinct should be to express it in terms of transfer functions, poles, and zeros. The techniques in this chapter\u2014partial fractions, residue calculation, and the value theorems\u2014will be used constantly as we move forward to analyze stability, design controllers, and tune system performance.</p> Self-Check: Test Your Understanding <p>Before moving on, see if you can answer these without looking back:</p> <ol> <li>What is the Laplace transform of \\(f(t) = 3e^{-2t}\\)?</li> <li>A transfer function has a pole at \\(s = -5\\). What is the corresponding time constant?</li> <li>Given \\(F(s) = \\frac{10}{s(s+2)}\\), use the final value theorem to find \\(f(\\infty)\\).</li> <li>Use the cover-up method to find the partial fraction expansion of \\(\\frac{6}{(s+1)(s+3)}\\).</li> <li>Why can't you use the final value theorem when \\(F(s) = \\frac{1}{s^2+4}\\)?</li> </ol> <p>If you answered all five correctly, you're ready for the next chapter on poles, zeros, and system analysis!</p>"},{"location":"chapters/06-poles-zeros-system-analysis/","title":"Poles, Zeros, and System Analysis","text":""},{"location":"chapters/06-poles-zeros-system-analysis/#summary","title":"Summary","text":"<p>This chapter explores the critical relationship between a system's poles and zeros and its dynamic behavior. Students will learn to construct and interpret pole-zero plots, understand different pole types (real, complex conjugate, repeated, simple), and recognize how pole locations in the s-plane determine stability and response characteristics. The concept of dominant poles is introduced as a practical tool for approximating higher-order system behavior. System order and proper transfer function properties complete the analysis framework.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 18 concepts from the learning graph:</p> <ol> <li>Poles</li> <li>Zeros</li> <li>Pole-Zero Plot</li> <li>Pole-Zero Cancellation</li> <li>Dominant Poles</li> <li>Pole Locations</li> <li>Complex Conjugate Poles</li> <li>Real Poles</li> <li>Repeated Poles</li> <li>Simple Poles</li> <li>Pole at Origin</li> <li>Poles in Left Half Plane</li> <li>Poles in Right Half Plane</li> <li>Poles on Imaginary Axis</li> <li>System Order</li> <li>Proper Transfer Function</li> <li>Strictly Proper Function</li> <li>DC Gain</li> </ol>"},{"location":"chapters/06-poles-zeros-system-analysis/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 3: Time-Domain Response Fundamentals</li> <li>Chapter 5: Laplace Transform Methods</li> </ul>"},{"location":"chapters/06-poles-zeros-system-analysis/#the-s-plane-a-map-of-system-behavior","title":"The S-Plane: A Map of System Behavior","text":"<p>Imagine having a map that tells you everything about how a system will behave\u2014whether it will oscillate, how fast it will respond, whether it will explode or settle down peacefully. That map exists, and it's called the s-plane. The locations of a system's poles and zeros on this complex plane encode the complete story of its dynamic behavior. Learn to read this map, and you'll have x-ray vision into any linear system.</p> <p>Here's the remarkable insight: two systems with completely different physical implementations\u2014an electrical circuit and a mechanical suspension, say\u2014will behave identically if they share the same pole and zero locations. The s-plane is the universal language of linear dynamics, transcending the specifics of springs, capacitors, or hydraulic cylinders. Master this language, and you can analyze anything.</p> <p>In this chapter, we'll develop the vocabulary and visual intuition to read pole-zero maps fluently. By the end, you'll be able to glance at a pole-zero plot and immediately know whether the system will be stable, how fast it will respond, whether it will oscillate, and what kind of controller might improve it. That's a genuine engineering superpower.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#poles-where-the-action-happens","title":"Poles: Where the Action Happens","text":"<p>The poles of a transfer function are the values of \\(s\\) that make the denominator equal to zero\u2014they're the roots of the characteristic equation. If you have a transfer function:</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#transfer-function-form","title":"Transfer Function Form","text":"<p>\\(G(s) = \\frac{N(s)}{D(s)}\\)</p> <p>where:</p> <ul> <li>\\(N(s)\\) is the numerator polynomial</li> <li>\\(D(s)\\) is the denominator polynomial</li> </ul> <p>Then the poles are the solutions to \\(D(s) = 0\\).</p> <p>Why do we call them \"poles\"? If you imagine the transfer function magnitude as a surface over the s-plane, poles are points where this surface shoots up to infinity\u2014like tent poles holding up a canvas. The mathematical term comes from complex analysis, but the visual metaphor is apt: poles are where the action is.</p> <p>Consider this transfer function:</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#example-transfer-function","title":"Example Transfer Function","text":"<p>\\(G(s) = \\frac{5}{(s+2)(s+5)}\\)</p> <p>The poles are at \\(s = -2\\) and \\(s = -5\\). At these values, the denominator becomes zero, and the transfer function theoretically \"blows up.\" But here's the crucial point: while we never actually operate the system at its pole frequencies, the pole locations completely determine how the system responds to any input.</p> <p>Each pole contributes a component to the natural response. For real poles:</p> <ul> <li>A pole at \\(s = -a\\) contributes a term \\(e^{-at}\\) to the time response</li> <li>More negative poles decay faster</li> <li>Poles closer to the imaginary axis dominate the response</li> </ul> Pole Location Time Response Component Behavior \\(s = -2\\) \\(e^{-2t}\\) Decays with time constant 0.5s \\(s = -5\\) \\(e^{-5t}\\) Decays with time constant 0.2s \\(s = -0.1\\) \\(e^{-0.1t}\\) Slowly decaying (dominates!) <p>Gyra Moment</p> <p>\"Every pole in my transfer function is a voice in my response. The poles closest to the imaginary axis are the loudest\u2014they're the last ones to quiet down after a disturbance. When my engineers want to speed me up, they push my poles further left. When they want me calmer, they add damping to spread the poles apart. My behavior is literally mapped on the s-plane.\"</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#zeros-shaping-the-response","title":"Zeros: Shaping the Response","text":"<p>While poles determine what response modes exist, zeros shape how much of each mode appears in the output. Zeros are the values of \\(s\\) that make the numerator equal to zero\u2014the roots of \\(N(s) = 0\\).</p> <p>For the transfer function:</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#transfer-function-with-zero","title":"Transfer Function with Zero","text":"<p>\\(G(s) = \\frac{s+3}{(s+2)(s+5)}\\)</p> <p>The zero is at \\(s = -3\\). Zeros have a remarkable property: they can suppress or enhance certain response characteristics.</p> <p>Here's the intuition: if you place a zero near a pole, the zero partially \"cancels\" that pole's contribution to the response. If you place a zero far from any poles, it has less effect on the dominant dynamics. This gives designers a tool\u2014add zeros through controllers to reshape the response without changing the fundamental pole locations.</p> <p>Key effects of zeros:</p> <ul> <li>Zeros in the left half-plane: Can cause overshoot in the step response, even for heavily damped systems</li> <li>Zeros near poles: Reduce the contribution of that pole to the response</li> <li>Right half-plane zeros: Create \"non-minimum phase\" behavior\u2014the response initially goes the \"wrong way\"</li> </ul> Zero Location Effect on Response LHP, far from poles Mild increase in overshoot LHP, near a pole Reduces that pole's influence RHP (positive real part) Initial undershoot, then recovery <p>Right Half-Plane Zeros</p> <p>RHP zeros are trouble. They cause the step response to initially move in the opposite direction from its final value\u2014like a car that backs up before going forward. Systems with RHP zeros are harder to control and have fundamental limitations on achievable bandwidth. If you encounter one, proceed with caution.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#the-pole-zero-plot","title":"The Pole-Zero Plot","text":"<p>A pole-zero plot is a graphical representation of all poles and zeros of a transfer function on the complex s-plane. By convention:</p> <ul> <li>Poles are marked with \u2715 symbols</li> <li>Zeros are marked with \u25cb symbols</li> <li>The horizontal axis is the real part of \\(s\\) (\u03c3)</li> <li>The vertical axis is the imaginary part of \\(s\\) (j\u03c9)</li> </ul> <p>This simple diagram packs enormous information. At a glance, you can determine:</p> <ul> <li>Stability: Are all poles in the left half-plane?</li> <li>Speed of response: How far left are the dominant poles?</li> <li>Oscillation: Are there complex conjugate poles?</li> <li>Damping: What angle do complex poles make with the negative real axis?</li> <li>DC gain: Where are the zeros relative to poles?</li> </ul>"},{"location":"chapters/06-poles-zeros-system-analysis/#diagram-interactive-pole-zero-plot","title":"Diagram: Interactive Pole-Zero Plot","text":"Interactive Pole-Zero Plot <p>Type: microsim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: interpret, explain</p> <p>Learning Objective: Students will interpret pole-zero plots by identifying pole and zero locations and understanding their implications for system behavior.</p> <p>Canvas layout: - Left side (55%): S-plane with poles and zeros - Right side (45%): Time response plot and transfer function display</p> <p>Visual elements: S-Plane: - Complex plane with real (\u03c3) and imaginary (j\u03c9) axes - Grid lines at integer values - Left half-plane shaded light green (stable region) - Right half-plane shaded light red (unstable region) - Imaginary axis highlighted - Poles marked with blue \u2715 symbols - Zeros marked with red \u25cb symbols - Draggable poles and zeros</p> <p>Time Response Plot: - Step response curve - Time axis (0 to 10 seconds) - Amplitude axis (0 to 2) - Steady-state reference line</p> <p>Interactive controls: - Drag poles and zeros on s-plane - Button: Add Pole (click to place) - Button: Add Zero (click to place) - Button: Delete Selected - Button: Reset to Example - Dropdown: Preset examples (First-order, Underdamped second-order, System with zero)</p> <p>Data Visibility Requirements: - Display transfer function G(s) in symbolic form - Show pole values: p\u2081 = [value], p\u2082 = [value], etc. - Show zero values: z\u2081 = [value], etc. - Display DC gain - For complex poles: show \u03b6 and \u03c9n</p> <p>Behavior: - Step response updates in real-time as poles/zeros are dragged - System becomes unstable (response grows) if any pole enters RHP - Complex conjugate poles must move as pairs - Transfer function display updates with each change - Warning message if system is unstable</p> <p>Instructional Rationale: Direct manipulation of poles and zeros with immediate visual feedback builds deep intuition for the connection between s-plane locations and time response. Students discover relationships through exploration rather than memorization.</p> <p>Implementation: p5.js with draggable elements and real-time response calculation</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#real-poles","title":"Real Poles","text":"<p>Real poles lie on the real axis of the s-plane\u2014they have no imaginary component. A real pole at \\(s = -a\\) (where \\(a &gt; 0\\)) contributes an exponentially decaying term \\(Ae^{-at}\\) to the time response.</p> <p>The location determines everything:</p> <ul> <li>Magnitude \\(|a|\\): Determines decay rate (larger = faster)</li> <li>Sign: Negative (left of origin) = stable, Positive (right) = unstable</li> <li>Distance from origin: Time constant \\(\\tau = 1/|a|\\)</li> </ul> <p>Real poles produce smooth, monotonic response components\u2014no oscillation. A first-order system has exactly one real pole. Second-order overdamped systems have two distinct real poles.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#real-pole-step-response","title":"Real Pole Step Response","text":"<p>For a system with a single real pole at \\(s = -a\\):</p> <p>\\(G(s) = \\frac{K \\cdot a}{s + a}\\)</p> <p>The step response is:</p> <p>\\(y(t) = K(1 - e^{-at})\\)</p> <p>where:</p> <ul> <li>\\(K\\) is the DC gain</li> <li>\\(a\\) is the pole magnitude (determines speed)</li> <li>\\(\\tau = 1/a\\) is the time constant</li> </ul> Pole at Time Constant 63.2% Time Settling Time (5\u03c4) \\(s = -1\\) 1 second 1 s 5 s \\(s = -5\\) 0.2 seconds 0.2 s 1 s \\(s = -0.5\\) 2 seconds 2 s 10 s"},{"location":"chapters/06-poles-zeros-system-analysis/#complex-conjugate-poles","title":"Complex Conjugate Poles","text":"<p>Complex conjugate poles always come in pairs (for systems with real coefficients) and create oscillatory behavior. A pair at \\(s = -\\sigma \\pm j\\omega_d\\) produces a damped sinusoidal response:</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#damped-sinusoidal-response","title":"Damped Sinusoidal Response","text":"<p>\\(y(t) = Ae^{-\\sigma t}\\sin(\\omega_d t + \\phi)\\)</p> <p>where:</p> <ul> <li>\\(\\sigma = \\zeta\\omega_n\\) is the decay rate (real part magnitude)</li> <li>\\(\\omega_d = \\omega_n\\sqrt{1-\\zeta^2}\\) is the damped frequency</li> <li>\\(\\zeta\\) is the damping ratio</li> <li>\\(\\omega_n\\) is the natural frequency</li> </ul> <p>The geometry of complex pole locations directly encodes the dynamic parameters:</p> <ul> <li>Distance from origin: \\(\\omega_n = \\sqrt{\\sigma^2 + \\omega_d^2}\\) (natural frequency)</li> <li>Angle from negative real axis: \\(\\theta = \\cos^{-1}(\\zeta)\\) (damping ratio)</li> <li>Real part magnitude: \\(\\sigma = \\zeta\\omega_n\\) (decay rate)</li> </ul> <p>Reading \u03b6 from the S-Plane</p> <p>Draw a line from the origin to a complex pole. The angle \u03b8 this line makes with the negative real axis relates to damping: \\(\\zeta = \\cos(\\theta)\\). Poles at 45\u00b0 have \u03b6 = 0.707 (often considered optimal). Poles near the imaginary axis (large \u03b8) are lightly damped. Poles near the real axis (small \u03b8) are heavily damped.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#diagram-complex-pole-geometry","title":"Diagram: Complex Pole Geometry","text":"Complex Pole Geometry <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: calculate, demonstrate</p> <p>Learning Objective: Students will calculate damping ratio and natural frequency from complex pole locations by measuring angles and distances on the s-plane.</p> <p>Canvas layout: - Left side (60%): S-plane with geometric construction - Right side (40%): Parameter display and response preview</p> <p>Visual elements: S-Plane: - Complex plane with axes labeled \u03c3 and j\u03c9 - Complex conjugate pole pair (draggable) - Line from origin to upper pole - Arc showing angle \u03b8 - Horizontal line to real axis intersection - Vertical line showing imaginary part - Constant \u03b6 lines (radial lines from origin) - Constant \u03c9n circles (arcs centered at origin)</p> <p>Parameter Display: - Real part: \u03c3 = [value] - Imaginary part: \u03c9d = [value] - Natural frequency: \u03c9n = [value] - Damping ratio: \u03b6 = [value] - Angle: \u03b8 = [value]\u00b0</p> <p>Response Preview: - Small step response plot showing damped oscillation - Envelope curves visible</p> <p>Interactive controls: - Drag pole to reposition (conjugate moves automatically) - Toggle: Show/hide constant \u03b6 lines - Toggle: Show/hide constant \u03c9n circles - Slider: Set \u03b6 directly (poles move to match) - Slider: Set \u03c9n directly (poles move to match)</p> <p>Data Visibility Requirements: - Display all geometric relationships as pole moves - Show calculation: \u03c9n = \u221a(\u03c3\u00b2 + \u03c9d\u00b2) - Show calculation: \u03b6 = \u03c3/\u03c9n = cos(\u03b8) - Update response preview in real-time</p> <p>Behavior: - As pole is dragged, all parameters update continuously - Constant \u03b6 lines are radial (same angle = same damping) - Constant \u03c9n circles show poles with same natural frequency - Cannot drag poles to RHP in this demonstration - Response preview shows corresponding time behavior</p> <p>Instructional Rationale: Geometric construction with live parameter calculation helps students internalize the relationships between pole locations and dynamic parameters. The dual representation (slider vs. drag) reinforces bidirectional understanding.</p> <p>Implementation: p5.js with geometric drawing and canvas-based controls</p> <p>Helping Gyra</p> <p>\"My complex conjugate poles determine my wobble characteristics. When they're close to the imaginary axis, I oscillate many times before settling\u2014it's exhausting! When they're far to the left, I barely wobble at all, but I'm also sluggish. My engineers found a sweet spot around \u03b6 = 0.7, where I'm responsive but not too bouncy. On the s-plane, that's when my poles sit at about 45\u00b0 from the real axis.\"</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#simple-poles-vs-repeated-poles","title":"Simple Poles vs. Repeated Poles","text":"<p>A simple pole is a pole of multiplicity one\u2014it appears exactly once as a root of the characteristic equation. Most poles you'll encounter are simple poles, and they contribute straightforward exponential or oscillatory components to the response.</p> <p>Repeated poles (also called multiple poles) occur when a root appears more than once. A pole of multiplicity \\(m\\) at \\(s = -a\\) appears as a factor \\((s+a)^m\\) in the denominator.</p> <p>The key difference is in the time response:</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#simple-vs-repeated-pole-response","title":"Simple vs Repeated Pole Response","text":"<p>For a simple pole at \\(s = -a\\):</p> <p>\\(\\mathcal{L}^{-1}\\left\\{\\frac{1}{s+a}\\right\\} = e^{-at}\\)</p> <p>For a repeated pole of order 2 at \\(s = -a\\):</p> <p>\\(\\mathcal{L}^{-1}\\left\\{\\frac{1}{(s+a)^2}\\right\\} = te^{-at}\\)</p> <p>For a repeated pole of order 3:</p> <p>\\(\\mathcal{L}^{-1}\\left\\{\\frac{1}{(s+a)^3}\\right\\} = \\frac{t^2}{2}e^{-at}\\)</p> <p>The pattern continues: multiplicity \\(m\\) contributes terms up to \\(t^{m-1}e^{-at}\\).</p> Pole Type Transfer Function Factor Time Response Simple at \\(-a\\) \\(\\frac{1}{s+a}\\) \\(e^{-at}\\) Double at \\(-a\\) \\(\\frac{1}{(s+a)^2}\\) \\(te^{-at}\\) Triple at \\(-a\\) \\(\\frac{1}{(s+a)^3}\\) \\(\\frac{t^2}{2}e^{-at}\\) <p>The polynomial factor (\\(t\\), \\(t^2\\), etc.) causes the response to initially grow before the exponential decay dominates. Critically damped second-order systems have a repeated pole\u2014that's why their response has the form \\((1 + \\omega_n t)e^{-\\omega_n t}\\).</p> <p>Repeated Poles in Practice</p> <p>Repeated poles are mathematically interesting but somewhat rare in physical systems. They represent a knife-edge condition\u2014a tiny change in parameters would split the repeated pole into two nearby simple poles. In design, we often aim for repeated poles when we want critical damping.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#pole-at-origin","title":"Pole at Origin","text":"<p>A pole at the origin (\\(s = 0\\)) has special significance. It corresponds to an integrator in the system\u2014a component that accumulates its input over time. In the time domain, a pole at \\(s = 0\\) contributes a constant or a ramp, depending on the input.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#integrator-transfer-function","title":"Integrator Transfer Function","text":"<p>\\(G(s) = \\frac{1}{s}\\)</p> <p>This is a pure integrator. Its step response is a ramp:</p> <p>\\(y(t) = t\\)</p> <p>The output grows without bound\u2014there's no decay because the pole's real part is zero.</p> <p>Poles at the origin are neither stable nor unstable\u2014they're marginally stable. The system doesn't blow up, but it doesn't settle down either. This is characteristic of systems with no restoring force or inherent feedback, such as:</p> <ul> <li>Position control systems (integrating velocity gives position)</li> <li>Tank level with continuous flow (integrating flow rate gives volume)</li> <li>A frictionless mass (integrating force gives velocity)</li> </ul> Pole Location Classification Step Response Left of origin Stable Bounded, settles At origin Marginally stable Ramp (unbounded) Right of origin Unstable Exponential growth <p>Gyra Moment</p> <p>\"I have something like a pole at the origin\u2014or very close to it. When I lean forward slightly, I don't spring back automatically. Without my controller constantly applying corrective torque, I'd just keep falling. That's what an integrator does: any small disturbance accumulates into a big problem. My controller has to actively fight this tendency every millisecond. If the controller sleeps, I fall.\"</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#poles-in-the-left-half-plane","title":"Poles in the Left Half Plane","text":"<p>Poles in the left half plane (LHP) are the hallmark of stable systems. Any pole with a negative real part (\\(\\text{Re}(s) &lt; 0\\)) contributes a decaying component to the time response\u2014whether exponential decay for real poles or damped oscillation for complex poles.</p> <p>For stability, all poles must be in the LHP. This is the fundamental stability criterion:</p> <p>Stability Criterion</p> <p>A linear time-invariant system is stable if and only if all poles of its transfer function lie in the open left half-plane (excluding the imaginary axis).</p> <p>The farther a pole is to the left, the faster its contribution decays. This gives us a design principle: if we want a faster system, push the poles leftward. But there are limits\u2014real actuators can't respond infinitely fast, and pushing poles too far left requires high gains that amplify noise.</p> <p>Consider a system with poles at \\(s = -1\\) and \\(s = -10\\):</p> <ul> <li>The pole at \\(s = -1\\) has time constant \\(\\tau = 1\\) s</li> <li>The pole at \\(s = -10\\) has time constant \\(\\tau = 0.1\\) s</li> </ul> <p>After about 0.5 seconds, the contribution from the \\(s = -10\\) pole has decayed to essentially nothing, while the \\(s = -1\\) pole is just getting started. The leftmost pole is \"fast\" and becomes negligible quickly; the rightmost pole (still in LHP) \"dominates\" the long-term response.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#diagram-lhp-pole-effects","title":"Diagram: LHP Pole Effects","text":"LHP Pole Effects <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: differentiate, compare</p> <p>Learning Objective: Students will analyze how pole distance from the imaginary axis affects response speed and settling time.</p> <p>Canvas layout: - Top (50%): S-plane showing pole locations - Bottom (50%): Time response showing individual pole contributions and total</p> <p>Visual elements: S-Plane: - LHP shaded green with \"Stable Region\" label - Imaginary axis highlighted - Multiple poles (2-3) at different horizontal positions - Draggable poles (horizontal movement only for this demo)</p> <p>Time Response: - Individual contributions from each pole (thin colored lines) - Total response (thick black line) - Time axis 0-10 seconds - Amplitude axis - Settling time markers</p> <p>Interactive controls: - Drag poles horizontally to change real part - Toggle: Show/hide individual contributions - Button: Reset - Dropdown: 2 poles, 3 poles, or 4 poles</p> <p>Data Visibility Requirements: - Display each pole location and its time constant - Show settling time for each component (5\u03c4) - Identify which pole is \"dominant\" (rightmost) - Show total system settling time</p> <p>Behavior: - As poles move left, their contributions decay faster - Dominant pole always labeled (rightmost LHP pole) - Response updates in real-time - Cannot drag poles across imaginary axis in this demo</p> <p>Instructional Rationale: By separating individual pole contributions, students see clearly why the rightmost pole dominates. Horizontal-only movement focuses attention on the key parameter affecting response speed.</p> <p>Implementation: p5.js with constrained dragging and multi-curve plotting</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#poles-in-the-right-half-plane","title":"Poles in the Right Half Plane","text":"<p>Poles in the right half plane (RHP) spell disaster. A pole with a positive real part (\\(\\text{Re}(s) &gt; 0\\)) contributes an exponentially growing component to the response. The system is unstable\u2014any disturbance, no matter how small, will eventually cause the output to blow up.</p> <p>For a pole at \\(s = +a\\) (where \\(a &gt; 0\\)):</p> <p>\\(y(t) \\propto e^{+at}\\)</p> <p>This grows without bound. In practice, physical systems don't actually reach infinity\u2014they hit actuator limits, break, catch fire, or otherwise demonstrate that mathematical models have their limits. But the point stands: RHP poles must be eliminated through feedback or the system is unusable.</p> <p>Unstable Systems</p> <p>An unstable system is not merely \"sluggish\" or \"oscillatory\"\u2014it's fundamentally broken for control purposes. Even with zero input, noise or numerical error will trigger exponential growth. RHP poles are red flags that demand immediate attention. Never deploy a system with RHP poles without closed-loop stabilization.</p> <p>How do RHP poles arise? Many interesting physical systems are inherently unstable:</p> <ul> <li>Inverted pendulums (Gyra!)</li> <li>Rocket or missile guidance (aerodynamic instability)</li> <li>Some chemical reactors (thermal runaway)</li> <li>Aircraft at certain flight conditions</li> </ul> <p>The good news: feedback control can move poles. A major goal of controller design is to take an unstable open-loop system and create a stable closed-loop system by moving RHP poles into the LHP.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#poles-on-the-imaginary-axis","title":"Poles on the Imaginary Axis","text":"<p>Poles on the imaginary axis represent the boundary between stability and instability. They produce sustained oscillations that neither grow nor decay\u2014marginal stability.</p> <p>A pair of complex conjugate poles at \\(s = \\pm j\\omega\\) contributes:</p> <p>\\(y(t) = A\\cos(\\omega t + \\phi)\\)</p> <p>This oscillation continues forever at constant amplitude. There's no damping (the real part is zero), so energy is neither added nor removed.</p> <p>Examples of systems with imaginary-axis poles:</p> <ul> <li>Ideal LC oscillators (no resistance)</li> <li>Undamped spring-mass systems (no friction)</li> <li>Systems at the edge of instability</li> </ul> Pole Location Real Part Response Behavior LHP Negative Decaying (stable) Imaginary axis Zero Sustained oscillation (marginal) RHP Positive Growing (unstable) <p>Imaginary-axis poles are tricky to work with. They're neither clearly stable nor unstable\u2014any small perturbation might push them into either half-plane. In practice, truly marginally stable systems are rare because real systems always have some damping. But understanding this boundary case is essential for stability analysis.</p> <p>Helping Gyra</p> <p>\"If my poles sat exactly on the imaginary axis, I would oscillate forever at constant amplitude\u2014swinging back and forth without ever settling or falling. But that would require perfect symmetry and zero friction, which don't exist. In reality, my poles are either slightly in the LHP (I eventually settle) or slightly in the RHP (I eventually fall). My controller's job is to make sure they stay firmly in the LHP.\"</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#system-order","title":"System Order","text":"<p>The system order is the degree of the denominator polynomial of the transfer function\u2014equivalently, the number of poles (counting multiplicity). System order determines the maximum complexity of the response and corresponds to the number of independent energy storage elements.</p> <p>For a transfer function:</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#general-transfer-function","title":"General Transfer Function","text":"<p>\\(G(s) = \\frac{b_m s^m + b_{m-1}s^{m-1} + \\cdots + b_0}{a_n s^n + a_{n-1}s^{n-1} + \\cdots + a_0}\\)</p> <p>The system order is \\(n\\) (the degree of the denominator).</p> Order Poles Energy Storage Example 1 1 1 element RC circuit 2 2 2 elements RLC circuit, mass-spring-damper 3 3 3 elements Cascaded tanks n n n elements Complex systems <p>Higher-order systems can exhibit more complex behavior\u2014multiple oscillation modes, multiple time scales, more complex transient shapes. However, higher-order systems can often be approximated by lower-order models using dominant pole analysis, which we'll explore shortly.</p> <p>The order also tells us how many initial conditions are needed to specify the system state completely and how many roots we need to find when analyzing the characteristic equation.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#proper-and-strictly-proper-transfer-functions","title":"Proper and Strictly Proper Transfer Functions","text":"<p>A transfer function's \"properness\" relates the degrees of its numerator and denominator. This classification has important implications for physical realizability and high-frequency behavior.</p> <p>A proper transfer function has:</p> <p>\\(\\deg(N(s)) \\leq \\deg(D(s))\\)</p> <p>In other words, the numerator degree is less than or equal to the denominator degree. All physically realizable systems are proper.</p> <p>A strictly proper transfer function has:</p> <p>\\(\\deg(N(s)) &lt; \\deg(D(s))\\)</p> <p>The numerator degree is strictly less than the denominator degree.</p> <p>An improper transfer function has:</p> <p>\\(\\deg(N(s)) &gt; \\deg(D(s))\\)</p> <p>Improper transfer functions are not physically realizable\u2014they would require predicting the future or infinite bandwidth.</p> Transfer Function Numerator Degree Denominator Degree Classification \\(\\frac{5}{s+2}\\) 0 1 Strictly proper \\(\\frac{s+1}{s+2}\\) 1 1 Proper \\(\\frac{s+1}{(s+2)(s+3)}\\) 1 2 Strictly proper \\(\\frac{s^2+1}{s+2}\\) 2 1 Improper <p>Why This Matters</p> <p>Strictly proper systems have gain that drops to zero at high frequencies\u2014they act as low-pass filters. Proper (but not strictly proper) systems approach a constant gain at high frequencies. These characteristics affect noise sensitivity, controller design, and simulation accuracy.</p> <p>For control design, we typically work with strictly proper plants (most physical systems) and may add proper controllers. Improper controllers can sometimes arise in theory but require approximation for implementation.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#dc-gain","title":"DC Gain","text":"<p>The DC gain is the system's steady-state output-to-input ratio for a constant input\u2014what happens when all the transients have died out and the system has fully settled. It's found by evaluating the transfer function at \\(s = 0\\):</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#dc-gain-formula","title":"DC Gain Formula","text":"<p>\\(K_{DC} = G(0) = \\lim_{s \\to 0} G(s)\\)</p> <p>For a transfer function:</p> <p>\\(G(s) = \\frac{5(s+3)}{(s+1)(s+2)}\\)</p> <p>The DC gain is:</p> <p>\\(K_{DC} = G(0) = \\frac{5(0+3)}{(0+1)(0+2)} = \\frac{15}{2} = 7.5\\)</p> <p>This means a unit step input produces a steady-state output of 7.5.</p> <p>DC gain tells you the \"amplification\" of the system for slowly-varying signals. It's crucial for:</p> <ul> <li>Predicting steady-state response to step inputs</li> <li>Calculating steady-state error in feedback systems</li> <li>Scaling controller gains</li> </ul> Transfer Function DC Gain Steady-State Step Response \\(\\frac{3}{s+2}\\) \\(3/2 = 1.5\\) 1.5 \\(\\frac{10}{(s+1)(s+5)}\\) \\(10/5 = 2\\) 2 \\(\\frac{s+2}{s+5}\\) \\(2/5 = 0.4\\) 0.4 <p>Poles at Origin</p> <p>If the system has a pole at the origin (an integrator), the DC gain is infinite\u2014\\(G(0)\\) blows up. This makes physical sense: an integrator's response to a constant input is a ramp that grows forever. For such systems, we talk about \"velocity constants\" or \"position constants\" instead.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#dominant-poles","title":"Dominant Poles","text":"<p>In higher-order systems, not all poles contribute equally to the response. Dominant poles are the poles closest to the imaginary axis\u2014they decay slowest and therefore dominate the long-term transient behavior.</p> <p>Consider a third-order system with poles at \\(s = -1\\), \\(s = -2\\), and \\(s = -10\\):</p> <ul> <li>Pole at \\(s = -1\\): time constant \\(\\tau = 1\\) s, contributes \\(e^{-t}\\)</li> <li>Pole at \\(s = -2\\): time constant \\(\\tau = 0.5\\) s, contributes \\(e^{-2t}\\)</li> <li>Pole at \\(s = -10\\): time constant \\(\\tau = 0.1\\) s, contributes \\(e^{-10t}\\)</li> </ul> <p>After \\(t = 0.5\\) seconds: - \\(e^{-10(0.5)} = e^{-5} \\approx 0.007\\) (essentially zero) - \\(e^{-2(0.5)} = e^{-1} \\approx 0.37\\) (significant) - \\(e^{-1(0.5)} = e^{-0.5} \\approx 0.61\\) (dominant)</p> <p>The pole at \\(s = -10\\) is effectively \"invisible\" after the first half-second. The pole at \\(s = -1\\) dominates the settling behavior.</p> <p>The Factor of 5 Rule</p> <p>A common approximation: if a pole is more than 5 times farther from the imaginary axis than the dominant pole(s), its contribution can often be neglected for design purposes. The system can then be approximated by a lower-order model containing only the dominant poles.</p> <p>This simplification is enormously practical. A tenth-order system might be well-approximated by a second-order model if only two poles are close to the imaginary axis and the rest are far to the left. Simplified models are easier to analyze, design for, and explain to management.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#diagram-dominant-pole-approximation","title":"Diagram: Dominant Pole Approximation","text":"Dominant Pole Approximation <p>Type: microsim</p> <p>Bloom Taxonomy: Evaluate (L5) Bloom Verb: assess, justify</p> <p>Learning Objective: Students will assess when a lower-order approximation is valid by comparing full and reduced-order model responses.</p> <p>Canvas layout: - Left (50%): S-plane showing all poles with dominance zones - Right (50%): Time response comparing full model vs. approximation</p> <p>Visual elements: S-Plane: - All poles of full system (3-4 poles) - Vertical \"dominance boundary\" line (adjustable) - Poles left of boundary shaded/dimmed (to be neglected) - Poles right of boundary highlighted (dominant)</p> <p>Time Response: - Full-order response (solid blue line) - Reduced-order approximation (dashed red line) - Error band showing difference - Settling time markers for both</p> <p>Interactive controls: - Slider: Position of \"neglect boundary\" - Drag poles to different locations - Dropdown: Preset systems (3rd, 4th, 5th order examples) - Toggle: Show/hide error - Display: Order of approximation</p> <p>Data Visibility Requirements: - List all poles with their distances from imaginary axis - Show ratio: \"Fastest neglected pole / Slowest kept pole\" - Display RMS error between full and approximate responses - Show percentage fit quality</p> <p>Behavior: - As boundary moves, some poles are \"kept\" and others \"neglected\" - Approximate response uses only kept poles (with DC gain correction) - Error generally decreases as more poles are kept - Good approximation when ratio &gt; 5</p> <p>Instructional Rationale: Students develop judgment about when approximations are valid by directly seeing the trade-off between model complexity and accuracy. The adjustable boundary lets them discover the \"factor of 5\" guideline empirically.</p> <p>Implementation: p5.js with adjustable boundary and error calculation</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#pole-zero-cancellation","title":"Pole-Zero Cancellation","text":"<p>Pole-zero cancellation occurs when a zero is located at or very near the same location as a pole. In the transfer function:</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#cancellation-example","title":"Cancellation Example","text":"<p>\\(G(s) = \\frac{s+2}{(s+2)(s+5)} = \\frac{1}{s+5}\\)</p> <p>The zero at \\(s = -2\\) \"cancels\" the pole at \\(s = -2\\), leaving a first-order system.</p> <p>But wait\u2014is this really that simple? Mathematically, yes. Practically, it's more nuanced.</p> <p>Perfect cancellation (exact match) eliminates the pole's contribution entirely. The mode associated with that pole simply doesn't appear in the transfer function output.</p> <p>Imperfect cancellation (pole and zero close but not identical) is more realistic. Manufacturing tolerances and parameter variations mean exact cancellation is nearly impossible. A small mismatch leaves a lightly-weighted pole that may still affect transient behavior.</p> <p>Hidden Modes</p> <p>Cancellation can hide dynamics but doesn't eliminate them. If a pole at \\(s = -2\\) is cancelled but initial conditions excite that mode, the response will still contain \\(e^{-2t}\\) components. Cancellation affects the forced response but not the natural response. This distinction matters for stability analysis and internal stability.</p> Cancellation Scenario Practical Concern LHP pole cancelled by LHP zero Generally acceptable, may hide slow mode RHP pole cancelled by RHP zero Dangerous! Internal instability remains Pole near zero (imperfect) Lightly-damped hidden mode, sensitive to parameters <p>The most dangerous case is attempting to cancel an unstable (RHP) pole with a RHP zero. The transfer function looks stable, but the internal dynamics remain unstable. Any noise or disturbance will excite the hidden unstable mode, causing internal state variables to blow up even while the output appears well-behaved\u2014until it doesn't.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#putting-it-all-together-reading-a-pole-zero-plot","title":"Putting It All Together: Reading a Pole-Zero Plot","text":"<p>Now that we've explored each element, let's develop a systematic approach to reading pole-zero plots. When presented with a pole-zero plot, follow this analysis checklist:</p> <p>Step 1: Check Stability Are all poles in the left half-plane? If any pole is on or right of the imaginary axis, the system is marginally stable or unstable.</p> <p>Step 2: Identify Dominant Poles Which poles are closest to the imaginary axis? These dominate the response.</p> <p>Step 3: Classify Response Type</p> <ul> <li>All real poles \u2192 No oscillation</li> <li>Complex conjugate poles \u2192 Oscillatory component</li> <li>Read damping from pole angle: \\(\\zeta = \\cos(\\theta)\\)</li> </ul> <p>Step 4: Estimate Speed Distance from imaginary axis determines speed. Dominant pole location gives approximate time constant.</p> <p>Step 5: Note Zeros</p> <ul> <li>LHP zeros affect overshoot</li> <li>RHP zeros cause initial undershoot</li> <li>Zeros near poles may indicate cancellation</li> </ul> <p>Step 6: Calculate DC Gain Evaluate \\(G(0)\\) for steady-state behavior.</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#diagram-pole-zero-analysis-workflow","title":"Diagram: Pole-Zero Analysis Workflow","text":"Pole-Zero Analysis Workflow <p>Type: workflow</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: execute, implement</p> <p>Learning Objective: Students will apply a systematic workflow to analyze any pole-zero plot and predict system behavior.</p> <p>Purpose: Show the step-by-step process for analyzing a pole-zero plot</p> <p>Visual style: Flowchart with decision diamonds and process rectangles</p> <p>Steps: 1. Start: \"Given: Pole-Zero Plot\"    Hover text: \"Start with locations of all poles and zeros\"</p> <ol> <li>Decision: \"All poles in LHP?\"    Hover text: \"Check if all poles have negative real parts\"</li> </ol> <p>3a. Process: \"System is STABLE\" (if yes)     Hover text: \"Proceed with response analysis\"</p> <p>3b. Process: \"System is UNSTABLE\" (if no)     Hover text: \"Stop! System requires stabilization first\"</p> <ol> <li> <p>Process: \"Identify Dominant Poles\"    Hover text: \"Find pole(s) closest to imaginary axis\"</p> </li> <li> <p>Decision: \"Complex or Real Poles?\"    Hover text: \"Check if dominant poles have imaginary parts\"</p> </li> </ol> <p>6a. Process: \"Calculate \u03b6, \u03c9n from geometry\" (if complex)     Hover text: \"Use \u03b6=cos(\u03b8), \u03c9n=distance from origin\"</p> <p>6b. Process: \"Calculate time constant \u03c4=1/|p|\" (if real)     Hover text: \"Response is purely exponential\"</p> <ol> <li> <p>Process: \"Analyze Zeros\"    Hover text: \"Check for LHP zeros (overshoot), RHP zeros (undershoot), or cancellations\"</p> </li> <li> <p>Process: \"Calculate DC Gain\"    Hover text: \"Evaluate G(0) for steady-state value\"</p> </li> <li> <p>End: \"Complete System Characterization\"    Hover text: \"Can now predict step response, stability margins, etc.\"</p> </li> </ol> <p>Color coding: - Blue: Data/query steps - Green: Stable path - Red: Unstable warning - Yellow: Decision points - Purple: Calculation steps</p> <p>Interactive elements: - Hover over each box for detailed explanation - Click to see example at each stage</p> <p>Implementation: HTML/CSS/JavaScript with SVG flowchart</p>"},{"location":"chapters/06-poles-zeros-system-analysis/#key-takeaways","title":"Key Takeaways","text":"<p>This chapter has equipped you with the vocabulary and visual intuition to analyze systems through their pole-zero structure. Here's what you can now do:</p> <ul> <li> <p>Poles are the roots of the denominator\u2014they determine the natural modes of the system. Every pole contributes a component to the time response.</p> </li> <li> <p>Zeros are the roots of the numerator\u2014they shape how strongly each mode appears. Zeros near poles can suppress those modes.</p> </li> <li> <p>The pole-zero plot is a complete graphical summary of a system's dynamics. Learn to read it like a map.</p> </li> <li> <p>Stability requires all poles to be in the left half-plane. RHP poles mean exponential growth\u2014unstable. Imaginary-axis poles mean sustained oscillation\u2014marginal stability.</p> </li> <li> <p>Real poles produce exponential decays or growths. Complex conjugate poles produce oscillations. The damping ratio \\(\\zeta = \\cos(\\theta)\\) can be read directly from the pole angle.</p> </li> <li> <p>Repeated poles produce polynomial-times-exponential responses. Critical damping is a special case with repeated poles.</p> </li> <li> <p>Dominant poles are closest to the imaginary axis and determine long-term behavior. Higher-order systems can often be approximated by keeping only dominant poles.</p> </li> <li> <p>DC gain \\(G(0)\\) gives the steady-state response to a step input.</p> </li> <li> <p>Pole-zero cancellation can simplify transfer functions but can hide internal dynamics\u2014especially dangerous if cancelling RHP poles.</p> </li> <li> <p>Proper transfer functions have numerator degree \u2264 denominator degree. All physical systems are proper; strictly proper systems are most common.</p> </li> </ul> <p>The s-plane is your diagnostic tool for understanding and designing control systems. When you see a transfer function, immediately sketch the pole-zero plot\u2014it will tell you everything you need to know about stability, speed, and oscillation characteristics.</p> Self-Check: Test Your Understanding <p>Before moving on, see if you can answer these without peeking:</p> <ol> <li>A system has poles at \\(s = -2 \\pm j3\\). What is the natural frequency \\(\\omega_n\\) and damping ratio \\(\\zeta\\)?</li> <li>A transfer function has poles at \\(s = -1\\), \\(s = -10\\), and \\(s = -50\\). Which pole dominates the response, and what is the approximate settling time?</li> <li>True or false: If you cancel an unstable pole with a zero at the same location, the system becomes stable.</li> <li>A system has DC gain of 5. What is the steady-state output for a unit step input?</li> <li>Looking at a pole at 45\u00b0 from the negative real axis, what is the damping ratio?</li> </ol> <p>If you got all five, you're ready for the next chapter on block diagrams and feedback structures!</p>"},{"location":"chapters/07-physical-system-modeling/","title":"Physical System Modeling","text":""},{"location":"chapters/07-physical-system-modeling/#summary","title":"Summary","text":"<p>This chapter develops the skills to create mathematical models of real physical systems. Students will learn to derive differential equations and transfer functions for electrical circuits (RC, RL, RLC, op-amp), mechanical systems (translational and rotational including mass-spring-dampers, pendulums, and gear trains), and electromechanical systems (DC motors). The chapter also introduces analogous system concepts that reveal deep connections between electrical and mechanical domains, enabling engineers to apply insights across disciplines.</p>"},{"location":"chapters/07-physical-system-modeling/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 25 concepts from the learning graph:</p> <ol> <li>Electrical Systems</li> <li>Mechanical Systems</li> <li>Translational Systems</li> <li>Rotational Systems</li> <li>Electromechanical Systems</li> <li>Motor Model</li> <li>DC Motor</li> <li>Armature-Controlled Motor</li> <li>Field-Controlled Motor</li> <li>Motor Transfer Function</li> <li>RLC Circuit</li> <li>RC Circuit</li> <li>RL Circuit</li> <li>Op-Amp Circuits</li> <li>Mass-Spring-Damper</li> <li>Pendulum System</li> <li>Gear Train</li> <li>Lever System</li> <li>Fluid Systems</li> <li>Thermal Systems</li> <li>Analogous Systems</li> <li>Impedance Analogy</li> <li>Mobility Analogy</li> <li>Force-Voltage Analogy</li> <li>Force-Current Analogy</li> </ol>"},{"location":"chapters/07-physical-system-modeling/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 2: Dynamic System Properties</li> <li>Chapter 3: Time-Domain Response Fundamentals</li> <li>Chapter 5: Laplace Transform Methods</li> </ul>"},{"location":"chapters/07-physical-system-modeling/#from-abstract-to-concrete","title":"From Abstract to Concrete","text":"<p>Up to this point, we've worked with transfer functions that appeared almost magically\u2014given to us as ratios of polynomials in \\(s\\). But where do these transfer functions come from? How do you look at a real physical system\u2014a circuit, a motor, a suspension system\u2014and write down the mathematics that describes its behavior?</p> <p>This is the art and science of physical system modeling. It's where control engineering connects to the real world. The transfer function isn't just a mathematical abstraction; it emerges from the actual physics of the system you're trying to control.</p> <p>In this chapter, we'll develop systematic techniques for deriving models of three major categories of physical systems:</p> <ul> <li>Electrical systems: circuits with resistors, capacitors, inductors, and operational amplifiers</li> <li>Mechanical systems: both translational (straight-line motion) and rotational (spinning)</li> <li>Electromechanical systems: devices like DC motors that convert between electrical and mechanical energy</li> </ul> <p>Along the way, we'll discover something remarkable: the equations governing these seemingly different systems are often identical in structure. A mass-spring-damper behaves mathematically just like an RLC circuit. This insight, captured in the concept of analogous systems, means that intuition developed in one domain transfers directly to others.</p> <p>Gyra Moment</p> <p>\"My body is where all these domains meet. I have motors (electromechanical), which drive wheels against the ground (mechanical), controlled by circuits on my board (electrical). When my engineers model me correctly, they can predict exactly how I'll respond. When they get the model wrong, well... let's just say I spend a lot of time on the floor.\"</p>"},{"location":"chapters/07-physical-system-modeling/#electrical-systems","title":"Electrical Systems","text":"<p>Electrical systems are natural starting points for control engineers because they're relatively easy to analyze mathematically and build physically. The fundamental components\u2014resistors, capacitors, and inductors\u2014each have simple, well-understood relationships between voltage and current.</p> <p>The building blocks:</p> Component Symbol Voltage-Current Relation Impedance \\(Z(s)\\) Resistor \\(R\\) \\(v = iR\\) \\(R\\) Capacitor \\(C\\) \\(v = \\frac{1}{C}\\int i \\, dt\\) \\(\\frac{1}{sC}\\) Inductor \\(L\\) \\(v = L\\frac{di}{dt}\\) \\(sL\\) <p>These relationships, combined with Kirchhoff's laws, allow us to write the governing equations for any circuit. Taking the Laplace transform gives us the s-domain representation, and from there, the transfer function.</p> <p>The impedance concept is particularly powerful: in the s-domain, all three components obey a generalized Ohm's law \\(V(s) = Z(s)I(s)\\), where \\(Z(s)\\) is the component's impedance. This means we can analyze complex circuits using the same techniques as simple resistive circuits\u2014just with complex, frequency-dependent impedances.</p>"},{"location":"chapters/07-physical-system-modeling/#rc-circuit","title":"RC Circuit","text":"<p>The RC circuit is the simplest dynamic electrical circuit, consisting of a resistor and capacitor in series. It's a first-order system with a single time constant.</p>"},{"location":"chapters/07-physical-system-modeling/#rc-circuit-schematic","title":"RC Circuit Schematic","text":"<p>Consider a series RC circuit with input voltage \\(v_{in}(t)\\) and output taken across the capacitor as \\(v_{out}(t)\\).</p> <p>Applying Kirchhoff's voltage law:</p> <p>\\(v_{in}(t) = v_R(t) + v_{out}(t) = Ri(t) + v_{out}(t)\\)</p> <p>The current through the capacitor is:</p> <p>\\(i(t) = C\\frac{dv_{out}}{dt}\\)</p> <p>Substituting:</p> <p>\\(v_{in}(t) = RC\\frac{dv_{out}}{dt} + v_{out}(t)\\)</p> <p>This is a first-order linear differential equation. Taking the Laplace transform (with zero initial conditions):</p> <p>\\(V_{in}(s) = RCs \\cdot V_{out}(s) + V_{out}(s) = (RCs + 1)V_{out}(s)\\)</p>"},{"location":"chapters/07-physical-system-modeling/#rc-circuit-transfer-function","title":"RC Circuit Transfer Function","text":"<p>\\(G(s) = \\frac{V_{out}(s)}{V_{in}(s)} = \\frac{1}{RCs + 1} = \\frac{1}{\\tau s + 1}\\)</p> <p>where:</p> <ul> <li>\\(\\tau = RC\\) is the time constant</li> <li>The pole is at \\(s = -1/\\tau = -1/RC\\)</li> </ul> <p>The RC circuit acts as a low-pass filter: it passes low-frequency signals while attenuating high frequencies. The cutoff frequency is \\(\\omega_c = 1/RC\\) rad/s. At DC (s = 0), the gain is 1; at high frequencies, the gain approaches zero.</p> <p>Physical interpretation: the capacitor voltage can't change instantaneously. When the input steps up, the capacitor gradually charges through the resistor, with the charging current decreasing exponentially as the capacitor voltage approaches the input.</p>"},{"location":"chapters/07-physical-system-modeling/#rl-circuit","title":"RL Circuit","text":"<p>The RL circuit pairs a resistor with an inductor, creating another first-order system but with different characteristics than the RC circuit.</p> <p>For a series RL circuit with output taken across the resistor:</p> <p>\\(v_{in}(t) = L\\frac{di}{dt} + Ri(t)\\)</p> <p>The output voltage across the resistor is \\(v_{out}(t) = Ri(t)\\), so \\(i(t) = v_{out}(t)/R\\).</p> <p>Taking the Laplace transform:</p> <p>\\(V_{in}(s) = \\frac{Ls}{R}V_{out}(s) + V_{out}(s) = \\left(\\frac{L}{R}s + 1\\right)V_{out}(s)\\)</p>"},{"location":"chapters/07-physical-system-modeling/#rl-circuit-transfer-function","title":"RL Circuit Transfer Function","text":"<p>\\(G(s) = \\frac{V_{out}(s)}{V_{in}(s)} = \\frac{1}{\\frac{L}{R}s + 1} = \\frac{1}{\\tau s + 1}\\)</p> <p>where:</p> <ul> <li>\\(\\tau = L/R\\) is the time constant</li> <li>The pole is at \\(s = -R/L\\)</li> </ul> <p>Wait\u2014this looks identical to the RC circuit transfer function! Both are first-order systems with the form \\(1/(\\tau s + 1)\\). The only difference is how \\(\\tau\\) is computed: \\(RC\\) for the RC circuit, \\(L/R\\) for the RL circuit.</p> <p>This is our first hint of the deep connections between different physical systems that we'll explore in the analogous systems section.</p>"},{"location":"chapters/07-physical-system-modeling/#rlc-circuit","title":"RLC Circuit","text":"<p>The RLC circuit combines all three passive components, creating a second-order system with much richer behavior than the first-order RC or RL circuits.</p> <p>Consider a series RLC circuit with input voltage \\(v_{in}(t)\\) and output taken across the capacitor:</p>"},{"location":"chapters/07-physical-system-modeling/#rlc-circuit-differential-equation","title":"RLC Circuit Differential Equation","text":"<p>\\(L\\frac{d^2v_{out}}{dt^2} + R\\frac{dv_{out}}{dt} + \\frac{1}{C}v_{out} = \\frac{1}{C}v_{in}\\)</p> <p>Taking the Laplace transform:</p> <p>\\(Ls^2V_{out}(s) + RsV_{out}(s) + \\frac{1}{C}V_{out}(s) = \\frac{1}{C}V_{in}(s)\\)</p>"},{"location":"chapters/07-physical-system-modeling/#rlc-circuit-transfer-function","title":"RLC Circuit Transfer Function","text":"<p>\\(G(s) = \\frac{V_{out}(s)}{V_{in}(s)} = \\frac{1/LC}{s^2 + \\frac{R}{L}s + \\frac{1}{LC}}\\)</p> <p>Comparing with the standard second-order form \\(\\frac{\\omega_n^2}{s^2 + 2\\zeta\\omega_n s + \\omega_n^2}\\):</p> <ul> <li>Natural frequency: \\(\\omega_n = \\frac{1}{\\sqrt{LC}}\\)</li> <li>Damping ratio: \\(\\zeta = \\frac{R}{2}\\sqrt{\\frac{C}{L}}\\)</li> </ul> <p>The RLC circuit can exhibit all the second-order behaviors we studied earlier: overdamped, critically damped, underdamped, or undamped oscillation\u2014depending on the relative values of R, L, and C.</p> Damping Condition Damping Ratio Circuit Behavior \\(R &gt; 2\\sqrt{L/C}\\) \\(\\zeta &gt; 1\\) Overdamped (sluggish) \\(R = 2\\sqrt{L/C}\\) \\(\\zeta = 1\\) Critically damped (fastest non-oscillatory) \\(R &lt; 2\\sqrt{L/C}\\) \\(\\zeta &lt; 1\\) Underdamped (oscillatory) \\(R = 0\\) \\(\\zeta = 0\\) Undamped (sustained oscillation)"},{"location":"chapters/07-physical-system-modeling/#diagram-rlc-circuit-response-explorer","title":"Diagram: RLC Circuit Response Explorer","text":"RLC Circuit Response Explorer <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: demonstrate, solve</p> <p>Learning Objective: Students will apply their understanding of second-order system parameters to predict RLC circuit behavior and observe how R, L, and C values affect the response.</p> <p>Canvas layout: - Left (55%): Time response plot - Right (45%): Circuit diagram and parameter panel</p> <p>Visual elements: Circuit Diagram: - Series RLC schematic with labeled components - Component values displayed - Input and output voltage indicators</p> <p>Time Response Plot: - Step response of capacitor voltage - Time axis (0 to 10\u03c4) - Amplitude axis with unity step input reference - Overshoot and settling time indicators for underdamped cases</p> <p>Parameter Panel: - Current R, L, C values - Calculated \u03c9_n and \u03b6 - Damping classification (overdamped/critically/underdamped) - Pole locations</p> <p>Interactive controls: - Slider: Resistance R (1 to 1000 \u03a9) - Slider: Inductance L (0.001 to 1 H) - Slider: Capacitance C (0.1 to 100 \u03bcF) - Button: Reset to defaults - Toggle: Show pole locations on s-plane inset</p> <p>Data Visibility Requirements: - Display calculated \u03c9_n = 1/\u221a(LC) - Display calculated \u03b6 = (R/2)\u221a(C/L) - Show damping classification - Display pole locations: s = -\u03b6\u03c9_n \u00b1 j\u03c9_n\u221a(1-\u03b6\u00b2)</p> <p>Behavior: - Response plot updates in real-time as sliders move - Color coding: overdamped (blue), critical (green), underdamped (orange) - Pole locations update on s-plane inset - Numerical displays update with slider changes</p> <p>Instructional Rationale: Direct manipulation of circuit parameters with immediate visual feedback builds intuition for how component values map to system dynamics. The connection between physical parameters and abstract quantities (\u03c9_n, \u03b6) becomes tangible.</p> <p>Implementation: p5.js with canvas-based sliders and dual plotting areas</p>"},{"location":"chapters/07-physical-system-modeling/#op-amp-circuits","title":"Op-Amp Circuits","text":"<p>Operational amplifiers (op-amps) are active electronic devices that dramatically expand what we can achieve with circuits. While passive RC and RL circuits can only attenuate signals, op-amp circuits can provide gain, inversion, integration, differentiation, and much more.</p> <p>For control systems, the ideal op-amp model suffices:</p> <ul> <li>Infinite input impedance (no current into input terminals)</li> <li>Zero output impedance</li> <li>Infinite open-loop gain (forces the difference between inputs to zero when feedback is present)</li> </ul> <p>These idealized properties, combined with negative feedback, give us the \"golden rules\" for op-amp analysis:</p> <ol> <li>No current flows into the + or \u2212 input terminals</li> <li>When negative feedback is present, the voltage difference between inputs is zero</li> </ol>"},{"location":"chapters/07-physical-system-modeling/#common-op-amp-circuits-for-control","title":"Common Op-Amp Circuits for Control","text":"<p>Inverting Amplifier:</p> <p>\\(G(s) = -\\frac{Z_f(s)}{Z_{in}(s)}\\)</p> <p>where \\(Z_f\\) is the feedback impedance and \\(Z_{in}\\) is the input impedance.</p> <p>Integrator (Inverting):</p> <p>With resistor input and capacitor feedback:</p> <p>\\(G(s) = -\\frac{1}{RCs}\\)</p> <p>This produces output proportional to the integral of the input\u2014essential for PI and PID controllers.</p> <p>Differentiator:</p> <p>With capacitor input and resistor feedback:</p> <p>\\(G(s) = -RCs\\)</p> <p>This produces output proportional to the derivative\u2014useful for PD control, though rarely used pure due to noise amplification.</p> <p>Active Low-Pass Filter:</p> <p>Combining an inverting amplifier with RC filtering:</p> <p>\\(G(s) = -\\frac{R_f}{R_{in}} \\cdot \\frac{1}{\\tau s + 1}\\)</p> <p>This provides both filtering and gain, making it useful in many control applications.</p> <p>Op-Amps in Control Systems</p> <p>Op-amp circuits are the building blocks of analog controllers. A PID controller can be constructed entirely from op-amp stages: an inverting integrator for the I term, a differentiator (with filtering) for the D term, and amplifiers for gain adjustment. Understanding these circuits helps bridge the gap between control theory and hardware implementation.</p>"},{"location":"chapters/07-physical-system-modeling/#mechanical-systems","title":"Mechanical Systems","text":"<p>Mechanical systems translate the physical world of forces, masses, and motion into mathematical models. We divide mechanical systems into two categories based on the type of motion: translational (straight-line) and rotational (spinning).</p> <p>The fundamental mechanical elements parallel the electrical ones in satisfying ways that we'll explore in the analogous systems section.</p>"},{"location":"chapters/07-physical-system-modeling/#translational-systems","title":"Translational Systems","text":"<p>Translational systems involve straight-line motion. The fundamental elements are mass, spring (stiffness), and damper (friction), with the relevant variables being force, velocity, and displacement.</p> Element Symbol Force Relationship Impedance \\(Z(s)\\) Mass \\(m\\) \\(F = m\\frac{d^2x}{dt^2}\\) \\(ms^2\\) Damper \\(b\\) \\(F = b\\frac{dx}{dt}\\) \\(bs\\) Spring \\(k\\) \\(F = kx\\) \\(k\\) <p>The key governing principle is Newton's second law: \\(\\sum F = ma\\). For each mass in the system, we write a force balance equation, then combine these with the constitutive relations for springs and dampers.</p>"},{"location":"chapters/07-physical-system-modeling/#mass-spring-damper-system","title":"Mass-Spring-Damper System","text":"<p>The mass-spring-damper system is the canonical second-order mechanical system, analogous to the RLC circuit in the electrical domain. It appears everywhere: vehicle suspensions, vibration isolation platforms, seismic sensors, and of course, simplified models of robots like Gyra.</p> <p>Consider a mass \\(m\\) attached to a fixed wall via a spring \\(k\\) and damper \\(b\\), with an applied force \\(F(t)\\) and displacement \\(x(t)\\) measured from equilibrium.</p> <p>Applying Newton's second law:</p> <p>\\(F(t) = m\\frac{d^2x}{dt^2} + b\\frac{dx}{dt} + kx\\)</p>"},{"location":"chapters/07-physical-system-modeling/#mass-spring-damper-transfer-function","title":"Mass-Spring-Damper Transfer Function","text":"<p>\\(G(s) = \\frac{X(s)}{F(s)} = \\frac{1}{ms^2 + bs + k}\\)</p> <p>This can be written in standard form:</p> <p>\\(G(s) = \\frac{1/k}{(m/k)s^2 + (b/k)s + 1} = \\frac{1/k}{\\frac{s^2}{\\omega_n^2} + \\frac{2\\zeta}{\\omega_n}s + 1}\\)</p> <p>where:</p> <ul> <li>Natural frequency: \\(\\omega_n = \\sqrt{k/m}\\)</li> <li>Damping ratio: \\(\\zeta = \\frac{b}{2\\sqrt{km}}\\)</li> <li>DC gain: \\(1/k\\) (static displacement per unit force)</li> </ul> <p>The physical interpretation is intuitive:</p> <ul> <li>A stiffer spring (larger \\(k\\)) means faster oscillation (higher \\(\\omega_n\\)) and smaller static displacement (lower DC gain)</li> <li>A heavier mass (larger \\(m\\)) means slower oscillation</li> <li>More damping (larger \\(b\\)) reduces oscillation and overshoot</li> </ul> <p>Gyra Moment</p> <p>\"I'm basically a mass-spring-damper\u2014except my 'spring' is gravity trying to tip me over, and my 'damper' is my control system fighting back. When my engineers tune my PD gains, they're essentially setting my effective spring constant and damping ratio. Too little damping and I wobble endlessly. Too much and I react like I'm stuck in honey.\"</p>"},{"location":"chapters/07-physical-system-modeling/#diagram-mass-spring-damper-simulator","title":"Diagram: Mass-Spring-Damper Simulator","text":"Mass-Spring-Damper Simulator <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: demonstrate, calculate</p> <p>Learning Objective: Students will apply Newton's second law to predict mass-spring-damper behavior and observe the relationship between physical parameters (m, b, k) and system response characteristics (\u03c9_n, \u03b6).</p> <p>Canvas layout: - Left (50%): Physical animation of mass-spring-damper - Right (50%): Response plots and parameters</p> <p>Visual elements: Physical Animation: - Fixed wall on left - Spring (zigzag line) connecting wall to mass - Damper (piston symbol) in parallel with spring - Rectangular mass block - Ground with friction indicators - Position reference line - Applied force arrow</p> <p>Response Plots: - Position vs time plot - Velocity vs time plot (smaller, below)</p> <p>Parameter Panel: - Current m, b, k values - Calculated \u03c9_n and \u03b6 - Damping classification</p> <p>Interactive controls: - Slider: Mass m (0.5 to 10 kg) - Slider: Damping b (0 to 20 N\u00b7s/m) - Slider: Stiffness k (10 to 200 N/m) - Button: Apply step force - Button: Apply impulse - Button: Reset position</p> <p>Data Visibility Requirements: - Display calculated \u03c9_n = \u221a(k/m) - Display calculated \u03b6 = b/(2\u221a(km)) - Show damping classification - Display period T = 2\u03c0/\u03c9_d for underdamped cases</p> <p>Behavior: - Animation shows mass moving with spring stretching/compressing - Response plots show position and velocity over time - Different damping regimes show visually distinct behaviors - Spring visualization stretches proportionally to displacement - Damper shows velocity-proportional resistance</p> <p>Instructional Rationale: Physical animation combined with response plots connects the abstract transfer function to tangible mechanical behavior. Students see how changing mass affects both animation speed and the response curves.</p> <p>Implementation: p5.js with physics simulation and synchronized plotting</p>"},{"location":"chapters/07-physical-system-modeling/#rotational-systems","title":"Rotational Systems","text":"<p>Rotational systems involve spinning motion around an axis. The variables and elements are analogous to translational systems but for rotation:</p> Translational Rotational Relationship Force \\(F\\) Torque \\(\\tau\\) \\(\\tau = Fr\\) (moment arm) Mass \\(m\\) Moment of inertia \\(J\\) \\(J = mr^2\\) (for point mass) Damping \\(b\\) Rotational damping \\(B\\) Same units concept Stiffness \\(k\\) Torsional stiffness \\(K\\) Same units concept Displacement \\(x\\) Angle \\(\\theta\\) Velocity \\(v\\) Angular velocity \\(\\omega\\) <p>Newton's second law becomes:</p> <p>\\(\\sum \\tau = J\\frac{d^2\\theta}{dt^2} = J\\dot{\\omega}\\)</p> <p>For a rotational mass-spring-damper (e.g., a torsional pendulum):</p>"},{"location":"chapters/07-physical-system-modeling/#rotational-second-order-system","title":"Rotational Second-Order System","text":"<p>\\(G(s) = \\frac{\\Theta(s)}{T(s)} = \\frac{1}{Js^2 + Bs + K}\\)</p> <p>where:</p> <ul> <li>\\(J\\) is the moment of inertia</li> <li>\\(B\\) is the rotational damping coefficient</li> <li>\\(K\\) is the torsional spring constant</li> <li>\\(\\Theta(s)\\) is the angular displacement</li> <li>\\(T(s)\\) is the applied torque</li> </ul> <p>The form is identical to the translational case\u2014only the variables and units differ.</p>"},{"location":"chapters/07-physical-system-modeling/#pendulum-system","title":"Pendulum System","text":"<p>The pendulum is a classical rotational system that introduces an important modeling concept: linearization. A simple pendulum's true dynamics are nonlinear, but for small angles, we can approximate the behavior with a linear model.</p> <p>For a simple pendulum of length \\(L\\) and mass \\(m\\), with angle \\(\\theta\\) from vertical:</p> <p>The exact equation of motion is:</p> <p>\\(mL^2\\frac{d^2\\theta}{dt^2} + mgL\\sin\\theta = \\tau_{applied}\\)</p> <p>This is nonlinear because of the \\(\\sin\\theta\\) term. However, for small angles (typically \\(\\theta &lt; 15\u00b0\\)), we can use the approximation \\(\\sin\\theta \\approx \\theta\\):</p>"},{"location":"chapters/07-physical-system-modeling/#linearized-pendulum-equation","title":"Linearized Pendulum Equation","text":"<p>\\(mL^2\\frac{d^2\\theta}{dt^2} + mgL\\theta = \\tau_{applied}\\)</p> <p>Adding damping \\(B\\) at the pivot:</p> <p>\\(mL^2\\frac{d^2\\theta}{dt^2} + B\\frac{d\\theta}{dt} + mgL\\theta = \\tau_{applied}\\)</p>"},{"location":"chapters/07-physical-system-modeling/#pendulum-transfer-function","title":"Pendulum Transfer Function","text":"<p>\\(G(s) = \\frac{\\Theta(s)}{T(s)} = \\frac{1}{mL^2s^2 + Bs + mgL}\\)</p> <p>This is again a second-order system with:</p> <ul> <li>Natural frequency: \\(\\omega_n = \\sqrt{g/L}\\) (the classic pendulum frequency)</li> <li>Damping ratio: \\(\\zeta = \\frac{B}{2mL^2\\omega_n} = \\frac{B}{2L\\sqrt{mgL}}\\)</li> </ul> <p>Linearization Limitations</p> <p>The linearized pendulum model only works for small angles. If the pendulum swings widely, the actual behavior diverges from the linear prediction. This is a recurring theme in control: linear models are powerful but have validity limits. Good engineers know where those limits lie.</p>"},{"location":"chapters/07-physical-system-modeling/#gear-train","title":"Gear Train","text":"<p>Gear trains are mechanical power transmission systems that transform speed and torque. They're essential components in motors, robotics, and machinery. From a modeling perspective, they act as transformers\u2014similar to electrical transformers but for mechanical quantities.</p> <p>For an ideal gear pair with gear ratio \\(N = N_2/N_1\\) (driven gear teeth / driving gear teeth):</p> Quantity Relationship Angular velocity \\(\\omega_2 = \\omega_1/N\\) Torque \\(\\tau_2 = N\\tau_1\\) Power \\(P_2 = P_1\\) (conserved) <p>Gears trade speed for torque: a gear ratio \\(N &gt; 1\\) reduces output speed but multiplies torque.</p> <p>When reflecting inertia and damping through a gear train to a single reference shaft:</p>"},{"location":"chapters/07-physical-system-modeling/#reflected-inertia-formula","title":"Reflected Inertia Formula","text":"<p>\\(J_{reflected} = J_{load}/N^2\\)</p> <p>where:</p> <ul> <li>\\(J_{load}\\) is the load inertia on the output shaft</li> <li>\\(N\\) is the gear ratio</li> <li>\\(J_{reflected}\\) is the equivalent inertia seen at the motor shaft</li> </ul> <p>This \\(N^2\\) relationship is crucial for motor sizing: a gear reduction makes the load appear lighter to the motor.</p> <p>Gear Ratio Selection</p> <p>Gear ratios involve tradeoffs. Higher ratios reduce the effective load inertia and increase torque but also reduce output speed and can introduce backlash and compliance. In robotics, matching the gear ratio to optimize for acceleration capability or force sensitivity is an important design decision.</p>"},{"location":"chapters/07-physical-system-modeling/#lever-system","title":"Lever System","text":"<p>Lever systems are rotational mechanical advantage devices, fundamental to tools and machines. Like gears, they transform force and displacement.</p> <p>For a lever with fulcrum position creating arms of length \\(a\\) (input side) and \\(b\\) (output side):</p>"},{"location":"chapters/07-physical-system-modeling/#lever-mechanical-advantage","title":"Lever Mechanical Advantage","text":"<p>\\(MA = \\frac{F_{out}}{F_{in}} = \\frac{a}{b}\\)</p> <p>And displacement relationship:</p> <p>\\(\\frac{x_{out}}{x_{in}} = \\frac{b}{a}\\)</p> <p>The product of force and displacement is conserved (work in = work out for ideal levers):</p> <p>\\(F_{in} \\cdot x_{in} = F_{out} \\cdot x_{out}\\)</p> <p>Levers are first-class (fulcrum between effort and load), second-class (load between fulcrum and effort), or third-class (effort between fulcrum and load), each suited to different applications.</p>"},{"location":"chapters/07-physical-system-modeling/#electromechanical-systems","title":"Electromechanical Systems","text":"<p>Electromechanical systems bridge the electrical and mechanical domains. They convert electrical energy to mechanical energy (motors) or mechanical energy to electrical energy (generators). For control systems, the DC motor is the most important electromechanical device to model.</p>"},{"location":"chapters/07-physical-system-modeling/#dc-motor","title":"DC Motor","text":"<p>The DC motor converts electrical current into rotational mechanical power through electromagnetic interaction. It's the actuator of choice in countless control applications: robotics, disk drives, automotive systems, and\u2014you guessed it\u2014Gyra's wheels.</p> <p>A DC motor has two main circuits:</p> <ul> <li>Armature circuit: the rotating winding that carries current and produces torque</li> <li>Field circuit: provides the magnetic field (can be permanent magnets or electromagnets)</li> </ul> <p>The key relationships governing DC motor behavior:</p>"},{"location":"chapters/07-physical-system-modeling/#motor-torque-equation","title":"Motor Torque Equation","text":"<p>\\(\\tau = K_t i_a\\)</p> <p>where:</p> <ul> <li>\\(\\tau\\) is the motor torque</li> <li>\\(K_t\\) is the torque constant (N\u00b7m/A)</li> <li>\\(i_a\\) is the armature current</li> </ul>"},{"location":"chapters/07-physical-system-modeling/#back-emf-equation","title":"Back-EMF Equation","text":"<p>\\(e_b = K_e \\omega\\)</p> <p>where:</p> <ul> <li>\\(e_b\\) is the back-EMF (electromotive force)</li> <li>\\(K_e\\) is the back-EMF constant (V\u00b7s/rad)</li> <li>\\(\\omega\\) is the angular velocity</li> </ul> <p>For an ideal motor, \\(K_t = K_e\\) when expressed in consistent units.</p> <p>The back-EMF is a crucial feedback mechanism: as the motor spins faster, it generates a voltage that opposes the applied voltage, naturally limiting speed.</p>"},{"location":"chapters/07-physical-system-modeling/#armature-controlled-dc-motor","title":"Armature-Controlled DC Motor","text":"<p>The armature-controlled DC motor is the most common configuration. The field is held constant (often using permanent magnets), and speed/torque are controlled by varying the armature voltage.</p> <p>The armature circuit equation:</p> <p>\\(v_a = L_a\\frac{di_a}{dt} + R_ai_a + e_b = L_a\\frac{di_a}{dt} + R_ai_a + K_e\\omega\\)</p> <p>The mechanical equation:</p> <p>\\(J\\frac{d\\omega}{dt} + B\\omega = \\tau - \\tau_L = K_ti_a - \\tau_L\\)</p> <p>where:</p> <ul> <li>\\(v_a\\) is the armature voltage (input)</li> <li>\\(L_a\\) and \\(R_a\\) are armature inductance and resistance</li> <li>\\(J\\) is the total inertia (motor + load)</li> <li>\\(B\\) is the viscous friction coefficient</li> <li>\\(\\tau_L\\) is the load torque</li> </ul> <p>Taking Laplace transforms and eliminating \\(I_a(s)\\):</p>"},{"location":"chapters/07-physical-system-modeling/#armature-controlled-dc-motor-transfer-function","title":"Armature-Controlled DC Motor Transfer Function","text":"<p>\\(G(s) = \\frac{\\Omega(s)}{V_a(s)} = \\frac{K_t}{(L_as + R_a)(Js + B) + K_tK_e}\\)</p> <p>For most DC motors, the electrical time constant (\\(L_a/R_a\\)) is much smaller than the mechanical time constant (\\(J/B\\)), so we often neglect armature inductance:</p>"},{"location":"chapters/07-physical-system-modeling/#simplified-motor-transfer-function","title":"Simplified Motor Transfer Function","text":"<p>\\(G(s) = \\frac{K_t/R_a}{Js + B + K_tK_e/R_a} = \\frac{K_m}{\\tau_m s + 1}\\)</p> <p>where:</p> <ul> <li>\\(K_m = \\frac{K_t}{R_aB + K_tK_e}\\) is the motor gain constant</li> <li>\\(\\tau_m = \\frac{JR_a}{R_aB + K_tK_e}\\) is the motor time constant</li> </ul> <p>This simplified model is a first-order system\u2014voltage in, speed out\u2014which is remarkably tractable for control design.</p>"},{"location":"chapters/07-physical-system-modeling/#field-controlled-dc-motor","title":"Field-Controlled DC Motor","text":"<p>The field-controlled DC motor varies the field current while keeping armature current constant. This configuration is less common but appears in some applications.</p> <p>With constant armature current \\(i_a\\) and variable field current \\(i_f\\):</p> <p>\\(\\tau = K'_t i_f i_a = K_f i_f\\) (where \\(K_f = K'_t i_a\\))</p> <p>The field circuit equation:</p> <p>\\(v_f = L_f\\frac{di_f}{dt} + R_fi_f\\)</p> <p>The mechanical equation:</p> <p>\\(J\\frac{d\\omega}{dt} + B\\omega = K_f i_f\\)</p>"},{"location":"chapters/07-physical-system-modeling/#field-controlled-motor-transfer-function","title":"Field-Controlled Motor Transfer Function","text":"<p>\\(G(s) = \\frac{\\Omega(s)}{V_f(s)} = \\frac{K_f}{(L_fs + R_f)(Js + B)}\\)</p> <p>This is a second-order system\u2014the field and mechanical dynamics each contribute a pole. The response is generally slower than armature control because of the field circuit's larger inductance.</p>"},{"location":"chapters/07-physical-system-modeling/#motor-transfer-function-summary","title":"Motor Transfer Function Summary","text":"<p>Both motor types can be expressed as transfer functions relating input voltage to output speed or position:</p> Motor Type Speed Transfer Function Order Armature-controlled (full) \\(\\frac{K_t}{(L_as + R_a)(Js + B) + K_tK_e}\\) Second Armature-controlled (simplified) \\(\\frac{K_m}{\\tau_m s + 1}\\) First Field-controlled \\(\\frac{K_f}{(L_fs + R_f)(Js + B)}\\) Second <p>For position control, integrate the speed transfer function (multiply by \\(1/s\\)):</p> <p>\\(G_\\theta(s) = \\frac{\\Theta(s)}{V(s)} = \\frac{G_\\omega(s)}{s}\\)</p>"},{"location":"chapters/07-physical-system-modeling/#diagram-dc-motor-model-visualization","title":"Diagram: DC Motor Model Visualization","text":"DC Motor Model Visualization <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: differentiate, examine</p> <p>Learning Objective: Students will analyze the interaction between electrical and mechanical dynamics in a DC motor, observing how changes in motor parameters affect both circuits and the resulting motion.</p> <p>Canvas layout: - Top left (40%): Electrical circuit schematic with live values - Top right (40%): Mechanical diagram with rotating load - Bottom (full width): Time response plots</p> <p>Visual elements: Electrical Schematic: - Armature circuit with R_a, L_a, voltage source - Back-EMF source (proportional to speed) - Current flow indicators - Live voltage and current displays</p> <p>Mechanical Diagram: - Motor rotor symbol - Rotating shaft with angle indicator - Connected inertia (disk) - Damper symbol - Angular velocity display</p> <p>Response Plots: - Armature current i_a(t) - Angular velocity \u03c9(t) - Applied voltage v_a(t) - Torque \u03c4(t)</p> <p>Interactive controls: - Slider: Armature voltage V_a (0 to 24 V) - Slider: Load inertia J (0.001 to 0.1 kg\u00b7m\u00b2) - Slider: Armature resistance R_a (0.5 to 5 \u03a9) - Slider: Torque constant K_t (0.01 to 0.1 N\u00b7m/A) - Toggle: Include/neglect inductance L_a - Button: Apply step voltage - Button: Apply load torque step</p> <p>Data Visibility Requirements: - Display all electrical quantities: v_a, i_a, e_b - Display all mechanical quantities: \u03c4, \u03c9, \u03b8 - Show power flow: P_elec = v_a\u00b7i_a, P_mech = \u03c4\u00b7\u03c9 - Display calculated time constants</p> <p>Behavior: - When voltage step applied, show current surge then decay - Show speed building up with electrical and mechanical dynamics - Back-EMF grows as speed increases, limiting current - Steady-state reached when torque equals friction load - Rotor animation synchronized with calculated velocity</p> <p>Instructional Rationale: Parallel visualization of electrical and mechanical domains shows the bidirectional coupling through K_t (current\u2192torque) and K_e (speed\u2192back-EMF). Students see that the motor is not just an electrical or mechanical system\u2014it's fundamentally both.</p> <p>Implementation: p5.js with coupled differential equation solver and synchronized animations</p> <p>Gyra Moment</p> <p>\"My motors are armature-controlled DC motors. When my controller commands a voltage, current surges through the armature, creating torque. As I start spinning, back-EMF builds up and opposes the current\u2014nature's built-in speed limiter. My engineers modeled this carefully: the torque constant tells them how much push I get per amp, and the back-EMF constant tells them how fast I resist acceleration. These two numbers, along with my inertia and friction, define who I am as a dynamic system.\"</p>"},{"location":"chapters/07-physical-system-modeling/#fluid-and-thermal-systems","title":"Fluid and Thermal Systems","text":"<p>While electrical, mechanical, and electromechanical systems are the primary focus of this course, two other domains appear frequently in industrial control: fluid systems and thermal systems. Understanding their models reinforces the analogous systems concept.</p>"},{"location":"chapters/07-physical-system-modeling/#fluid-systems","title":"Fluid Systems","text":"<p>Fluid systems involve the flow of liquids or gases through pipes, tanks, and valves. The relevant variables are pressure (analogous to voltage), flow rate (analogous to current), and fluid volume or mass.</p> <p>For an incompressible liquid tank with cross-sectional area \\(A\\) and outlet resistance \\(R\\):</p>"},{"location":"chapters/07-physical-system-modeling/#tank-level-dynamics","title":"Tank Level Dynamics","text":"<p>\\(A\\frac{dh}{dt} = q_{in} - q_{out} = q_{in} - \\frac{h}{R}\\)</p> <p>where:</p> <ul> <li>\\(h\\) is the liquid height</li> <li>\\(q_{in}\\) is the inlet flow rate</li> <li>\\(q_{out} = h/R\\) assumes laminar flow through the outlet</li> <li>\\(R\\) is the fluid resistance</li> </ul> <p>This gives a first-order transfer function relating inlet flow to level:</p> <p>\\(G(s) = \\frac{H(s)}{Q_{in}(s)} = \\frac{R}{ARs + 1} = \\frac{R}{\\tau s + 1}\\)</p> <p>where \\(\\tau = AR\\) is the tank time constant.</p> <p>Key fluid system elements:</p> Element Analogous To Relationship Fluid resistance Electrical resistance \\(\\Delta P = Rq\\) (pressure drop) Tank capacitance Electrical capacitance \\(C = A\\) (storage capacity) Fluid inertance Electrical inductance \\(\\Delta P = I(dq/dt)\\) (momentum)"},{"location":"chapters/07-physical-system-modeling/#thermal-systems","title":"Thermal Systems","text":"<p>Thermal systems involve heat flow and temperature. The relevant variables are temperature (analogous to voltage), heat flow rate (analogous to current), and thermal energy stored.</p> <p>For a body with thermal capacitance \\(C_{th}\\) and thermal resistance \\(R_{th}\\) to the environment at temperature \\(T_{amb}\\):</p>"},{"location":"chapters/07-physical-system-modeling/#thermal-dynamics","title":"Thermal Dynamics","text":"<p>\\(C_{th}\\frac{dT}{dt} = q_{in} - \\frac{T - T_{amb}}{R_{th}}\\)</p> <p>where:</p> <ul> <li>\\(T\\) is the body temperature</li> <li>\\(q_{in}\\) is the heat input rate</li> <li>\\(R_{th}\\) is the thermal resistance to ambient</li> <li>\\(C_{th}\\) is the thermal capacitance (mass \u00d7 specific heat)</li> </ul> <p>The transfer function from heat input to temperature rise above ambient:</p> <p>\\(G(s) = \\frac{T(s) - T_{amb}}{Q_{in}(s)} = \\frac{R_{th}}{R_{th}C_{th}s + 1} = \\frac{R_{th}}{\\tau_{th}s + 1}\\)</p> <p>Thermal systems are typically first-order with large time constants (minutes to hours for building heating, seconds for electronics cooling).</p> Thermal Element Analogous To Relationship Thermal resistance Electrical resistance \\(\\Delta T = R_{th}q\\) Thermal capacitance Electrical capacitance \\(C_{th} = mc_p\\) Temperature Voltage Driving potential Heat flow Current Flow quantity"},{"location":"chapters/07-physical-system-modeling/#analogous-systems","title":"Analogous Systems","text":"<p>One of the most powerful insights in engineering is that seemingly different physical systems often obey the same mathematical equations. A circuit, a mechanical system, a fluid tank, and a heating system can all be described by the same transfer function. This concept of analogous systems allows engineers to transfer intuition and analysis techniques across domains.</p> <p>The analogies arise because all linear physical systems are governed by conservation laws (energy, momentum, mass) and constitutive relations (component behaviors). The mathematics doesn't care whether the energy is stored in a capacitor or a spring, or whether the \"flow\" is electrical current or fluid volume rate.</p> <p>There are two main analogy conventions for relating electrical and mechanical systems:</p>"},{"location":"chapters/07-physical-system-modeling/#force-voltage-analogy-impedance-analogy","title":"Force-Voltage Analogy (Impedance Analogy)","text":"<p>The force-voltage analogy (also called the impedance analogy) maps:</p> Mechanical Electrical Force \\(F\\) Voltage \\(v\\) Velocity \\(v\\) Current \\(i\\) Displacement \\(x\\) Charge \\(q\\) Mass \\(m\\) Inductance \\(L\\) Damping \\(b\\) Resistance \\(R\\) Stiffness \\(k\\) 1/Capacitance \\(1/C\\) <p>The name \"impedance analogy\" comes from the fact that mechanical impedance \\(Z_m = F/v\\) maps to electrical impedance \\(Z_e = V/I\\).</p> <p>Under this analogy:</p> <ul> <li>A mass (stores kinetic energy, \\(E = \\frac{1}{2}mv^2\\)) is analogous to an inductor (stores magnetic energy, \\(E = \\frac{1}{2}Li^2\\))</li> <li>A spring (stores potential energy, \\(E = \\frac{1}{2}kx^2\\)) is analogous to a capacitor (stores electric energy, \\(E = \\frac{1}{2}Cv^2\\))</li> <li>A damper (dissipates energy, \\(P = bv^2\\)) is analogous to a resistor (dissipates energy, \\(P = Ri^2\\))</li> </ul> <p>Why Force Maps to Voltage</p> <p>In this analogy, elements in series in the mechanical domain (experiencing the same force) correspond to elements in series in the electrical domain (experiencing the same voltage). This makes circuit topology match mechanical topology.</p>"},{"location":"chapters/07-physical-system-modeling/#force-current-analogy-mobility-analogy","title":"Force-Current Analogy (Mobility Analogy)","text":"<p>The force-current analogy (also called the mobility analogy) provides an alternative mapping:</p> Mechanical Electrical Force \\(F\\) Current \\(i\\) Velocity \\(v\\) Voltage \\(v\\) Displacement \\(x\\) Flux linkage \\(\\lambda\\) Mass \\(m\\) Capacitance \\(C\\) Damping \\(b\\) 1/Resistance \\(1/R\\) Stiffness \\(k\\) 1/Inductance \\(1/L\\) <p>Under this analogy:</p> <ul> <li>A mass is analogous to a capacitor (both store energy proportional to the square of the \"across\" variable: velocity or voltage)</li> <li>A spring is analogous to an inductor (both store energy proportional to the square of the \"through\" variable: force or current)</li> <li>A damper is analogous to a conductance (reciprocal of resistance)</li> </ul> <p>Which Analogy to Use?</p> <p>Both analogies are valid and lead to correct transfer functions. The force-voltage analogy is more common in textbooks because it preserves series/parallel relationships. The force-current analogy is sometimes preferred in computer simulation because node voltages correspond to velocities, which are the natural state variables.</p>"},{"location":"chapters/07-physical-system-modeling/#diagram-analogous-systems-comparison","title":"Diagram: Analogous Systems Comparison","text":"Analogous Systems Comparison <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: compare, contrast</p> <p>Learning Objective: Students will compare the behavior of mechanical and electrical systems, observing that analogous systems with matched parameters produce identical transfer functions and responses.</p> <p>Canvas layout: - Top left: Mechanical system (mass-spring-damper) animation and schematic - Top right: Electrical system (RLC circuit) animation and schematic - Bottom: Shared response plot with both outputs overlaid</p> <p>Visual elements: Mechanical System: - Mass-spring-damper schematic - Animation of mass position - Parameter values: m, b, k - Applied force input indicator</p> <p>Electrical System: - RLC circuit schematic - Animation showing capacitor voltage as moving bar - Parameter values: L, R, C - Applied voltage input indicator</p> <p>Shared Response Plot: - Time axis - Mechanical response (displacement x or velocity v) - Electrical response (voltage or current) - Both curves overlaid showing identical dynamics - Legend distinguishing curves</p> <p>Parameter Mapping Panel: - Shows which analogy is active - Displays the mapping: m\u2194L, b\u2194R, k\u21941/C (force-voltage) - Calculated \u03c9_n and \u03b6 for both systems</p> <p>Interactive controls: - Radio buttons: Select analogy (Force-Voltage or Force-Current) - Slider: Natural frequency \u03c9_n (shared for both systems) - Slider: Damping ratio \u03b6 (shared for both systems) - Button: Apply step input to both - Button: Apply impulse to both - Toggle: Show/hide individual responses</p> <p>Data Visibility Requirements: - Display transfer functions for both systems - Show that they are identical in form - Display calculated component values based on \u03c9_n and \u03b6 - Show analogy mapping table</p> <p>Behavior: - Both systems animate simultaneously with step/impulse input - Response curves overlay exactly when analogy is correct - Changing \u03c9_n or \u03b6 updates both systems proportionally - Switching analogy changes the mapping but maintains identical response</p> <p>Instructional Rationale: Side-by-side visualization with overlaid responses proves that different physical systems can be mathematically identical. The shared sliders for \u03c9_n and \u03b6 emphasize that these are the fundamental parameters\u2014not the specific physical values.</p> <p>Implementation: p5.js with dual physics simulations and synchronized response plotting</p>"},{"location":"chapters/07-physical-system-modeling/#practical-value-of-analogies","title":"Practical Value of Analogies","text":"<p>The analogous systems concept isn't just academic elegance\u2014it has real practical value:</p> <ol> <li> <p>Transfer of intuition: If you understand how an RLC circuit behaves, you understand mass-spring-dampers, tank level systems, and thermal dynamics.</p> </li> <li> <p>Cross-domain modeling: Complex systems often span multiple domains. A motor-driven mechanical system involves electrical dynamics (armature circuit) coupled to mechanical dynamics (rotor and load). Analogies help create unified models.</p> </li> <li> <p>Simulation: Electrical circuit simulators (like SPICE) can model mechanical, thermal, and fluid systems by creating analogous electrical circuits. This was common before multi-domain simulators became widely available.</p> </li> <li> <p>Physical insight: Sometimes a behavior is more intuitive in one domain. The \"resonance\" of an RLC circuit might be easier to visualize than the corresponding mechanical oscillation, or vice versa.</p> </li> </ol> System Type Energy Storage 1 Energy Storage 2 Energy Dissipation Electrical Inductor (\\(L\\)) Capacitor (\\(C\\)) Resistor (\\(R\\)) Mech. Trans. Mass (\\(m\\)) Spring (\\(1/k\\)) Damper (\\(b\\)) Mech. Rot. Inertia (\\(J\\)) Torsion spring (\\(1/K\\)) Rot. damper (\\(B\\)) Fluid Inertance Tank (\\(A\\)) Resistance (\\(R_f\\)) Thermal \u2014 Capacitance (\\(C_{th}\\)) Resistance (\\(R_{th}\\))"},{"location":"chapters/07-physical-system-modeling/#systematic-modeling-procedure","title":"Systematic Modeling Procedure","text":"<p>Whether modeling electrical, mechanical, or electromechanical systems, a systematic approach prevents errors and builds understanding. Here's a recommended procedure:</p> <p>Step 1: Identify the System Boundary Determine what's inside your model (the \"plant\") and what's outside (inputs, disturbances, loads).</p> <p>Step 2: Choose Variables Select the minimum set of independent variables needed to describe the system state. These are typically \"across\" variables (voltage, velocity, temperature) at nodes and \"through\" variables (current, force, heat flow) in branches.</p> <p>Step 3: Apply Conservation Laws - Electrical: Kirchhoff's voltage law (KVL) and current law (KCL) - Mechanical: Newton's laws (force/torque balance) - Thermal/Fluid: Energy/mass conservation</p> <p>Step 4: Apply Constitutive Relations Relate the through and across variables for each component (Ohm's law, spring law, etc.).</p> <p>Step 5: Combine and Simplify Eliminate intermediate variables to get equations in terms of input(s) and output(s) only.</p> <p>Step 6: Take Laplace Transform Convert differential equations to algebraic equations in \\(s\\).</p> <p>Step 7: Solve for Transfer Function Express \\(G(s) = Output(s)/Input(s)\\).</p> <p>Step 8: Verify Check units, limiting cases (DC, high frequency), and physical reasonableness. Does the model behave as expected?</p> <p>Example: Modeling a Motor-Driven Mass</p> <p>Consider a DC motor (armature-controlled) connected through gears to a translational mass. The input is armature voltage \\(v_a\\); the output is mass position \\(x\\).</p> <p>Components: - Motor: \\(R_a\\), \\(L_a\\), \\(K_t\\), \\(K_e\\), rotor inertia \\(J_m\\), rotor damping \\(B_m\\) - Gears: ratio \\(N\\) (motor turns per output revolution) - Mass: \\(m\\), damping \\(b\\), plus rack-and-pinion with radius \\(r\\)</p> <p>Analysis approach: 1. Model motor electrically and mechanically 2. Reflect load to motor shaft through gears 3. Convert rotational motion to translation via rack-and-pinion 4. Combine into single transfer function \\(X(s)/V_a(s)\\)</p> <p>The result is a third-order system (electrical + two mechanical integrations), though often simplified by neglecting armature inductance.</p>"},{"location":"chapters/07-physical-system-modeling/#key-takeaways","title":"Key Takeaways","text":"<p>This chapter developed the essential skill of physical system modeling\u2014translating real-world systems into mathematical descriptions suitable for control analysis and design.</p> <p>Electrical Systems: - RC, RL circuits are first-order systems with time constants \\(\\tau = RC\\) or \\(\\tau = L/R\\) - RLC circuits are second-order with natural frequency \\(\\omega_n = 1/\\sqrt{LC}\\) and damping ratio \\(\\zeta = (R/2)\\sqrt{C/L}\\) - Op-amp circuits enable active operations: gain, integration, differentiation</p> <p>Mechanical Systems: - Translational and rotational systems share parallel structures - Mass-spring-damper is the canonical second-order mechanical system - Gear trains transform speed and torque with ratio \\(N\\); inertia reflects by \\(N^2\\) - Nonlinear systems (like pendulums) can be linearized for small deviations</p> <p>Electromechanical Systems: - DC motors couple electrical and mechanical dynamics - Armature-controlled motors relate voltage to speed via coupled first/second-order dynamics - Torque constant \\(K_t\\) and back-EMF constant \\(K_e\\) characterize the coupling</p> <p>Analogous Systems: - Different physical domains obey similar mathematical structures - Force-voltage and force-current analogies relate mechanical to electrical systems - Analogies enable transfer of insight across disciplines</p> <p>The transfer functions derived in this chapter are the starting point for the stability analysis, frequency response methods, and controller design techniques covered in subsequent chapters. A good model is the foundation of good control.</p> Self-Check: Test Your Understanding <p>Before moving on, verify you can answer these:</p> <ol> <li> <p>An RC circuit has R = 10 k\u03a9 and C = 0.1 \u03bcF. What is the time constant? What is the pole location?</p> </li> <li> <p>A mass-spring-damper has m = 2 kg, k = 50 N/m, b = 4 N\u00b7s/m. Calculate \u03c9_n and \u03b6. Is it underdamped, critically damped, or overdamped?</p> </li> <li> <p>A motor has K_t = 0.05 N\u00b7m/A and K_e = 0.05 V\u00b7s/rad. If the motor runs at 100 rad/s, what back-EMF is generated?</p> </li> <li> <p>In the force-voltage analogy, what electrical component is analogous to a mechanical spring?</p> </li> <li> <p>Why do we often neglect armature inductance when modeling DC motors?</p> </li> </ol> <p>If you can answer all five, you're ready to analyze stability and design controllers in the chapters ahead!</p>"},{"location":"chapters/08-linearization-nonlinear-effects/","title":"Linearization and Nonlinear Effects","text":""},{"location":"chapters/08-linearization-nonlinear-effects/#summary","title":"Summary","text":"<p>This chapter addresses the challenge of analyzing systems that are inherently nonlinear. Students will learn to identify operating points and equilibrium conditions, apply Taylor series expansion to linearize nonlinear system equations, and perform small-signal analysis around operating points. The chapter also introduces common nonlinear phenomena encountered in real systems including saturation, dead zones, backlash, and hysteresis. Understanding these effects helps engineers anticipate when linear analysis may be insufficient.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 10 concepts from the learning graph:</p> <ol> <li>Linearization</li> <li>Operating Point</li> <li>Equilibrium Point</li> <li>Small Signal Analysis</li> <li>Taylor Series Expansion</li> <li>Nonlinear System</li> <li>Saturation</li> <li>Dead Zone</li> <li>Backlash</li> <li>Hysteresis</li> </ol>"},{"location":"chapters/08-linearization-nonlinear-effects/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 2: Dynamic System Properties</li> <li>Chapter 7: Physical System Modeling</li> </ul>"},{"location":"chapters/08-linearization-nonlinear-effects/#the-uncomfortable-truth-about-real-systems","title":"The Uncomfortable Truth About Real Systems","text":"<p>In Chapter 2, we celebrated the Linear Time-Invariant (LTI) system as the foundation of classical control theory. In Chapter 7, we derived transfer functions for electrical, mechanical, and electromechanical systems\u2014treating them as nice, well-behaved linear creatures. But here's the awkward confession: almost every real physical system is nonlinear.</p> <p>Springs stiffen at large deflections. Amplifiers saturate. Gears have backlash. Valves stick. Motors have friction that isn't purely viscous. Even the simple pendulum\u2014that textbook favorite\u2014follows a \\(\\sin\\theta\\) relationship that defies linearity.</p> <p>So why didn't we mention this earlier? Because there's a powerful saving grace: many nonlinear systems behave approximately linear over a limited operating range. The art of linearization is extracting a useful linear model from a fundamentally nonlinear reality, valid near a specific operating point. This isn't mathematical wishful thinking\u2014it's a principled approximation that works remarkably well in practice.</p> <p>This chapter develops the tools to:</p> <ul> <li>Identify where a system \"wants to be\" (equilibrium points)</li> <li>Approximate nonlinear behavior with linear models (Taylor series linearization)</li> <li>Analyze small deviations from the operating point (small-signal analysis)</li> <li>Recognize common nonlinear effects that can't be linearized away</li> </ul> <p>Gyra Moment</p> <p>\"Here's my confession: I'm deeply, fundamentally nonlinear. My motors saturate when I'm falling fast. Gravity acts through \\(\\sin\\theta\\), not \\(\\theta\\). There's friction that sticks before it slips. But here's the beautiful thing\u2014when I'm nearly upright and things are calm, I behave almost linearly. That's when your LTI tools work on me. My engineers call it my 'sweet spot,' and their job is to keep me there.\"</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#nonlinear-systems-a-closer-look","title":"Nonlinear Systems: A Closer Look","text":"<p>A nonlinear system is any system that doesn't satisfy the superposition principle. Recall from Chapter 2 that linear systems obey two rules: homogeneity (scale the input, scale the output proportionally) and additivity (add inputs, add outputs). Nonlinear systems violate one or both of these properties.</p> <p>Nonlinearity manifests in differential equations through:</p> Nonlinear Feature Example Physical Interpretation Products of variables \\(y \\cdot \\frac{dy}{dt}\\) Velocity-dependent friction Powers other than 1 \\(y^2\\), \\(\\sqrt{y}\\) Aerodynamic drag, flow through orifice Transcendental functions \\(\\sin y\\), \\(e^y\\) Pendulum angle, thermal radiation Variable coefficients \\((1+y)k\\) Hardening spring Discontinuities \\(\\text{sign}(v)\\) Coulomb friction <p>Consider the simple pendulum from Chapter 7. The true equation of motion is:</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#true-pendulum-equation","title":"True Pendulum Equation","text":"<p>\\(mL^2\\frac{d^2\\theta}{dt^2} + B\\frac{d\\theta}{dt} + mgL\\sin\\theta = \\tau\\)</p> <p>where:</p> <ul> <li>\\(m\\) is the pendulum mass</li> <li>\\(L\\) is the pendulum length</li> <li>\\(B\\) is the damping coefficient</li> <li>\\(g\\) is gravitational acceleration</li> <li>\\(\\theta\\) is the angle from vertical</li> <li>\\(\\tau\\) is the applied torque</li> </ul> <p>The \\(\\sin\\theta\\) term makes this nonlinear. Doubling the initial angle does not double the response. Adding two angle solutions does not give the solution for the sum of initial angles. Superposition fails.</p> <p>The same pendulum equation we linearized in Chapter 7 using \\(\\sin\\theta \\approx \\theta\\) is our prototype example for this chapter. That approximation isn't magic\u2014it's a Taylor series truncation, and understanding when and why it works is essential for applying linearization to any nonlinear system.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#diagram-linear-vs-nonlinear-response-comparison","title":"Diagram: Linear vs Nonlinear Response Comparison","text":"Linear vs Nonlinear Response Comparison <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: compare, contrast</p> <p>Learning Objective: Students will analyze how linear and nonlinear systems respond differently to scaled and combined inputs, demonstrating that superposition fails for nonlinear systems.</p> <p>Canvas layout: - Top (50%): Two response plots side by side   - Left: Linear system responses   - Right: Nonlinear (pendulum) system responses - Bottom (50%): Controls and superposition test display</p> <p>Visual elements: Linear System Panel: - Response to input u\u2081(t) - Response to input 2\u00b7u\u2081(t) - Shows that 2\u00b7y\u2081(t) overlays exactly with response to 2\u00b7u\u2081(t)</p> <p>Nonlinear System Panel: - Response to input \u03b8\u2081(0) initial angle - Response to input 2\u00b7\u03b8\u2081(0) initial angle - Shows that 2\u00b7y\u2081(t) does NOT match response to 2\u00b7\u03b8\u2081(0) - Difference highlighted in red</p> <p>Superposition Test: - Numerical comparison: \"Expected (if linear): X, Actual: Y, Error: Z%\"</p> <p>Interactive controls: - Slider: Initial angle \u03b8\u2081(0) for pendulum (5\u00b0 to 45\u00b0) - Slider: Damping ratio (0.1 to 1.0) - Radio buttons: Test type (Homogeneity test, Additivity test) - Button: Run comparison - Button: Reset</p> <p>Data Visibility Requirements: - Display both linear prediction and actual nonlinear response - Show percentage deviation from linear behavior - For homogeneity: compare 2\u00b7y(\u03b8\u2080) with y(2\u03b8\u2080) - For additivity: compare y(\u03b8\u2081+\u03b8\u2082) with y(\u03b8\u2081)+y(\u03b8\u2082)</p> <p>Behavior: - For small angles, curves nearly overlap (linear approximation valid) - For large angles, significant deviation appears - Error percentage increases with angle magnitude - Visual emphasis on where linearity breaks down</p> <p>Instructional Rationale: Direct visual comparison between linear and nonlinear responses makes abstract superposition failure concrete. Students see that the discrepancy grows with signal amplitude.</p> <p>Implementation: p5.js with differential equation solver (Runge-Kutta) for pendulum dynamics</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#equilibrium-points-where-systems-want-to-rest","title":"Equilibrium Points: Where Systems Want to Rest","text":"<p>Before linearizing a nonlinear system, we must first ask: linearize around what? The answer is the equilibrium point (also called a fixed point or steady-state)\u2014a condition where the system remains at rest if undisturbed.</p> <p>An equilibrium point is a state where all derivatives are zero when the input is constant. For a system described by:</p> <p>\\(\\frac{dx}{dt} = f(x, u)\\)</p> <p>the equilibrium point \\((x_e, u_e)\\) satisfies:</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#equilibrium-condition","title":"Equilibrium Condition","text":"<p>\\(f(x_e, u_e) = 0\\)</p> <p>where:</p> <ul> <li>\\(x_e\\) is the equilibrium state</li> <li>\\(u_e\\) is the constant input at equilibrium</li> <li>\\(f\\) is the system dynamics function</li> </ul> <p>For the pendulum with constant torque input \\(\\tau_e\\):</p> <p>\\(0 = -\\frac{B}{mL^2}\\dot{\\theta} - \\frac{g}{L}\\sin\\theta_e + \\frac{\\tau_e}{mL^2}\\)</p> <p>With \\(\\dot{\\theta} = 0\\) at equilibrium:</p> <p>\\(\\sin\\theta_e = \\frac{\\tau_e}{mgL}\\)</p> <p>If \\(\\tau_e = 0\\) (no applied torque), then \\(\\theta_e = 0\\) (hanging down) or \\(\\theta_e = \\pi\\) (balanced up) are equilibrium points. Only \\(\\theta_e = 0\\) is stable\u2014small disturbances die out. At \\(\\theta_e = \\pi\\), the pendulum is balanced but any tiny nudge sends it falling.</p> <p>Equilibrium vs Operating Point</p> <p>The terms \"equilibrium point\" and \"operating point\" are related but not identical. An equilibrium point is a special state where derivatives vanish\u2014the system is truly at rest. An operating point is more general: it's any steady-state condition around which we choose to linearize, which might involve constant motion (like a motor spinning at constant speed) rather than absolute stillness.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#finding-equilibrium-points","title":"Finding Equilibrium Points","text":"<p>For systems with multiple variables, finding equilibrium points requires solving simultaneous algebraic equations. Consider a system with two state variables:</p> <p>\\(\\frac{dx_1}{dt} = f_1(x_1, x_2, u)\\)</p> <p>\\(\\frac{dx_2}{dt} = f_2(x_1, x_2, u)\\)</p> <p>Setting both derivatives to zero gives:</p> <p>\\(f_1(x_{1e}, x_{2e}, u_e) = 0\\)</p> <p>\\(f_2(x_{1e}, x_{2e}, u_e) = 0\\)</p> <p>This system of equations may have zero, one, or multiple solutions\u2014corresponding to no equilibrium, a unique equilibrium, or multiple equilibria (like the pendulum's up and down positions).</p> System Equilibrium Condition Example Equilibria Pendulum \\(\\sin\\theta_e = \\tau_e/(mgL)\\) \\(\\theta = 0\\) (stable), \\(\\theta = \\pi\\) (unstable) Tank level \\(q_{in} = q_{out}(h_e)\\) Level where inflow equals outflow DC motor \\(K_t i_a = B\\omega_e + \\tau_L\\) Speed where motor torque equals load Thermostat \\(q_{heating} = q_{loss}(T_e)\\) Temperature where heat in equals heat out <p>Helping Gyra</p> <p>\"I have exactly one equilibrium point I care about: perfectly vertical at \\(\\theta = 0\\). That's where I want to be. There's technically another equilibrium at \\(\\theta = \\pi\\)\u2014upside down\u2014but let's not talk about that. It's unstable anyway. My control system's entire job is to keep me near my preferred equilibrium. When I drift away, the controller applies torque to bring me back. It's a constant negotiation with gravity.\"</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#operating-points-the-foundation-of-linearization","title":"Operating Points: The Foundation of Linearization","text":"<p>An operating point is the steady-state condition around which we linearize a nonlinear system. For equilibrium points, this means zero derivatives. For systems in steady motion (like a motor at constant speed), the operating point includes constant rates of change.</p> <p>Consider a DC motor driving a load at constant speed \\(\\omega_0\\) with armature voltage \\(V_0\\). The operating point satisfies:</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#motor-operating-point","title":"Motor Operating Point","text":"<p>\\(V_0 = R_a I_0 + K_e \\omega_0\\)</p> <p>\\(K_t I_0 = B\\omega_0 + \\tau_L\\)</p> <p>where:</p> <ul> <li>\\(V_0\\) is the steady-state armature voltage</li> <li>\\(I_0\\) is the steady-state armature current</li> <li>\\(\\omega_0\\) is the steady-state angular velocity</li> <li>\\(\\tau_L\\) is the constant load torque</li> </ul> <p>At the operating point, electrical power in equals mechanical power out plus losses. The motor is in equilibrium with its load.</p> <p>To linearize, we analyze small deviations from this operating point:</p> <p>\\(v_a(t) = V_0 + \\Delta v_a(t)\\)</p> <p>\\(\\omega(t) = \\omega_0 + \\Delta \\omega(t)\\)</p> <p>\\(i_a(t) = I_0 + \\Delta i_a(t)\\)</p> <p>The deviations \\(\\Delta v_a\\), \\(\\Delta \\omega\\), \\(\\Delta i_a\\) are the \"small signals\" we analyze. The operating point values \\(V_0\\), \\(\\omega_0\\), \\(I_0\\) are the \"DC bias\" or \"quiescent point.\"</p> <p>This separation is powerful because the small-signal dynamics are often linear even when the full system is not. We sacrifice information about the absolute values to gain the ability to use transfer functions, frequency response, and all our LTI tools.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#diagram-operating-point-concept-visualizer","title":"Diagram: Operating Point Concept Visualizer","text":"Operating Point Concept Visualizer <p>Type: microsim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: explain, interpret</p> <p>Learning Objective: Students will interpret the relationship between operating point, small-signal deviations, and the total system response by visualizing how signals decompose into DC and AC components.</p> <p>Canvas layout: - Left (60%): Time-domain plot showing signal decomposition - Right (40%): Operating point diagram and explanation</p> <p>Visual elements: Time Plot: - Total signal (black solid line): \\(x(t) = X_0 + \\Delta x(t)\\) - Operating point level (blue dashed horizontal line): \\(X_0\\) - Small signal deviation (green): \\(\\Delta x(t)\\) - Shaded region between operating point and total signal</p> <p>Operating Point Diagram: - Vertical axis representing the signal variable - Marked operating point with label - Arrows showing deviation range - \"Linear region\" bracket showing valid range for linearization</p> <p>Interactive controls: - Slider: Operating point value \\(X_0\\) (adjustable range) - Slider: Small signal amplitude (0 to 20% of operating point) - Slider: Small signal frequency - Toggle: Show/hide components individually - Button: Reset to defaults</p> <p>Data Visibility Requirements: - Display numerical value of operating point - Display peak deviation magnitude - Show ratio: deviation/operating_point (should be small for valid linearization) - Warning indicator when deviation exceeds \"small signal\" validity</p> <p>Behavior: - Total signal moves up/down as operating point changes - Small signal oscillates around operating point - Color coding shows valid vs questionable linearization region - Visual warning when deviation amplitude is too large</p> <p>Instructional Rationale: Visualizing the decomposition of a signal into DC (operating point) and AC (small signal) components builds intuition for what linearization actually means physically. The warning for large deviations reinforces validity limits.</p> <p>Implementation: p5.js with real-time signal generation and annotation</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#taylor-series-expansion-the-mathematical-engine","title":"Taylor Series Expansion: The Mathematical Engine","text":"<p>Taylor series expansion is the mathematical tool that powers linearization. It allows us to approximate any smooth function as a polynomial, with accuracy improving as we include more terms.</p> <p>For a function \\(f(x)\\) expanded around point \\(x_0\\):</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#taylor-series-formula","title":"Taylor Series Formula","text":"<p>\\(f(x) = f(x_0) + \\frac{df}{dx}\\bigg|_{x_0}(x - x_0) + \\frac{1}{2!}\\frac{d^2f}{dx^2}\\bigg|_{x_0}(x - x_0)^2 + \\cdots\\)</p> <p>where:</p> <ul> <li>\\(f(x_0)\\) is the function value at the expansion point</li> <li>\\(\\frac{df}{dx}\\big|_{x_0}\\) is the first derivative evaluated at \\(x_0\\)</li> <li>\\((x - x_0)\\) is the deviation from the expansion point</li> <li>Higher-order terms contain higher powers of \\((x - x_0)\\)</li> </ul> <p>For linearization, we truncate after the first-order term:</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#linear-approximation","title":"Linear Approximation","text":"<p>\\(f(x) \\approx f(x_0) + \\frac{df}{dx}\\bigg|_{x_0}(x - x_0)\\)</p> <p>This approximation is valid when \\((x - x_0)\\) is \"small\" so that the quadratic and higher terms are negligible.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#example-linearizing-sin","title":"Example: Linearizing sin(\u03b8)","text":"<p>The pendulum's \\(\\sin\\theta\\) term linearizes around \\(\\theta_0 = 0\\):</p> <p>\\(\\sin\\theta \\approx \\sin(0) + \\cos(0) \\cdot (\\theta - 0) = 0 + 1 \\cdot \\theta = \\theta\\)</p> <p>The famous small-angle approximation! But where did it come from? The Taylor series:</p> <ul> <li>\\(f(\\theta) = \\sin\\theta\\)</li> <li>\\(f(0) = \\sin(0) = 0\\)</li> <li>\\(f'(0) = \\cos(0) = 1\\)</li> <li>Linear approximation: \\(\\sin\\theta \\approx \\theta\\)</li> </ul> <p>For expansion around \\(\\theta_0 \\neq 0\\):</p> <p>\\(\\sin\\theta \\approx \\sin\\theta_0 + \\cos\\theta_0 \\cdot (\\theta - \\theta_0)\\)</p> <p>The slope of the approximation depends on where you expand. At \\(\\theta_0 = 0\\), the slope is \\(\\cos(0) = 1\\). At \\(\\theta_0 = \\pi/2\\), the slope is \\(\\cos(\\pi/2) = 0\\)\u2014the function is locally flat at its peak.</p> Function Expansion Point Linear Approximation \\(\\sin\\theta\\) \\(\\theta_0 = 0\\) \\(\\theta\\) \\(\\cos\\theta\\) \\(\\theta_0 = 0\\) \\(1\\) (constant) \\(e^x\\) \\(x_0 = 0\\) \\(1 + x\\) \\(\\ln(1+x)\\) \\(x_0 = 0\\) \\(x\\) \\(\\sqrt{1+x}\\) \\(x_0 = 0\\) \\(1 + \\frac{x}{2}\\) \\((1+x)^n\\) \\(x_0 = 0\\) \\(1 + nx\\)"},{"location":"chapters/08-linearization-nonlinear-effects/#diagram-taylor-series-approximation-explorer","title":"Diagram: Taylor Series Approximation Explorer","text":"Taylor Series Approximation Explorer <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: demonstrate, calculate</p> <p>Learning Objective: Students will apply Taylor series expansion to approximate nonlinear functions, observing how the approximation accuracy depends on the expansion point and the number of terms included.</p> <p>Canvas layout: - Main area (70%): Function plot with Taylor approximations - Side panel (30%): Controls and error display</p> <p>Visual elements: Function Plot: - Original nonlinear function (black solid curve): sin(\u03b8), cos(\u03b8), e^x, etc. - Linear approximation (blue dashed line) - Quadratic approximation (green dotted line, optional) - Expansion point marker (red dot) - Vertical lines showing valid region where error &lt; threshold</p> <p>Error Display: - Numerical error at current cursor position - Shaded region showing approximation validity</p> <p>Interactive controls: - Dropdown: Function to approximate (sin, cos, exp, sqrt, ln) - Slider: Expansion point x\u2080 (-\u03c0 to \u03c0 for trig, -2 to 2 for others) - Slider: View range - Radio buttons: Approximation order (1st order, 2nd order, 3rd order) - Toggle: Show error shading - Mouse: Hover to see error at specific x values</p> <p>Data Visibility Requirements: - Display Taylor series formula with numerical coefficients - Show function value f(x\u2080) and slope f'(x\u2080) at expansion point - Display error magnitude at cursor position - Show \"valid range\" where error &lt; 5%</p> <p>Behavior: - Tangent line updates as expansion point moves - Higher-order approximations show better fit over wider range - Error shading shows where approximation breaks down - Cursor displays exact values and errors</p> <p>Instructional Rationale: Interactive manipulation of the expansion point and order builds geometric intuition for Taylor series. Seeing the tangent line as the linear approximation connects calculus concepts to linearization practice.</p> <p>Implementation: p5.js with real-time function plotting and derivative calculation</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#multivariable-taylor-expansion","title":"Multivariable Taylor Expansion","text":"<p>For systems with multiple variables, we need the multivariable Taylor expansion. For a function \\(f(x_1, x_2)\\) around operating point \\((x_{10}, x_{20})\\):</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#multivariable-linear-approximation","title":"Multivariable Linear Approximation","text":"<p>\\(f(x_1, x_2) \\approx f(x_{10}, x_{20}) + \\frac{\\partial f}{\\partial x_1}\\bigg|_0 (x_1 - x_{10}) + \\frac{\\partial f}{\\partial x_2}\\bigg|_0 (x_2 - x_{20})\\)</p> <p>where:</p> <ul> <li>\\(\\frac{\\partial f}{\\partial x_1}\\big|_0\\) is the partial derivative with respect to \\(x_1\\) at the operating point</li> <li>\\(\\frac{\\partial f}{\\partial x_2}\\big|_0\\) is the partial derivative with respect to \\(x_2\\) at the operating point</li> </ul> <p>The partial derivatives evaluated at the operating point become the coefficients of the linearized model. This is how nonlinear coupling between variables gets \"frozen\" into constant coefficients for small-signal analysis.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#linearization-procedure-a-systematic-approach","title":"Linearization Procedure: A Systematic Approach","text":"<p>Linearizing a nonlinear system follows a systematic procedure. Here's the step-by-step approach:</p> <p>Step 1: Write the Nonlinear System Equations</p> <p>Express the system as first-order differential equations:</p> <p>\\(\\frac{dx}{dt} = f(x, u)\\)</p> <p>\\(y = g(x, u)\\)</p> <p>where \\(x\\) is the state, \\(u\\) is the input, and \\(y\\) is the output.</p> <p>Step 2: Find the Operating Point</p> <p>Solve for the equilibrium or steady-state condition:</p> <p>\\(f(x_0, u_0) = 0\\)</p> <p>\\(y_0 = g(x_0, u_0)\\)</p> <p>Step 3: Define Deviation Variables</p> <p>Introduce small deviations from the operating point:</p> <p>\\(\\Delta x = x - x_0\\)</p> <p>\\(\\Delta u = u - u_0\\)</p> <p>\\(\\Delta y = y - y_0\\)</p> <p>Step 4: Apply Taylor Series</p> <p>Expand the nonlinear functions and keep only first-order terms:</p> <p>\\(f(x, u) \\approx f(x_0, u_0) + \\frac{\\partial f}{\\partial x}\\bigg|_0 \\Delta x + \\frac{\\partial f}{\\partial u}\\bigg|_0 \\Delta u\\)</p> <p>Since \\(f(x_0, u_0) = 0\\) at equilibrium:</p> <p>\\(\\frac{d(\\Delta x)}{dt} = \\frac{\\partial f}{\\partial x}\\bigg|_0 \\Delta x + \\frac{\\partial f}{\\partial u}\\bigg|_0 \\Delta u\\)</p> <p>Step 5: Write the Linearized Model</p> <p>Define the linearized coefficients:</p> <p>\\(A = \\frac{\\partial f}{\\partial x}\\bigg|_0, \\quad B = \\frac{\\partial f}{\\partial u}\\bigg|_0\\)</p> <p>The linearized system is:</p> <p>\\(\\frac{d(\\Delta x)}{dt} = A \\cdot \\Delta x + B \\cdot \\Delta u\\)</p> <p>Step 6: Derive the Transfer Function</p> <p>Take the Laplace transform and solve for the transfer function:</p> <p>\\(s\\Delta X(s) = A \\cdot \\Delta X(s) + B \\cdot \\Delta U(s)\\)</p> <p>\\((s - A)\\Delta X(s) = B \\cdot \\Delta U(s)\\)</p> <p>\\(G(s) = \\frac{\\Delta X(s)}{\\Delta U(s)} = \\frac{B}{s - A}\\)</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#example-linearizing-a-tank-level-system","title":"Example: Linearizing a Tank Level System","text":"<p>Consider a tank with cross-sectional area \\(A\\), inlet flow rate \\(q_{in}\\), and outlet flow through an orifice where flow depends nonlinearly on height:</p> <p>\\(q_{out} = k\\sqrt{h}\\)</p> <p>The governing equation is:</p> <p>\\(A\\frac{dh}{dt} = q_{in} - k\\sqrt{h}\\)</p> <p>This is nonlinear due to the \\(\\sqrt{h}\\) term.</p> <p>Step 1: Nonlinear equation</p> <p>\\(\\frac{dh}{dt} = \\frac{1}{A}(q_{in} - k\\sqrt{h})\\)</p> <p>Step 2: Operating point</p> <p>At steady state with \\(q_{in} = Q_0\\):</p> <p>\\(0 = Q_0 - k\\sqrt{h_0}\\)</p> <p>\\(h_0 = (Q_0/k)^2\\)</p> <p>Step 3: Deviation variables</p> <p>\\(\\Delta h = h - h_0\\), \\(\\Delta q = q_{in} - Q_0\\)</p> <p>Step 4: Taylor series</p> <p>\\(\\sqrt{h} \\approx \\sqrt{h_0} + \\frac{1}{2\\sqrt{h_0}}(h - h_0) = \\sqrt{h_0} + \\frac{1}{2\\sqrt{h_0}}\\Delta h\\)</p> <p>Substituting:</p> <p>\\(\\frac{d(\\Delta h)}{dt} = \\frac{1}{A}\\left(\\Delta q - \\frac{k}{2\\sqrt{h_0}}\\Delta h\\right)\\)</p> <p>Step 5: Linearized model</p> <p>Define: \\(R = \\frac{2\\sqrt{h_0}}{k} = \\frac{2h_0}{Q_0}\\) (effective resistance)</p> <p>\\(\\frac{d(\\Delta h)}{dt} = -\\frac{1}{AR}\\Delta h + \\frac{1}{A}\\Delta q\\)</p> <p>Step 6: Transfer function</p> <p>\\(G(s) = \\frac{\\Delta H(s)}{\\Delta Q(s)} = \\frac{R}{ARs + 1} = \\frac{R}{\\tau s + 1}\\)</p> <p>The linearized system is first-order with time constant \\(\\tau = AR\\) and DC gain \\(R\\). But notice: \\(R\\) depends on the operating point \\(h_0\\). At higher tank levels, the effective resistance is larger, meaning the system responds more slowly. The \"same\" physical system has different linearized dynamics at different operating points!</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#small-signal-analysis-working-with-deviations","title":"Small Signal Analysis: Working with Deviations","text":"<p>Small signal analysis is the practice of analyzing system behavior in terms of deviations from an operating point. It's the practical application of linearization\u2014separating the steady-state (DC) response from the dynamic (AC) response.</p> <p>The key insight is that the small-signal transfer function relates deviations in output to deviations in input:</p> <p>\\(G(s) = \\frac{\\Delta Y(s)}{\\Delta U(s)}\\)</p> <p>This transfer function is computed at a specific operating point and is only valid for small excursions around that point. Large deviations invalidate the linearization.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#validity-of-small-signal-analysis","title":"Validity of Small Signal Analysis","text":"<p>How \"small\" is small enough? There's no universal answer\u2014it depends on:</p> <ol> <li> <p>How nonlinear the system is: Systems with sharp nonlinearities (saturation edges, dead zone boundaries) require smaller signals than gently curved nonlinearities.</p> </li> <li> <p>Acceptable error: For rough analysis, 10-20% error might be acceptable. For precision control, less than 1% might be required.</p> </li> <li> <p>Safety margins: In safety-critical systems, you might require the linearization to be valid over the entire expected operating range plus margins.</p> </li> </ol> <p>A practical approach is to:</p> <ul> <li>Linearize the system</li> <li>Simulate the full nonlinear system</li> <li>Compare the responses</li> <li>Determine the amplitude where they diverge unacceptably</li> </ul> <p>Operating Point Dependence</p> <p>The linearized model depends on the operating point! A motor linearized at 1000 RPM has different transfer function coefficients than the same motor linearized at 5000 RPM. If your system operates over a wide range, you may need multiple linearized models or gain scheduling to account for this variation.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#diagram-small-signal-validity-checker","title":"Diagram: Small Signal Validity Checker","text":"Small Signal Validity Checker <p>Type: microsim</p> <p>Bloom Taxonomy: Evaluate (L5) Bloom Verb: assess, validate</p> <p>Learning Objective: Students will evaluate the validity of small-signal linearization by comparing linear model predictions to actual nonlinear system responses, determining the amplitude threshold where linearization breaks down.</p> <p>Canvas layout: - Top (60%): Dual response plot (nonlinear vs linearized) - Bottom (40%): Error analysis and validity indicator</p> <p>Visual elements: Response Plot: - Nonlinear system response (solid black) - Linearized model prediction (dashed blue) - Difference/error (red, optional overlay) - Operating point reference line</p> <p>Error Analysis Panel: - Error magnitude vs time or vs signal amplitude - Threshold line for \"acceptable\" error - Validity indicator: green (valid), yellow (marginal), red (invalid) - Maximum error percentage display</p> <p>Interactive controls: - Dropdown: System type (pendulum, tank, saturating amplifier) - Slider: Operating point - Slider: Input amplitude (small to large) - Slider: Error threshold (1% to 20%) - Button: Step input test - Button: Sinusoidal input test - Toggle: Show error overlay</p> <p>Data Visibility Requirements: - Display RMS error between nonlinear and linear responses - Show peak instantaneous error - Display \"valid up to X% of operating point\" recommendation - Track error vs amplitude relationship</p> <p>Behavior: - For small inputs, responses overlay closely - As input amplitude increases, discrepancy grows - Error indicator changes color at threshold - System clearly shows when linearization fails</p> <p>Instructional Rationale: Quantitative comparison between nonlinear reality and linear approximation develops judgment about when linearization is trustworthy. The error threshold visualization makes the abstract \"small signal\" concept concrete.</p> <p>Implementation: p5.js with dual differential equation solvers and error computation</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#example-small-signal-analysis-of-a-pendulum","title":"Example: Small Signal Analysis of a Pendulum","text":"<p>For a pendulum linearized around \\(\\theta_0 = 0\\):</p> <p>Nonlinear: \\(\\ddot{\\theta} + \\frac{B}{J}\\dot{\\theta} + \\frac{g}{L}\\sin\\theta = \\frac{\\tau}{J}\\)</p> <p>Linearized: \\(\\ddot{\\theta} + \\frac{B}{J}\\dot{\\theta} + \\frac{g}{L}\\theta = \\frac{\\tau}{J}\\)</p> <p>The small-signal transfer function from torque to angle is:</p> <p>\\(G(s) = \\frac{\\Theta(s)}{T(s)} = \\frac{1/J}{s^2 + \\frac{B}{J}s + \\frac{g}{L}}\\)</p> <p>This is a standard second-order system with:</p> <ul> <li>Natural frequency: \\(\\omega_n = \\sqrt{g/L}\\)</li> <li>Damping ratio: \\(\\zeta = \\frac{B}{2J\\omega_n}\\)</li> </ul> <p>But this is only valid for small angles! At \\(\\theta = 30\u00b0\\) (0.52 rad), the error in the \\(\\sin\\theta \\approx \\theta\\) approximation is:</p> <p>\\(\\text{Error} = \\frac{|\\sin(0.52) - 0.52|}{|\\sin(0.52)|} = \\frac{|0.497 - 0.52|}{0.497} \\approx 4.6\\%\\)</p> <p>At \\(\\theta = 60\u00b0\\) (1.05 rad), the error jumps to about 17%. For many engineering applications, 5% error is the threshold where the linear model becomes questionable.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#common-nonlinear-effects-in-real-systems","title":"Common Nonlinear Effects in Real Systems","text":"<p>While linearization handles smooth nonlinearities well, certain nonlinear effects have sharp features that resist linearization. These are important to recognize because they can cause unexpected behavior in systems that otherwise appear linear.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#saturation","title":"Saturation","text":"<p>Saturation occurs when a system's output reaches a physical limit and can no longer increase regardless of input. It's the most common nonlinearity in control systems.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#saturation-characteristic","title":"Saturation Characteristic","text":"<p>\\(y = \\begin{cases} u_{max} &amp; \\text{if } u &gt; u_{max} \\\\ u &amp; \\text{if } -u_{max} \\leq u \\leq u_{max} \\\\ -u_{max} &amp; \\text{if } u &lt; -u_{max} \\end{cases}\\)</p> <p>where:</p> <ul> <li>\\(y\\) is the saturated output</li> <li>\\(u\\) is the input</li> <li>\\(u_{max}\\) is the saturation limit</li> </ul> <p>Examples of saturation:</p> <ul> <li>Amplifier output voltage hitting the power supply rails</li> <li>Motor torque limited by maximum current</li> <li>Valve fully open or fully closed</li> <li>Control surface deflection limits on aircraft</li> <li>Actuator position limits</li> </ul> <p>Saturation affects closed-loop systems in insidious ways. When a controller's output saturates, the system can't respond as aggressively as the controller commands. This mismatch between commanded and actual control effort causes:</p> <ul> <li>Delayed response: The system takes longer to reach setpoint</li> <li>Integrator windup: An integral controller keeps accumulating error during saturation, causing overshoot when saturation ends</li> <li>Loss of stability margins: The effective loop gain drops during saturation</li> </ul> <p>Gyra Moment</p> <p>\"Saturation is my nemesis. When I'm falling fast and my controller screams for maximum torque, my motors give everything they've got\u2014but 'everything' has limits. The current saturates. The torque saturates. No matter how loud the controller shouts, I can only push back so hard. This is why my engineers tune for modest gains: if I rarely hit saturation, I stay in my nice linear world. But push me too far, too fast, and I'm in trouble.\"</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#dead-zone","title":"Dead Zone","text":"<p>A dead zone (or dead band) is a region of input values where the output is zero. It's the opposite of saturation\u2014instead of limiting the output, the system ignores small inputs entirely.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#dead-zone-characteristic","title":"Dead Zone Characteristic","text":"<p>\\(y = \\begin{cases} m(u - d) &amp; \\text{if } u &gt; d \\\\ 0 &amp; \\text{if } -d \\leq u \\leq d \\\\ m(u + d) &amp; \\text{if } u &lt; -d \\end{cases}\\)</p> <p>where:</p> <ul> <li>\\(y\\) is the output</li> <li>\\(u\\) is the input</li> <li>\\(d\\) is the dead zone half-width</li> <li>\\(m\\) is the slope outside the dead zone</li> </ul> <p>Examples of dead zones:</p> <ul> <li>Spool valve requiring minimum pressure to move</li> <li>Gear engagement requiring minimum torque</li> <li>Stiction (static friction) overcoming threshold</li> <li>Relay switching thresholds</li> <li>Sensor noise floors</li> </ul> <p>Dead zones cause particular problems for precision positioning:</p> <ul> <li>Limit cycles: Oscillation around the setpoint as the controller alternates between overshooting and undershooting the dead zone</li> <li>Steady-state error: The system settles within the dead zone rather than at the exact setpoint</li> <li>Loss of resolution: Fine control is impossible within the dead zone</li> </ul>"},{"location":"chapters/08-linearization-nonlinear-effects/#backlash","title":"Backlash","text":"<p>Backlash is the play or lost motion between mating components, most commonly in gear trains. When the direction of motion reverses, the driving gear must travel through the backlash gap before engaging the driven gear.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#backlash-characteristic","title":"Backlash Characteristic","text":"<p>The backlash relationship is history-dependent (hysteretic). If the input is increasing:</p> <p>\\(y = u - b\\) (after engaging)</p> <p>If the input is decreasing:</p> <p>\\(y = u + b\\) (after engaging)</p> <p>where:</p> <ul> <li>\\(b\\) is the backlash half-width</li> <li>The output \"lags\" behind the input by \\(2b\\) when direction reverses</li> </ul> <p>Examples of backlash:</p> <ul> <li>Gear trains (intentional clearance to prevent binding)</li> <li>Leadscrew and nut assemblies</li> <li>Linkage mechanisms with pivot clearance</li> <li>Steering systems (steering wheel \"play\")</li> <li>Valve actuators with mechanical coupling</li> </ul> <p>Backlash causes:</p> <ul> <li>Position uncertainty: The output position is uncertain within the backlash band</li> <li>Limit cycles: Similar to dead zones, oscillation can occur as the system \"bounces\" through the backlash</li> <li>Phase lag at reversal: Effective delay when direction changes</li> <li>Poor low-amplitude tracking: Small signals may not propagate through the backlash</li> </ul> <p>Mitigating Backlash</p> <p>Mechanical solutions include preloaded gears (anti-backlash gears), harmonic drives, or direct-drive motors that eliminate gearing entirely. Control solutions include backlash compensation algorithms that add extra motion during reversals, or dither signals that keep the mechanism \"engaged\" in one direction.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#hysteresis","title":"Hysteresis","text":"<p>Hysteresis is a memory effect where the output depends not only on the current input but also on the history of past inputs. The output follows different paths for increasing versus decreasing input, forming a characteristic loop.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#hysteresis-loop","title":"Hysteresis Loop","text":"<p>Unlike backlash (which is purely kinematic), hysteresis involves energy storage or material properties. The output-input relationship forms a closed loop when the input cycles.</p> <p>Examples of hysteresis:</p> <ul> <li>Magnetic materials (B-H curve in transformers and motors)</li> <li>Mechanical systems with friction (different static vs. kinetic friction)</li> <li>Thermal systems with phase changes</li> <li>Pneumatic systems with pressure hysteresis in seals</li> <li>On/off controllers (thermostat with different on and off thresholds)</li> </ul> <p>Hysteresis effects include:</p> <ul> <li>Path dependence: The output depends on where you came from, not just where you are</li> <li>Energy dissipation: The area inside the hysteresis loop represents energy lost per cycle</li> <li>Limit cycles: Systems can oscillate around the hysteresis loop</li> <li>Difficulty in precision control: History-dependent behavior complicates feedback control</li> </ul> <p>The key distinction between backlash and hysteresis: backlash has a definite \"contact\" point where the system becomes rigid, while hysteresis has a continuous (though path-dependent) input-output relationship.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#diagram-nonlinear-effects-gallery","title":"Diagram: Nonlinear Effects Gallery","text":"Nonlinear Effects Gallery <p>Type: microsim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: describe, classify</p> <p>Learning Objective: Students will describe and classify common nonlinear effects (saturation, dead zone, backlash, hysteresis) by observing their characteristic input-output relationships and how each distorts sinusoidal signals.</p> <p>Canvas layout: - Left (50%): Input-output characteristic curve - Right (50%): Time-domain effect on sinusoidal input</p> <p>Visual elements: Characteristic Curve (left): - X-axis: Input - Y-axis: Output - Ideal linear relationship (dashed gray) - Actual nonlinear relationship (solid black) - Shaded regions showing nonlinear zones - Arrows showing traversal direction (for hysteresis/backlash)</p> <p>Time Domain (right): - Input sinusoid (blue) - Output through nonlinearity (red/orange) - Difference/distortion (green) - Annotations showing effect features</p> <p>Nonlinearity Selector: - Tabs or radio buttons: Saturation, Dead Zone, Backlash, Hysteresis</p> <p>Interactive controls: - Tab/Radio: Select nonlinearity type - Slider: Nonlinearity parameter (saturation level, dead zone width, backlash width, hysteresis loop width) - Slider: Input amplitude - Slider: Input frequency - Button: Animate input-output trace on characteristic - Toggle: Show harmonic distortion spectrum</p> <p>Data Visibility Requirements: - Display nonlinearity parameter values - Show input amplitude vs output amplitude ratio - For Saturation: show clipping percentage - For Dead Zone: show \"dead time\" percentage of cycle - For Backlash: show phase lag at reversals - For Hysteresis: show loop area (energy loss)</p> <p>Behavior: - Characteristic curve animates as input sinusoid sweeps - Moving dot traces the input-output relationship - For backlash/hysteresis: trace forms loop instead of line - Distortion becomes more severe with larger amplitudes or narrower linear regions</p> <p>Instructional Rationale: Side-by-side view of characteristic curve and time-domain effect connects the abstract input-output plot to practical signal distortion. Interactive adjustment builds intuition for how each nonlinearity affects system behavior.</p> <p>Implementation: p5.js with animated characteristic tracing and synchronized time-domain plotting</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#impact-of-nonlinearities-on-control-system-performance","title":"Impact of Nonlinearities on Control System Performance","text":"<p>Nonlinear effects don't just complicate analysis\u2014they directly degrade control system performance. Understanding these impacts helps engineers anticipate problems and design mitigations.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#effects-on-stability","title":"Effects on Stability","text":"<p>Linear stability analysis (Routh-Hurwitz, root locus, Bode) assumes a linear system. Nonlinearities can:</p> <ul> <li>Create limit cycles: Oscillations that neither grow nor decay, stabilized by the nonlinearity</li> <li>Cause conditional stability: Stable for small disturbances but unstable for large ones (or vice versa)</li> <li>Introduce multiple equilibria: Some stable, some unstable\u2014initial conditions determine which the system approaches</li> </ul>"},{"location":"chapters/08-linearization-nonlinear-effects/#effects-on-performance","title":"Effects on Performance","text":"Nonlinearity Tracking Error Overshoot Settling Time Special Issues Saturation Increases (delayed response) Can increase (integrator windup) Increases Loss of controllability Dead Zone Steady-state error May increase Increases Limit cycles, resolution loss Backlash Position uncertainty May oscillate Increases Limit cycles at reversal Hysteresis Path-dependent May oscillate Increases Energy loss, limit cycles"},{"location":"chapters/08-linearization-nonlinear-effects/#dealing-with-nonlinearities","title":"Dealing with Nonlinearities","text":"<p>Engineers have several strategies:</p> <ol> <li> <p>Stay in the linear region: Design the operating point and input magnitudes to avoid nonlinear effects. This is the most common approach\u2014keep saturation margin, stay above dead zone, minimize direction reversals.</p> </li> <li> <p>Linearization with multiple operating points: Develop different linear models for different operating regimes and switch between them (gain scheduling).</p> </li> <li> <p>Nonlinear compensation: Add inverse nonlinearities to cancel the original. For example, apply extra input to overcome dead zone, or use anti-windup logic for saturation.</p> </li> <li> <p>Describing function analysis: An approximate method for analyzing limit cycles in systems with nonlinearities (beyond this course but worth knowing exists).</p> </li> <li> <p>Robust design: Accept that nonlinearities exist and design controllers with sufficient margins to maintain stability despite them.</p> </li> </ol> <p>Helping Gyra</p> <p>\"My engineers don't pretend I'm perfectly linear. They know about my motor saturation, the dead zone in my low-torque region, and the backlash in my gear train (yes, I have a tiny one). Their strategy? Keep me well away from these trouble zones during normal operation. They use moderate gains that don't demand saturation, feedback signals large enough to be above the dead zone, and smooth motion that doesn't require sudden reversals. It's not about eliminating nonlinearity\u2014it's about coexisting with it peacefully.\"</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#linearization-in-practice-a-complete-example","title":"Linearization in Practice: A Complete Example","text":"<p>Let's work through a complete linearization example for a system that combines multiple concepts: a water tank with nonlinear outflow and a pump with saturation.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#system-description","title":"System Description","text":"<p>A cylindrical tank of cross-sectional area \\(A\\) receives water from a pump. The pump flow rate is proportional to input voltage but saturates at \\(q_{max}\\):</p> <p>\\(q_{pump} = \\begin{cases} k_p v &amp; \\text{if } 0 \\leq k_p v \\leq q_{max} \\\\ q_{max} &amp; \\text{if } k_p v &gt; q_{max} \\end{cases}\\)</p> <p>The outlet flow depends nonlinearly on height (turbulent flow):</p> <p>\\(q_{out} = k_v \\sqrt{h}\\)</p> <p>The complete system equation is:</p> <p>\\(A\\frac{dh}{dt} = q_{pump} - k_v\\sqrt{h}\\)</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#step-1-find-operating-point","title":"Step 1: Find Operating Point","text":"<p>For nominal input voltage \\(V_0\\) (assuming no saturation), steady-state gives:</p> <p>\\(0 = k_p V_0 - k_v\\sqrt{h_0}\\)</p> <p>\\(h_0 = \\left(\\frac{k_p V_0}{k_v}\\right)^2\\)</p> <p>The operating point exists if \\(k_p V_0 \\leq q_{max}\\) (no pump saturation at steady state).</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#step-2-linearize-around-operating-point","title":"Step 2: Linearize Around Operating Point","text":"<p>Define deviations: \\(\\Delta h = h - h_0\\), \\(\\Delta v = v - V_0\\)</p> <p>Linearizing \\(\\sqrt{h}\\) around \\(h_0\\):</p> <p>\\(\\sqrt{h} \\approx \\sqrt{h_0} + \\frac{1}{2\\sqrt{h_0}}\\Delta h\\)</p> <p>The linearized system equation becomes:</p> <p>\\(A\\frac{d(\\Delta h)}{dt} = k_p \\Delta v - \\frac{k_v}{2\\sqrt{h_0}}\\Delta h\\)</p> <p>Rearranging:</p> <p>\\(\\frac{d(\\Delta h)}{dt} = -\\frac{k_v}{2A\\sqrt{h_0}}\\Delta h + \\frac{k_p}{A}\\Delta v\\)</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#step-3-transfer-function","title":"Step 3: Transfer Function","text":"<p>Define parameters:</p> <p>\\(\\tau = \\frac{2A\\sqrt{h_0}}{k_v} = \\frac{2Ah_0}{k_p V_0}\\) (time constant, operating-point dependent)</p> <p>\\(K = \\frac{2k_p\\sqrt{h_0}}{k_v} = \\frac{2h_0}{V_0}\\) (DC gain, operating-point dependent)</p> <p>The small-signal transfer function is:</p> <p>\\(G(s) = \\frac{\\Delta H(s)}{\\Delta V(s)} = \\frac{K}{\\tau s + 1}\\)</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#step-4-interpret-results","title":"Step 4: Interpret Results","text":"<p>Key observations:</p> <ul> <li>The linearized system is first-order (one energy storage element: the tank)</li> <li>Both \\(\\tau\\) and \\(K\\) depend on \\(h_0\\), which depends on \\(V_0\\)\u2014the dynamics change with operating point</li> <li>At higher operating levels (\\(h_0\\) large), both time constant and gain increase</li> <li>The linearization is valid only for small \\(\\Delta v\\) and \\(\\Delta h\\)</li> <li>Pump saturation is ignored in the linearized model\u2014valid only when operating well below \\(q_{max}\\)</li> </ul>"},{"location":"chapters/08-linearization-nonlinear-effects/#step-5-check-validity","title":"Step 5: Check Validity","text":"<p>For the linearization to be valid:</p> <ol> <li>\\(\\Delta h \\ll h_0\\) (square-root approximation)</li> <li>\\(k_p(V_0 + \\Delta v) &lt; q_{max}\\) (no saturation)</li> <li>\\(h &gt; 0\\) (tank not empty)</li> </ol> <p>If these conditions are violated, the linearized model gives incorrect predictions.</p>"},{"location":"chapters/08-linearization-nonlinear-effects/#key-takeaways","title":"Key Takeaways","text":"<p>This chapter addressed the fundamental tension in control engineering: real systems are nonlinear, but our most powerful analysis tools assume linearity. The resolution is linearization\u2014approximating nonlinear behavior with linear models valid near an operating point.</p> <p>Nonlinear Systems:</p> <ul> <li>Violate the superposition principle (scaling and/or additivity fail)</li> <li>Arise from products, powers, transcendental functions, or discontinuities in the governing equations</li> <li>Include almost every real physical system to some degree</li> </ul> <p>Equilibrium and Operating Points:</p> <ul> <li>An equilibrium point is where all derivatives vanish under constant input</li> <li>An operating point is the steady-state condition around which we linearize</li> <li>The operating point determines the coefficients of the linearized model</li> </ul> <p>Taylor Series Linearization:</p> <ul> <li>The linear term of the Taylor series provides the local linear approximation</li> <li>Partial derivatives evaluated at the operating point become system coefficients</li> <li>Valid only for \"small\" deviations\u2014the neglected higher-order terms must be negligible</li> </ul> <p>Small Signal Analysis:</p> <ul> <li>Analyzes deviations from operating point using linear transfer functions</li> <li>The linearized transfer function relates deviation inputs to deviation outputs</li> <li>Validity depends on how far the system operates from the linearization point</li> </ul> <p>Common Nonlinear Effects:</p> <ul> <li>Saturation: Output limited to maximum value (amplifiers, motors, actuators)</li> <li>Dead Zone: Zero output for small inputs (valves, friction, threshold effects)</li> <li>Backlash: Play between mating components (gears, linkages)</li> <li>Hysteresis: Path-dependent, history-dependent behavior (magnetic materials, friction)</li> </ul> <p>These nonlinear effects resist linearization and cause limit cycles, steady-state errors, and degraded performance. Engineers must recognize them and design systems that either avoid triggering them or include compensation strategies.</p> <p>The linearization skills developed here connect physical system modeling (Chapter 7) to the stability analysis and controller design techniques that follow. A good linearized model, with awareness of its validity limits, is the foundation for effective control system design.</p> Self-Check: Test Your Understanding <p>Before moving on, verify you can answer these:</p> <ol> <li> <p>A system is described by \\(\\frac{dy}{dt} = ay + bu + cy^2\\). Is this system linear? Why or why not?</p> </li> <li> <p>For the equation \\(\\frac{dx}{dt} = x^2 - 4\\), find all equilibrium points. Which are stable?</p> </li> <li> <p>Linearize \\(f(x) = x^3\\) around \\(x_0 = 2\\). What is the linearized function?</p> </li> <li> <p>A pump has flow rate \\(q = k\\sqrt{\\Delta P}\\) where \\(\\Delta P\\) is pressure difference. Linearize this around operating point \\(\\Delta P_0 = 4\\) bar.</p> </li> <li> <p>Explain why saturation in a control system's actuator can lead to integrator windup.</p> </li> <li> <p>A position control system has backlash of \u00b10.5 mm in its gear train. How does this affect steady-state positioning accuracy?</p> </li> </ol>"},{"location":"chapters/09-block-diagrams-signal-flow/","title":"Block Diagrams and Signal Flow","text":""},{"location":"chapters/09-block-diagrams-signal-flow/#summary","title":"Summary","text":"<p>This chapter develops graphical methods for representing and analyzing complex interconnected systems. Students will learn to construct block diagrams using summing junctions, pickoff points, and various connection types (cascade, parallel, feedback). Block diagram reduction techniques enable finding overall transfer functions from complex arrangements. The chapter also introduces signal flow graphs and Mason's gain formula as alternative methods for analyzing systems with multiple loops and forward paths. These tools are essential for modeling real control systems with nested feedback loops.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 28 concepts from the learning graph:</p> <ol> <li>Block Diagram</li> <li>Summing Junction</li> <li>Pickoff Point</li> <li>Cascade Connection</li> <li>Parallel Connection</li> <li>Feedback Connection</li> <li>Block Diagram Reduction</li> <li>Block Diagram Algebra</li> <li>Forward Path</li> <li>Feedback Path</li> <li>Loop</li> <li>Inner Loop</li> <li>Outer Loop</li> <li>Loop Gain</li> <li>Closed-Loop Transfer</li> <li>Open-Loop Transfer</li> <li>Unity Feedback</li> <li>Non-Unity Feedback</li> <li>Signal Flow Graph</li> <li>Node</li> <li>Branch</li> <li>Branch Gain</li> <li>Mason's Gain Formula</li> <li>Forward Path Gain</li> <li>Loop Gain Calculation</li> <li>Non-Touching Loops</li> <li>Graph Determinant</li> <li>Cofactor</li> </ol>"},{"location":"chapters/09-block-diagrams-signal-flow/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Introduction to Control Systems</li> <li>Chapter 5: Laplace Transform Methods</li> </ul>"},{"location":"chapters/09-block-diagrams-signal-flow/#the-art-of-visual-system-representation","title":"The Art of Visual System Representation","text":"<p>Control systems rarely exist in isolation. A real-world system like Gyra involves multiple interconnected subsystems\u2014sensors measuring tilt, controllers computing corrections, amplifiers boosting signals, motors generating torque, and the mechanical structure responding to forces. Understanding how these subsystems combine requires more than differential equations; it requires a visual language that captures both the structure and the signal flow of complex systems.</p> <p>Block diagrams provide exactly this visual language. They allow you to represent systems as interconnected blocks, each representing a transfer function, with signals flowing along connecting paths. Think of a block diagram as an engineering schematic that tells you not just what components exist, but how signals propagate and transform as they travel through the system.</p> <p>This chapter equips you with two powerful graphical tools: block diagrams and signal flow graphs. Both serve the same ultimate purpose\u2014finding the overall transfer function from input to output\u2014but they approach the problem differently. Block diagrams are intuitive and widely used for design; signal flow graphs are compact and powerful for analysis. Together, they form the visual foundation of classical control theory.</p> <p>Gyra Moment</p> <p>\"My designers don't just write equations\u2014they draw pictures of me! Each block represents something: my IMU, my controller, my motors, even my wobbling body. When they connect these blocks together, they can literally see how a command to 'stand still' transforms into the motor currents that keep me upright.\"</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#block-diagrams-building-blocks-of-control","title":"Block Diagrams: Building Blocks of Control","text":"<p>A block diagram is a graphical representation of a system using blocks, arrows, and special connection symbols. Each block represents a transfer function\u2014a mathematical relationship between its input and output signals. Arrows indicate the direction of signal flow, and special symbols handle signal combination and distribution.</p> <p>The beauty of block diagrams lies in their modularity. You can analyze complex systems by first understanding simple building blocks, then combining them according to well-defined rules. This \"divide and conquer\" approach makes even intimidating systems manageable.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#the-three-essential-elements","title":"The Three Essential Elements","text":"<p>Every block diagram is constructed from three fundamental elements:</p> Element Symbol Function Block Rectangle Multiplies input signal by transfer function Summing Junction Circle with +/\u2212 signs Adds or subtracts multiple signals Pickoff Point Dot or branch point Distributes one signal to multiple destinations <p>Let's examine each element in detail.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#blocks-and-transfer-functions","title":"Blocks and Transfer Functions","text":"<p>The rectangular block is the workhorse of block diagrams. Each block contains a transfer function\u2014typically written as \\(G(s)\\), \\(H(s)\\), or with subscripts like \\(G_1(s)\\)\u2014that describes how the input signal is transformed to produce the output.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#transfer-function-block-relationship","title":"Transfer Function Block Relationship","text":"<p>\\(Y(s) = G(s) \\cdot X(s)\\)</p> <p>where:</p> <ul> <li>\\(Y(s)\\) is the output signal in the s-domain</li> <li>\\(X(s)\\) is the input signal in the s-domain</li> <li>\\(G(s)\\) is the transfer function of the block</li> </ul> <p>The transfer function encapsulates all the dynamics of that subsystem\u2014poles, zeros, gain, and frequency response. When you look at a block labeled \\(G(s)\\), you're seeing a complete dynamic system condensed into a single symbol.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#the-summing-junction","title":"The Summing Junction","text":"<p>The summing junction combines multiple signals through addition or subtraction. It's drawn as a circle with signs (+ or \u2212) next to each input arrow indicating whether that signal is added or subtracted.</p> <p>The summing junction is where error signals are born. When a reference input \\(R(s)\\) enters with a positive sign and measured output \\(Y(s)\\) enters with a negative sign, the result is the error:</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#error-signal-computation","title":"Error Signal Computation","text":"<p>\\(E(s) = R(s) - Y(s)\\)</p> <p>where:</p> <ul> <li>\\(E(s)\\) is the error signal</li> <li>\\(R(s)\\) is the reference (desired) input</li> <li>\\(Y(s)\\) is the measured output (fed back through the sensor)</li> </ul> <p>Summing junctions can have more than two inputs\u2014disturbances, multiple feedback signals, and feedforward paths might all meet at a single junction. The key rule: signals are simply added algebraically according to their signs.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#the-pickoff-point","title":"The Pickoff Point","text":"<p>A pickoff point (also called a branch point or takeoff point) allows a single signal to be sent to multiple destinations without being altered. It's drawn as a small dot or simply as a branching of the signal line.</p> <p>Pickoff points don't modify the signal\u2014they just copy it. This is essential for feedback systems where the output must simultaneously go to the \"outside world\" and back to the summing junction for comparison with the reference.</p> <p>Signal Conservation at Pickoff Points</p> <p>When a signal branches at a pickoff point, each branch carries the same signal. There's no \"splitting\" of signal magnitude\u2014it's like making copies of a digital file. Every copy is identical to the original.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#diagram-block-diagram-elements","title":"Diagram: Block Diagram Elements","text":"Block Diagram Elements Interactive <p>Type: microsim</p> <p>Bloom Taxonomy: Remember (L1) Bloom Verb: identify, recognize</p> <p>Learning Objective: Students will identify and recognize the three fundamental block diagram elements (blocks, summing junctions, pickoff points) and understand how each transforms or routes signals.</p> <p>Canvas layout: - Top section (60%): Interactive block diagram building area - Bottom section (40%): Element palette and signal value display</p> <p>Visual elements: - Palette of draggable elements: transfer function block, summing junction (with configurable +/- signs), pickoff point - Work area with grid background - Connecting lines that can be drawn between elements - Signal value annotations that update in real-time</p> <p>Interactive controls: - Click on palette elements to add them to the work area - Drag elements to position them - Connect elements by clicking and dragging from output to input - Input field to set the input signal value (numeric) - Input field to enter transfer function gain for blocks - Display panel showing output values at each node</p> <p>Default example: - Pre-built simple feedback loop with R(s)=1, G(s)=10, H(s)=1 - Shows computed values: E(s), Y(s) at each signal point</p> <p>Behavior: - When connections are complete, calculate and display all signal values - Highlight signal path when hovering over any signal line - Show popup with element description when hovering over element</p> <p>Instructional Rationale: Drag-and-drop construction with real-time signal value computation helps students internalize how signals flow through each element type before analyzing more complex systems.</p> <p>Implementation: p5.js with canvas-based controls Canvas size: Responsive, minimum 800x500px</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#connection-types-how-blocks-combine","title":"Connection Types: How Blocks Combine","text":"<p>When multiple blocks appear in a system, they're connected in specific patterns. Three fundamental connection types cover nearly every configuration you'll encounter: cascade (series), parallel, and feedback.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#cascade-connection","title":"Cascade Connection","text":"<p>A cascade connection (or series connection) occurs when the output of one block feeds directly into the input of another. The blocks are \"in line,\" like train cars coupled together.</p> <p>For two blocks \\(G_1(s)\\) and \\(G_2(s)\\) in cascade:</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#cascade-transfer-function","title":"Cascade Transfer Function","text":"<p>\\(G_{cascade}(s) = G_1(s) \\cdot G_2(s)\\)</p> <p>where:</p> <ul> <li>\\(G_{cascade}(s)\\) is the equivalent transfer function of the cascade</li> <li>\\(G_1(s)\\) is the first block in the chain</li> <li>\\(G_2(s)\\) is the second block in the chain</li> </ul> <p>The rule extends to any number of blocks: multiply all the transfer functions together. This makes intuitive sense\u2014each block multiplies the signal by its transfer function, so chaining \\(n\\) blocks multiplies by all \\(n\\) transfer functions.</p> <p>Order matters for physical interpretation (signals flow through \\(G_1\\) before \\(G_2\\)), but mathematically, multiplication is commutative: \\(G_1(s) \\cdot G_2(s) = G_2(s) \\cdot G_1(s)\\).</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#parallel-connection","title":"Parallel Connection","text":"<p>A parallel connection occurs when a signal splits into multiple paths, each path passes through a different block, and the results combine at a summing junction.</p> <p>For two blocks \\(G_1(s)\\) and \\(G_2(s)\\) in parallel (both added):</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#parallel-transfer-function","title":"Parallel Transfer Function","text":"<p>\\(G_{parallel}(s) = G_1(s) + G_2(s)\\)</p> <p>where:</p> <ul> <li>\\(G_{parallel}(s)\\) is the equivalent transfer function of the parallel combination</li> <li>\\(G_1(s)\\) is the upper parallel path</li> <li>\\(G_2(s)\\) is the lower parallel path</li> </ul> <p>If one path has a negative sign at the summing junction, you subtract instead of add. Parallel connections are common when multiple effects contribute to a single output\u2014perhaps a feedforward path alongside the main control path, or multiple disturbances entering the plant.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#feedback-connection","title":"Feedback Connection","text":"<p>The feedback connection is the heart of closed-loop control. The output of a forward path block \\(G(s)\\) is fed back through a feedback block \\(H(s)\\) and subtracted (for negative feedback) from the input.</p> <p>For negative feedback:</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#closed-loop-transfer-function","title":"Closed-Loop Transfer Function","text":"<p>\\(T(s) = \\frac{G(s)}{1 + G(s)H(s)}\\)</p> <p>where:</p> <ul> <li>\\(T(s)\\) is the closed-loop transfer function</li> <li>\\(G(s)\\) is the forward path transfer function</li> <li>\\(H(s)\\) is the feedback path transfer function</li> <li>\\(G(s)H(s)\\) is the loop transfer function (open-loop transfer function)</li> </ul> <p>This formula is so fundamental that you should commit it to memory. It appears constantly in control systems analysis and design.</p> <p>For positive feedback (when the fed-back signal is added rather than subtracted):</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#positive-feedback-transfer-function","title":"Positive Feedback Transfer Function","text":"<p>\\(T(s) = \\frac{G(s)}{1 - G(s)H(s)}\\)</p> <p>where:</p> <ul> <li>The denominator has a minus sign instead of plus</li> <li>Positive feedback is rarely used intentionally (it tends toward instability)</li> </ul> <p>The Sign Matters!</p> <p>The difference between \\(1 + G(s)H(s)\\) (negative feedback) and \\(1 - G(s)H(s)\\) (positive feedback) is critical. Most control systems use negative feedback because it's inherently stabilizing. The denominator \\(1 + G(s)H(s)\\) is called the characteristic polynomial\u2014its roots determine system stability.</p> Connection Type Configuration Equivalent Transfer Function Cascade Blocks in series \\(G_1 \\cdot G_2\\) Parallel Blocks in parallel, summed \\(G_1 + G_2\\) Negative Feedback Forward and feedback paths \\(\\frac{G}{1 + GH}\\) Positive Feedback Forward path, added feedback \\(\\frac{G}{1 - GH}\\)"},{"location":"chapters/09-block-diagrams-signal-flow/#diagram-connection-type-comparison","title":"Diagram: Connection Type Comparison","text":"Connection Type Comparison MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: compare, contrast</p> <p>Learning Objective: Students will compare cascade, parallel, and feedback connection types, observing how different configurations produce different overall transfer functions from identical component blocks.</p> <p>Canvas layout: - Left panel (30%): Connection type selector and transfer function display - Right panel (70%): Visual block diagram that updates based on selection</p> <p>Visual elements: - Three connection configurations shown graphically - Block \\(G_1(s)\\) and \\(G_2(s)\\) with adjustable gains - Input arrow \\(R(s)\\) and output arrow \\(Y(s)\\) - Formula display showing equivalent transfer function - Pole-zero plot or Bode magnitude sketch for each configuration</p> <p>Interactive controls: - Radio buttons: Select \"Cascade\", \"Parallel\", or \"Feedback\" - Slider: \\(G_1\\) gain (0.1 to 10, default 2) - Slider: \\(G_2\\) gain (0.1 to 10, default 3) - Checkbox: Show equivalent single-block representation - Button: Reset to defaults</p> <p>Default parameters: - Connection type: Cascade - \\(G_1 = 2\\), \\(G_2 = 3\\) - Transfer functions shown as simple gains for clarity</p> <p>Behavior: - When connection type changes, diagram reconfigures smoothly - Equivalent transfer function updates in real-time as gains change - For feedback, show the classic loop with summing junction - Display numerical value of equivalent transfer function</p> <p>Data Visibility Requirements: - Stage 1: Show selected connection type diagram - Stage 2: Show individual transfer function values - Stage 3: Show formula for combination - Stage 4: Show computed equivalent transfer function</p> <p>Instructional Rationale: Side-by-side comparison with identical blocks allows students to directly observe how connection topology (not just component values) determines overall system behavior.</p> <p>Implementation: p5.js with canvas-based controls Canvas size: Responsive, 800x550px minimum</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#understanding-forward-and-feedback-paths","title":"Understanding Forward and Feedback Paths","text":"<p>Before we can reduce complex block diagrams, we need precise vocabulary for describing the routes signals take through a system.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#forward-path","title":"Forward Path","text":"<p>A forward path is any path from the input \\(R(s)\\) to the output \\(Y(s)\\) that traverses signals only in the forward direction (following the arrows) and doesn't pass through any node more than once.</p> <p>In a simple feedback system, there's typically one forward path: from \\(R(s)\\) through the controller, through the plant, to \\(Y(s)\\). Complex systems may have multiple forward paths\u2014perhaps a direct feedforward path alongside the main control path.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#feedback-path","title":"Feedback Path","text":"<p>The feedback path is the route from the output back to the summing junction at the input. This path typically includes the sensor and any signal conditioning. The feedback path contains the block \\(H(s)\\) in our standard notation.</p> <p>The feedback path is what makes closed-loop control possible. Without it, the system has no way to compare actual output to desired output.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#the-loop","title":"The Loop","text":"<p>A loop is a closed path starting and ending at the same point, following signal directions around the circuit. The most important loop in control systems is the main feedback loop\u2014from the summing junction, through \\(G(s)\\), out to the output, back through \\(H(s)\\), and returning to the summing junction.</p> <p>The product of all transfer functions around a loop is called the loop gain or loop transfer function:</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#loop-transfer-function","title":"Loop Transfer Function","text":"<p>\\(L(s) = G(s)H(s)\\)</p> <p>where:</p> <ul> <li>\\(L(s)\\) is the loop transfer function</li> <li>\\(G(s)\\) is the forward path transfer function</li> <li>\\(H(s)\\) is the feedback path transfer function</li> </ul> <p>Loop gain is central to stability analysis. The roots of \\(1 + L(s) = 0\\) determine whether the closed-loop system is stable.</p> <p>Gyra Moment</p> <p>\"My main feedback loop goes like this: My tilt angle gets measured by my IMU, compared to 'zero' (the reference), the error goes to my controller, the controller drives my motors, the motors push me, and that changes my tilt angle\u2014which gets measured again. Around and around, dozens of times per second. That loop is my heartbeat.\"</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#inner-and-outer-loops","title":"Inner and Outer Loops","text":"<p>Complex systems often have nested feedback loops\u2014a feedback loop inside another feedback loop. The innermost feedback structure is called the inner loop, while the loop encompassing it is the outer loop.</p> <p>Inner loops typically handle fast dynamics (like motor current control), while outer loops handle slower dynamics (like position or velocity control). This hierarchical structure is called cascade control (not to be confused with cascade connections of blocks).</p> <p>To analyze nested loops, you typically:</p> <ol> <li>Reduce the inner loop first, treating it as a single equivalent block</li> <li>Then analyze the outer loop with the simplified inner loop</li> </ol> <p>This inside-out approach simplifies complex structures step by step.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#diagram-nested-feedback-loop-structure","title":"Diagram: Nested Feedback Loop Structure","text":"Nested Feedback Loop Structure <p>Type: diagram</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: differentiate, organize</p> <p>Learning Objective: Students will differentiate between inner and outer loops in a nested feedback structure and trace the signal flow through each loop independently.</p> <p>Purpose: Visualize the hierarchical structure of nested feedback loops commonly found in cascade control systems</p> <p>Components to show: - Outer loop reference input \\(R(s)\\) - Outer loop summing junction - Outer loop controller \\(G_{c1}(s)\\) - Inner loop reference (output of outer controller) - Inner loop summing junction - Inner loop controller \\(G_{c2}(s)\\) - Plant \\(G_p(s)\\) - Inner loop sensor \\(H_2(s)\\) - Outer loop sensor \\(H_1(s)\\) - Output \\(Y(s)\\)</p> <p>Visual layout: - Inner loop highlighted with light blue background - Outer loop highlighted with light green background - Clear labels for \"Inner Loop\" and \"Outer Loop\" - Signal labels at all key points</p> <p>Interactive features: - Hover over inner loop region: highlights all inner loop components - Hover over outer loop region: highlights all outer loop components - Click \"Show Inner Loop Equivalent\": collapses inner loop to single block - Animation showing signal flow around each loop</p> <p>Color scheme: - Inner loop components: blue - Outer loop components: green - Plant: gray - Signals: black arrows</p> <p>Implementation: vis-network or custom SVG with JavaScript Canvas size: 900x500px, responsive</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#open-loop-and-closed-loop-transfer-functions","title":"Open-Loop and Closed-Loop Transfer Functions","text":"<p>Two transfer functions are fundamental to control system analysis: the open-loop transfer function and the closed-loop transfer function. Understanding the relationship between them is crucial.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#open-loop-transfer-function","title":"Open-Loop Transfer Function","text":"<p>The open-loop transfer function \\(G_{OL}(s)\\) describes the system behavior when the feedback loop is \"broken\"\u2014when the measured output is not connected back to the summing junction. It's the product of all transfer functions around the loop:</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#open-loop-transfer-function-definition","title":"Open-Loop Transfer Function Definition","text":"<p>\\(G_{OL}(s) = G(s)H(s)\\)</p> <p>where:</p> <ul> <li>\\(G_{OL}(s)\\) is the open-loop transfer function</li> <li>\\(G(s)\\) is the forward path transfer function</li> <li>\\(H(s)\\) is the feedback path transfer function</li> </ul> <p>The open-loop transfer function is what you measure if you open the loop (break the feedback connection) and inject a signal at one point while measuring at another. It's essential for stability analysis using Bode plots and Nyquist diagrams.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#closed-loop-transfer-function_1","title":"Closed-Loop Transfer Function","text":"<p>The closed-loop transfer function \\(T(s)\\) describes the overall input-output relationship when the feedback loop is closed:</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#closed-loop-transfer-function-definition","title":"Closed-Loop Transfer Function Definition","text":"<p>\\(T(s) = \\frac{Y(s)}{R(s)} = \\frac{G(s)}{1 + G(s)H(s)}\\)</p> <p>where:</p> <ul> <li>\\(T(s)\\) is the closed-loop transfer function</li> <li>\\(Y(s)\\) is the output</li> <li>\\(R(s)\\) is the reference input</li> <li>The denominator \\(1 + G(s)H(s)\\) is called the characteristic polynomial</li> </ul> <p>The poles of \\(T(s)\\)\u2014the roots of \\(1 + G(s)H(s) = 0\\)\u2014determine closed-loop stability and transient response.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#unity-feedback-systems","title":"Unity Feedback Systems","text":"<p>A unity feedback system is the special case where \\(H(s) = 1\\). The sensor is \"ideal\"\u2014it perfectly measures the output without any dynamics or gain. This simplifies the closed-loop transfer function:</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#unity-feedback-transfer-function","title":"Unity Feedback Transfer Function","text":"<p>\\(T(s) = \\frac{G(s)}{1 + G(s)}\\)</p> <p>where:</p> <ul> <li>\\(H(s) = 1\\) (unity feedback)</li> <li>The open-loop transfer function equals the forward path: \\(G_{OL}(s) = G(s)\\)</li> </ul> <p>Unity feedback is a common assumption in textbook problems and serves as a useful starting point for design. Real sensors have dynamics, but at frequencies of interest, \\(H(s) \\approx 1\\) is often a reasonable approximation.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#non-unity-feedback-systems","title":"Non-Unity Feedback Systems","text":"<p>When \\(H(s) \\neq 1\\), the system has non-unity feedback. The sensor might have:</p> <ul> <li>Gain different from 1 (e.g., a tachometer outputting volts per rad/s)</li> <li>Dynamics (e.g., sensor bandwidth limitations)</li> <li>Filtering (e.g., to remove noise)</li> </ul> <p>For non-unity feedback, you must include \\(H(s)\\) explicitly in all calculations. A common transformation is to convert a non-unity feedback system to an equivalent unity feedback form for analysis, but this requires care with the transfer function definitions.</p> System Type Feedback Transfer Function Closed-Loop Transfer Open-Loop Transfer Unity Feedback \\(H(s) = 1\\) \\(\\frac{G}{1+G}\\) \\(G(s)\\) Non-Unity Feedback \\(H(s) \\neq 1\\) \\(\\frac{G}{1+GH}\\) \\(G(s)H(s)\\) <p>Deriving the Closed-Loop Transfer Function</p> <p>You can derive \\(T(s) = \\frac{G}{1+GH}\\) from first principles:</p> <ol> <li>Write \\(E = R - HY\\) (error = reference minus fed-back output)</li> <li>Write \\(Y = GE\\) (output = forward path times error)</li> <li>Substitute: \\(Y = G(R - HY) = GR - GHY\\)</li> <li>Rearrange: \\(Y + GHY = GR\\), so \\(Y(1 + GH) = GR\\)</li> <li>Solve: \\(T = \\frac{Y}{R} = \\frac{G}{1+GH}\\)</li> </ol>"},{"location":"chapters/09-block-diagrams-signal-flow/#block-diagram-reduction","title":"Block Diagram Reduction","text":"<p>Real control systems have block diagrams far more complex than a single feedback loop. Block diagram reduction is the systematic process of simplifying these complex diagrams to find the overall transfer function.</p> <p>The goal is straightforward: start with a complicated diagram and end with a single block showing the transfer function from input to output. The process uses equivalence rules that preserve the input-output relationship while simplifying the structure.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#block-diagram-algebra-rules","title":"Block Diagram Algebra Rules","text":"<p>Block diagram algebra consists of rules for manipulating block diagrams while preserving their input-output behavior. These rules let you move blocks and pickoff points, combine blocks, and ultimately reduce the diagram.</p> <p>The fundamental rules are:</p> <ol> <li>Cascade blocks combine by multiplication</li> <li>Parallel blocks combine by addition</li> <li>Feedback loops combine using the feedback formula</li> <li>Moving a pickoff point past a block requires compensation</li> <li>Moving a summing junction past a block requires compensation</li> </ol> <p>Let's examine the compensation rules in detail.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#moving-a-pickoff-point-past-a-block","title":"Moving a Pickoff Point Past a Block","text":"<p>If you need to move a pickoff point from the output of block \\(G(s)\\) to its input, you must add a compensating block \\(G(s)\\) in the path that was picked off:</p> <p>Moving pickoff point backward (toward input): Insert \\(G(s)\\) in the picked-off path</p> <p>Moving pickoff point forward (toward output): Insert \\(\\frac{1}{G(s)}\\) in the picked-off path</p> <p>This compensation ensures that the signal in the picked-off path has the same value as before the move.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#moving-a-summing-junction-past-a-block","title":"Moving a Summing Junction Past a Block","text":"<p>Similarly, moving a summing junction past a block requires compensation:</p> <p>Moving summing junction backward: Insert \\(\\frac{1}{G(s)}\\) in paths entering the junction</p> <p>Moving summing junction forward: Insert \\(G(s)\\) in paths entering the junction</p> <p>These rules are the \"legal moves\" in the game of block diagram reduction. Master them, and you can systematically simplify any block diagram.</p> Operation Compensation Required Move pickoff point backward past \\(G(s)\\) Add \\(G(s)\\) in picked-off path Move pickoff point forward past \\(G(s)\\) Add \\(\\frac{1}{G(s)}\\) in picked-off path Move summing junction backward past \\(G(s)\\) Add \\(\\frac{1}{G(s)}\\) in entering paths Move summing junction forward past \\(G(s)\\) Add \\(G(s)\\) in entering paths"},{"location":"chapters/09-block-diagrams-signal-flow/#diagram-block-diagram-reduction-steps","title":"Diagram: Block Diagram Reduction Steps","text":"Block Diagram Reduction Steps MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: execute, apply</p> <p>Learning Objective: Students will apply block diagram algebra rules to systematically reduce a multi-loop block diagram to a single transfer function, seeing each step animated.</p> <p>Canvas layout: - Main area (75%): Block diagram that transforms step by step - Side panel (25%): Reduction steps list and current formula</p> <p>Visual elements: - Multi-loop block diagram with 4-5 blocks - Animated transitions showing each reduction step - Highlighted regions showing which elements are being combined - Running calculation of equivalent transfer function</p> <p>Interactive controls: - Button: \"Next Step\" - advances reduction by one step - Button: \"Previous Step\" - goes back one step - Button: \"Auto-Run\" - animates through all steps - Slider: Animation speed (0.5 to 2 seconds per step) - Button: \"Reset\" - returns to original diagram - Dropdown: Select example problem (3 different diagrams of varying complexity)</p> <p>Default example: - System with inner and outer loops - Forward path: \\(G_1(s)G_2(s)G_3(s)\\) - Inner feedback: \\(H_1(s)\\) around \\(G_2(s)G_3(s)\\) - Outer feedback: \\(H_2(s)\\) around entire system</p> <p>Reduction sequence: Step 1: Identify inner loop Step 2: Apply feedback formula to inner loop, replace with equivalent block Step 3: Combine cascade blocks in forward path Step 4: Apply feedback formula to outer loop Step 5: Simplify to final transfer function</p> <p>Data Visibility Requirements: - Each step shows: diagram state, rule being applied, formula evolution - Final step shows complete transfer function with all terms</p> <p>Instructional Rationale: Step-by-step animation with pause and rewind allows students to trace each algebraic manipulation, building procedural fluency before tackling problems independently.</p> <p>Implementation: p5.js with canvas-based controls and smooth transitions Canvas size: 900x600px, responsive</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#reduction-strategy","title":"Reduction Strategy","text":"<p>When facing a complex block diagram, follow this systematic approach:</p> <ol> <li>Identify all loops - Find inner loops, outer loops, and any parallel paths</li> <li>Reduce inner loops first - Apply the feedback formula to innermost structures</li> <li>Combine cascade elements - Multiply series transfer functions</li> <li>Combine parallel elements - Add parallel transfer functions</li> <li>Repeat until only one block remains</li> </ol> <p>If you get stuck, look for opportunities to move pickoff points or summing junctions using the compensation rules. Sometimes rearranging the diagram makes the reduction path clearer.</p> <p>Gyra Moment</p> <p>\"My designers once drew my complete control system\u2014it looked like spaghetti! There was an inner loop for motor current control, a middle loop for velocity, and an outer loop for position. But step by step, they collapsed each loop using the feedback formula until the whole thing became one transfer function. That's when they could finally tune me properly.\"</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#signal-flow-graphs","title":"Signal Flow Graphs","text":"<p>While block diagrams are intuitive, they can become unwieldy for systems with many loops and forward paths. Signal flow graphs offer a more compact alternative that's particularly well-suited for applying Mason's gain formula\u2014a powerful technique for finding transfer functions without step-by-step reduction.</p> <p>A signal flow graph represents the same information as a block diagram but in a different form: signals become nodes (points), and transfer functions become branches (directed lines connecting nodes).</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#nodes-and-branches","title":"Nodes and Branches","text":"<p>A node represents a signal variable. Unlike block diagram signals (which are just labels on arrows), nodes are explicit points in the graph. Each node has a value equal to the sum of all signals entering it.</p> <p>A branch connects two nodes and has an associated gain\u2014the transfer function by which the source node's value is multiplied to contribute to the destination node's value. Branches have direction, shown by arrows.</p> <p>The key relationship: the value at any node equals the sum of all incoming branch gains times their source node values:</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#node-value-equation","title":"Node Value Equation","text":"<p>\\(X_j = \\sum_i T_{ij} X_i\\)</p> <p>where:</p> <ul> <li>\\(X_j\\) is the value at node \\(j\\)</li> <li>\\(X_i\\) is the value at source node \\(i\\)</li> <li>\\(T_{ij}\\) is the branch gain from node \\(i\\) to node \\(j\\)</li> <li>The sum is over all branches entering node \\(j\\)</li> </ul>"},{"location":"chapters/09-block-diagrams-signal-flow/#branch-gain","title":"Branch Gain","text":"<p>The branch gain is simply the transfer function written along the branch arrow. For a branch from node \\(X_i\\) to node \\(X_j\\) with gain \\(G(s)\\), the contribution to \\(X_j\\) is \\(G(s) \\cdot X_i\\).</p> <p>Signal flow graphs are drawn with input nodes on the left (sources, with only outgoing branches), output nodes on the right (sinks, with only incoming branches), and intermediate nodes in between.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#converting-block-diagrams-to-signal-flow-graphs","title":"Converting Block Diagrams to Signal Flow Graphs","text":"<p>The conversion is straightforward:</p> <ol> <li>Each signal in the block diagram becomes a node</li> <li>Each block becomes a branch with gain equal to the block's transfer function</li> <li>Summing junctions become nodes (the sum happens implicitly)</li> <li>Pickoff points are simply nodes with multiple outgoing branches</li> </ol> <p>Signal flow graphs are more compact because they don't need separate symbols for summing\u2014it's built into the node definition.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#diagram-block-diagram-to-signal-flow-graph-conversion","title":"Diagram: Block Diagram to Signal Flow Graph Conversion","text":"Block Diagram to Signal Flow Graph Conversion <p>Type: diagram</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: interpret, convert</p> <p>Learning Objective: Students will interpret the correspondence between block diagram elements and signal flow graph elements, converting between the two representations.</p> <p>Purpose: Show side-by-side comparison of block diagram and equivalent signal flow graph</p> <p>Layout: - Top half: Block diagram of a feedback system - Bottom half: Equivalent signal flow graph - Dashed lines connecting corresponding elements</p> <p>Block diagram elements (top): - Reference input R(s) - Summing junction - Error E(s) - Forward block G(s) - Output Y(s) - Feedback block H(s) - Feedback signal</p> <p>Signal flow graph elements (bottom): - Node R (input node, leftmost) - Node E (after summing) - Branch with gain G from E to Y - Node Y (output node, rightmost) - Branch with gain -H from Y to E (negative for feedback)</p> <p>Interactive features: - Hover over block diagram element: highlights corresponding SFG element - Hover over SFG element: highlights corresponding block diagram element - Animation showing signal values propagating through both representations - Toggle: \"Show signal values\" displays numerical values at each node</p> <p>Visual style: - Block diagram: standard rectangular blocks and circles - SFG: dots for nodes, arrows with gain labels for branches - Matching colors between corresponding elements</p> <p>Implementation: vis-network or custom SVG Canvas size: 800x500px, responsive</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#masons-gain-formula","title":"Mason's Gain Formula","text":"<p>Mason's gain formula is a powerful technique for finding the transfer function of a signal flow graph without performing step-by-step reduction. It's particularly valuable for complex systems with multiple loops and forward paths where block diagram reduction would be tedious.</p> <p>The formula may look intimidating at first, but it's based on a systematic accounting of all paths and loops in the graph.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#forward-path-gain","title":"Forward Path Gain","text":"<p>A forward path in a signal flow graph is any path from the input node to the output node that doesn't pass through any node more than once. Each forward path has an associated forward path gain\u2014the product of all branch gains along that path.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#forward-path-gain-definition","title":"Forward Path Gain Definition","text":"<p>\\(P_k = \\prod_{\\text{branches in path } k} T_i\\)</p> <p>where:</p> <ul> <li>\\(P_k\\) is the gain of the \\(k\\)th forward path</li> <li>\\(T_i\\) are the individual branch gains along the path</li> </ul> <p>Many systems have only one forward path, but complex systems with feedforward or multiple routes from input to output may have several.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#loop-gain-calculation","title":"Loop Gain Calculation","text":"<p>A loop in a signal flow graph is a closed path that starts and ends at the same node, traversing each intermediate node only once. Each loop has a loop gain\u2014the product of all branch gains around the loop.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#loop-gain-definition","title":"Loop Gain Definition","text":"<p>\\(L_i = \\prod_{\\text{branches in loop } i} T_j\\)</p> <p>where:</p> <ul> <li>\\(L_i\\) is the gain of the \\(i\\)th loop</li> <li>\\(T_j\\) are the branch gains around the loop</li> </ul>"},{"location":"chapters/09-block-diagrams-signal-flow/#non-touching-loops","title":"Non-Touching Loops","text":"<p>Two loops are non-touching if they share no common nodes. Non-touching loops don't interact directly\u2014a signal can't travel through both loops in a single trip around the graph.</p> <p>Mason's formula requires identifying:</p> <ul> <li>All individual loop gains</li> <li>All products of two non-touching loop gains</li> <li>All products of three non-touching loop gains</li> <li>And so on...</li> </ul>"},{"location":"chapters/09-block-diagrams-signal-flow/#the-graph-determinant","title":"The Graph Determinant","text":"<p>The graph determinant \\(\\Delta\\) (also called the system determinant) summarizes all the loop structure:</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#graph-determinant-formula","title":"Graph Determinant Formula","text":"<p>\\(\\Delta = 1 - \\sum L_i + \\sum L_i L_j - \\sum L_i L_j L_k + \\cdots\\)</p> <p>where:</p> <ul> <li>\\(\\sum L_i\\) is the sum of all individual loop gains</li> <li>\\(\\sum L_i L_j\\) is the sum of products of all pairs of non-touching loops</li> <li>\\(\\sum L_i L_j L_k\\) is the sum of products of all triplets of non-touching loops</li> <li>The pattern continues with alternating signs</li> </ul> <p>For many practical systems, especially those with touching loops, only the first few terms are non-zero.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#cofactors","title":"Cofactors","text":"<p>The cofactor \\(\\Delta_k\\) for the \\(k\\)th forward path is the graph determinant evaluated with all loops that touch that forward path removed:</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#cofactor-definition","title":"Cofactor Definition","text":"<p>\\(\\Delta_k = 1 - \\sum L_i^{(k)} + \\sum L_i^{(k)} L_j^{(k)} - \\cdots\\)</p> <p>where:</p> <ul> <li>The superscript \\((k)\\) indicates only loops that don't touch forward path \\(k\\)</li> <li>If all loops touch forward path \\(k\\), then \\(\\Delta_k = 1\\)</li> </ul>"},{"location":"chapters/09-block-diagrams-signal-flow/#the-complete-formula","title":"The Complete Formula","text":"<p>Mason's gain formula gives the transfer function as:</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#masons-gain-formula_1","title":"Mason's Gain Formula","text":"<p>\\(T(s) = \\frac{Y(s)}{R(s)} = \\frac{\\sum_k P_k \\Delta_k}{\\Delta}\\)</p> <p>where:</p> <ul> <li>\\(P_k\\) is the gain of the \\(k\\)th forward path</li> <li>\\(\\Delta_k\\) is the cofactor for the \\(k\\)th forward path</li> <li>\\(\\Delta\\) is the graph determinant</li> <li>The sum is over all forward paths</li> </ul> <p>This formula directly gives the closed-loop transfer function without any intermediate reduction steps.</p> Term Symbol Description Forward path gain \\(P_k\\) Product of branch gains along forward path \\(k\\) Loop gain \\(L_i\\) Product of branch gains around loop \\(i\\) Graph determinant \\(\\Delta\\) \\(1 - \\sum L_i + \\sum L_iL_j - \\cdots\\) Cofactor \\(\\Delta_k\\) Graph determinant with path-\\(k\\)-touching loops removed"},{"location":"chapters/09-block-diagrams-signal-flow/#diagram-masons-gain-formula-step-by-step","title":"Diagram: Mason's Gain Formula Step-by-Step","text":"Mason's Gain Formula Step-by-Step MicroSim <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: calculate, apply</p> <p>Learning Objective: Students will apply Mason's gain formula by identifying forward paths, loops, non-touching loop pairs, and computing the transfer function step by step.</p> <p>Canvas layout: - Left panel (50%): Signal flow graph with interactive highlighting - Right panel (50%): Step-by-step calculation display</p> <p>Visual elements: - Signal flow graph with 4-5 nodes and multiple loops - Forward paths highlighted in green when selected - Loops highlighted in orange when selected - Non-touching loop pairs shown with matching colors - Formula building progressively as terms are identified</p> <p>Interactive controls: - Step 1 button: \"Find Forward Paths\" - highlights each forward path in sequence - Step 2 button: \"Find Loops\" - highlights each loop in sequence - Step 3 button: \"Find Non-Touching Pairs\" - shows which loops don't touch - Step 4 button: \"Calculate \u0394\" - builds determinant formula - Step 5 button: \"Calculate Cofactors\" - shows \u0394_k for each path - Step 6 button: \"Apply Formula\" - combines everything into final T(s) - Dropdown: Select example (3 different signal flow graphs) - Button: Reset</p> <p>Default example: - System with two forward paths - Three loops, one pair of non-touching loops - Simple gains (integers) for easy hand calculation</p> <p>Data Visibility Requirements: - Stage 1: Highlight forward path, display P_k value - Stage 2: Highlight each loop, display L_i value - Stage 3: Show which loops touch which paths - Stage 4: Show \u0394 formula with numerical values - Stage 5: Show \u0394_k for each forward path - Stage 6: Show final T(s) with all substitutions</p> <p>Instructional Rationale: Breaking Mason's formula into discrete steps with visual feedback demystifies what can seem like a cryptic procedure, building student confidence for independent application.</p> <p>Implementation: p5.js with canvas-based controls Canvas size: 900x650px, responsive</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#worked-example-applying-masons-formula","title":"Worked Example: Applying Mason's Formula","text":"<p>Consider a signal flow graph with:</p> <ul> <li>Input node \\(R\\), intermediate nodes \\(X_1\\), \\(X_2\\), and output node \\(Y\\)</li> <li>Forward path: \\(R \\to X_1 \\to X_2 \\to Y\\) with gains \\(G_1\\), \\(G_2\\), \\(G_3\\)</li> <li>Loop 1: \\(X_1 \\to X_2 \\to X_1\\) with gain \\(-G_2 H_1\\) (self-loop through feedback)</li> <li>Loop 2: \\(X_2 \\to Y \\to X_2\\) with gain \\(-G_3 H_2\\)</li> </ul> <p>Step 1: Identify forward paths</p> <p>There's one forward path with gain \\(P_1 = G_1 G_2 G_3\\)</p> <p>Step 2: Identify loops and their gains</p> <ul> <li>\\(L_1 = -G_2 H_1\\)</li> <li>\\(L_2 = -G_3 H_2\\)</li> </ul> <p>Step 3: Identify non-touching loops</p> <p>Do loops 1 and 2 share any nodes? Loop 1 involves \\(X_1, X_2\\). Loop 2 involves \\(X_2, Y\\). They share \\(X_2\\), so they're touching. No non-touching pairs exist.</p> <p>Step 4: Calculate the graph determinant</p> <p>\\(\\Delta = 1 - (L_1 + L_2) + 0 = 1 + G_2 H_1 + G_3 H_2\\)</p> <p>Step 5: Calculate cofactors</p> <p>Does the forward path touch all loops? Path goes through \\(X_1, X_2, Y\\). Both loops touch this path (they share nodes with it). So \\(\\Delta_1 = 1\\).</p> <p>Step 6: Apply Mason's formula</p> <p>\\(T(s) = \\frac{P_1 \\Delta_1}{\\Delta} = \\frac{G_1 G_2 G_3}{1 + G_2 H_1 + G_3 H_2}\\)</p> <p>When to Use Mason's Formula</p> <p>Mason's gain formula shines when:</p> <ul> <li>The system has multiple forward paths</li> <li>There are many loops, some non-touching</li> <li>Block diagram reduction would require many steps</li> </ul> <p>For simple single-loop systems, direct application of \\(T = \\frac{G}{1+GH}\\) is usually faster.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#practical-examples-gyras-control-loops","title":"Practical Examples: Gyra's Control Loops","text":"<p>Let's apply these techniques to a realistic scenario: Gyra's cascade position control system. This example illustrates nested loops, multiple transfer functions, and the power of systematic reduction.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#gyras-cascade-control-structure","title":"Gyra's Cascade Control Structure","text":"<p>Gyra uses three nested control loops:</p> <ol> <li>Inner loop (fastest): Motor current control - ensures motors deliver commanded torque</li> <li>Middle loop: Velocity control - regulates how fast Gyra tilts</li> <li>Outer loop (slowest): Position control - keeps Gyra at the desired tilt angle (zero for upright)</li> </ol> <p>Each loop operates at a different speed, with inner loops responding much faster than outer loops. This hierarchical structure improves performance and makes tuning easier.</p> <p>The transfer functions are:</p> <ul> <li>\\(G_c(s)\\) - Position controller (outer)</li> <li>\\(G_v(s)\\) - Velocity controller (middle)</li> <li>\\(G_i(s)\\) - Current controller (inner)</li> <li>\\(G_m(s)\\) - Motor dynamics</li> <li>\\(G_p(s)\\) - Gyra's mechanical dynamics</li> <li>\\(H_i(s)\\) - Current sensor</li> <li>\\(H_v(s)\\) - Velocity sensor (derived from gyroscope)</li> <li>\\(H_p(s)\\) - Position sensor (from accelerometer)</li> </ul>"},{"location":"chapters/09-block-diagrams-signal-flow/#diagram-gyras-cascade-control-block-diagram","title":"Diagram: Gyra's Cascade Control Block Diagram","text":"Gyra's Cascade Control Block Diagram <p>Type: diagram</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: organize, deconstruct</p> <p>Learning Objective: Students will deconstruct Gyra's cascade control system into nested loop structures, identifying which loops must be reduced first.</p> <p>Purpose: Show realistic cascade control structure with physical interpretation for each block</p> <p>Components to show: - Reference input: Desired tilt angle \u03b8_ref (typically 0\u00b0 for upright) - Outer loop controller G_c(s): Position controller (PD or PID) - Velocity reference: Output of position controller - Middle loop controller G_v(s): Velocity controller - Current reference: Output of velocity controller - Inner loop controller G_i(s): Current controller - Motor G_m(s): Motor electrical and mechanical dynamics - Plant G_p(s): Gyra's inverted pendulum dynamics - Output \u03b8: Actual tilt angle - Current sensor H_i(s): Measures motor current - Velocity sensor H_v(s): From gyroscope - Position sensor H_p(s): From accelerometer/IMU fusion</p> <p>Visual layout: - Nested rectangular regions showing each loop - Inner loop in innermost region (light blue) - Middle loop in middle region (light green) - Outer loop in outermost region (light yellow) - Clear signal flow arrows</p> <p>Interactive features: - Click on any loop region to highlight that loop's components - Hover over any block to see physical description and typical transfer function form - Button: \"Show reduction order\" - animates the inside-out reduction sequence - Button: \"Show equivalent blocks\" - shows result of reducing each loop</p> <p>Color scheme: - Position loop: yellow/gold - Velocity loop: green - Current loop: blue - Physical plant: gray - Sensors: purple</p> <p>Implementation: vis-network or custom interactive SVG Canvas size: 900x550px, responsive</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#reducing-gyras-control-structure","title":"Reducing Gyra's Control Structure","text":"<p>To find the overall transfer function from desired angle to actual angle, we reduce inside-out:</p> <p>Step 1: Reduce the inner (current) loop</p> <p>\\(T_i(s) = \\frac{G_i(s) G_m(s)}{1 + G_i(s) G_m(s) H_i(s)}\\)</p> <p>This represents the \"controlled motor\" that delivers current proportional to command.</p> <p>Step 2: Reduce the middle (velocity) loop</p> <p>The forward path is now \\(G_v(s) T_i(s) G_p(s)\\). With velocity feedback:</p> <p>\\(T_v(s) = \\frac{G_v(s) T_i(s) G_p(s)}{1 + G_v(s) T_i(s) G_p(s) H_v(s)}\\)</p> <p>Step 3: Reduce the outer (position) loop</p> <p>Finally, with position feedback:</p> <p>\\(T(s) = \\frac{G_c(s) T_v(s)}{1 + G_c(s) T_v(s) H_p(s)}\\)</p> <p>Substituting backwards gives the complete transfer function\u2014which would be extremely messy if written out fully, but the structured approach keeps it manageable.</p> <p>Gyra Moment</p> <p>\"My inner current loop responds in milliseconds\u2014it's like a reflex, too fast for me to even notice. My velocity loop is a bit slower, smoothing out the jerkiness. And my position loop? That's the one that really keeps me upright, comparing where I am to where I should be, over and over.\"</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#loop-gain-and-stability-preview","title":"Loop Gain and Stability Preview","text":"<p>While detailed stability analysis comes in later chapters, block diagrams provide immediate insight into a crucial stability quantity: the loop gain.</p> <p>The loop gain \\(L(s) = G(s)H(s)\\) determines system stability. Specifically, the closed-loop system is stable if and only if all roots of the characteristic equation:</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#characteristic-equation","title":"Characteristic Equation","text":"<p>\\(1 + L(s) = 0\\)</p> <p>have negative real parts (lie in the left half of the s-plane).</p> <p>Block diagrams make the loop gain visually apparent\u2014just multiply the transfer functions around any feedback loop. This connection between graphical representation and stability is one of the great insights of classical control theory.</p>"},{"location":"chapters/09-block-diagrams-signal-flow/#summary_1","title":"Summary","text":"<p>This chapter developed two complementary graphical methods for analyzing control systems:</p> <p>Block Diagrams:</p> <ul> <li>Built from blocks, summing junctions, and pickoff points</li> <li>Cascade connections multiply transfer functions</li> <li>Parallel connections add transfer functions</li> <li>Feedback connections use \\(T = \\frac{G}{1+GH}\\)</li> <li>Reduction follows inside-out strategy for nested loops</li> <li>Block diagram algebra enables systematic simplification</li> </ul> <p>Signal Flow Graphs:</p> <ul> <li>Nodes represent signals; branches represent transfer functions</li> <li>More compact than block diagrams for complex systems</li> <li>Mason's gain formula finds transfer functions directly</li> </ul> <p>Key Formulas:</p> Concept Formula Closed-loop transfer (negative feedback) \\(T = \\frac{G}{1+GH}\\) Closed-loop transfer (positive feedback) \\(T = \\frac{G}{1-GH}\\) Open-loop transfer function \\(L = GH\\) Characteristic equation \\(1 + GH = 0\\) Mason's gain formula \\(T = \\frac{\\sum P_k \\Delta_k}{\\Delta}\\) <p>These graphical tools transform abstract mathematical relationships into visible structures that reveal system architecture, signal flow, and the critical feedback loops that determine behavior. Whether you're designing a new controller for Gyra or analyzing an industrial process control system, block diagrams and signal flow graphs are indispensable companions.</p> Check Your Understanding: What happens to the closed-loop transfer function if feedback is removed (H = 0)? <p>When \\(H(s) = 0\\) (no feedback), the closed-loop formula \\(T = \\frac{G}{1+GH}\\) becomes \\(T = \\frac{G}{1+0} = G\\). The system becomes open-loop\u2014output equals input times forward gain, with no error correction. This is exactly what we'd expect: removing feedback converts a closed-loop system into an open-loop system.</p> Check Your Understanding: In Mason's formula, what is the cofactor for a forward path that touches all loops? <p>If a forward path touches all loops in the graph, then when we remove those loops to calculate the cofactor, no loops remain. The cofactor formula \\(\\Delta_k = 1 - \\sum L_i^{(k)} + \\cdots\\) has all terms zero except the 1, so \\(\\Delta_k = 1\\). This is the most common case in simple systems.</p>"},{"location":"chapters/10-stability-routh-hurwitz/","title":"Stability Analysis and the Routh-Hurwitz Criterion","text":""},{"location":"chapters/10-stability-routh-hurwitz/#summary","title":"Summary","text":"<p>This chapter introduces the critical concept of stability in feedback control systems. Students will learn multiple stability definitions including BIBO (bounded-input, bounded-output), asymptotic, and marginal stability, and understand how these relate to pole locations. The characteristic equation and polynomial are developed as tools for stability analysis. The Routh-Hurwitz criterion provides an algebraic method to determine stability without solving for poles directly. Special cases including zeros in the first column and rows of zeros are addressed. Relative stability concepts introduce the idea that some stable systems are more stable than others.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 20 concepts from the learning graph:</p> <ol> <li>Stability</li> <li>BIBO Stability</li> <li>Internal Stability</li> <li>Asymptotic Stability</li> <li>Marginal Stability</li> <li>Unstable System</li> <li>Bounded Input</li> <li>Bounded Output</li> <li>Characteristic Equation</li> <li>Characteristic Polynomial</li> <li>Characteristic Roots</li> <li>Routh-Hurwitz Criterion</li> <li>Routh Array</li> <li>Routh Array Construction</li> <li>Special Cases Routh</li> <li>Zero in First Column</li> <li>Row of Zeros</li> <li>Auxiliary Polynomial</li> <li>Stability Boundary</li> <li>Relative Stability</li> </ol>"},{"location":"chapters/10-stability-routh-hurwitz/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Introduction to Control Systems</li> <li>Chapter 4: Transient Response Specifications</li> <li>Chapter 6: Poles, Zeros, and System Analysis</li> <li>Chapter 9: Block Diagrams and Signal Flow</li> </ul>"},{"location":"chapters/10-stability-routh-hurwitz/#the-question-every-engineer-must-answer","title":"The Question Every Engineer Must Answer","text":"<p>Before you optimize a system's speed, before you minimize overshoot, before you worry about steady-state error\u2014you must answer one fundamental question: Will this system blow up?</p> <p>Stability isn't just one of many design requirements; it's the prerequisite for all other requirements to matter. An unstable control system is worse than useless\u2014it's actively dangerous. Rockets explode, robots run away, chemical plants catch fire, power grids collapse. The mathematics of stability analysis isn't abstract theory; it's the engineer's first line of defense against catastrophe.</p> <p>In Chapter 6, we learned that poles in the right half-plane (RHP) cause exponential growth\u2014instability. That insight is powerful, but it comes with a practical problem: finding pole locations requires solving polynomial equations, and for polynomials of degree 5 or higher, there's no general closed-form solution. What do we do when we can't find the poles?</p> <p>Enter the Routh-Hurwitz criterion\u2014an elegant algebraic test that determines stability without ever finding the poles themselves. By the end of this chapter, you'll be able to check stability for systems of any order using only arithmetic, determine how many poles are in the RHP, find stability boundaries as functions of controller parameters, and handle the special cases that arise in practice.</p> <p>This is one of the most useful tools in your control engineering toolkit.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#what-is-stability","title":"What Is Stability?","text":"<p>The word \"stability\" gets used loosely in everyday language\u2014a \"stable\" relationship, a \"stable\" economy. In control systems, we need precise definitions. A system's stability tells us whether its response to disturbances will eventually die out or grow without bound.</p> <p>Consider Gyra trying to balance. If she leans slightly forward and her controller brings her back to vertical, she's stable. If a small lean causes her to fall over completely, she's unstable. If she wobbles forever at constant amplitude, she's marginally stable. These everyday observations correspond to mathematical definitions we'll now make precise.</p> <p>Gyra Moment</p> <p>\"Stability is my existential question. Every millisecond, my controller asks: 'Will this disturbance die out, or will it grow until I crash?' The math you're learning is the same math running inside me, deciding 50 times per second whether I'm about to fall.\"</p>"},{"location":"chapters/10-stability-routh-hurwitz/#bounded-input-and-bounded-output","title":"Bounded Input and Bounded Output","text":"<p>Before defining stability formally, we need to clarify what \"bounded\" means.</p> <p>A bounded input is a signal that remains finite for all time. Mathematically:</p>"},{"location":"chapters/10-stability-routh-hurwitz/#bounded-input-definition","title":"Bounded Input Definition","text":"<p>\\(|u(t)| \\leq M_u &lt; \\infty \\text{ for all } t \\geq 0\\)</p> <p>where:</p> <ul> <li>\\(u(t)\\) is the input signal</li> <li>\\(M_u\\) is some finite constant</li> </ul> <p>Common bounded inputs include:</p> <ul> <li>Step functions</li> <li>Sinusoids</li> <li>Any signal that doesn't grow to infinity</li> </ul> <p>A bounded output follows the same pattern\u2014a signal that remains finite:</p>"},{"location":"chapters/10-stability-routh-hurwitz/#bounded-output-definition","title":"Bounded Output Definition","text":"<p>\\(|y(t)| \\leq M_y &lt; \\infty \\text{ for all } t \\geq 0\\)</p> <p>where:</p> <ul> <li>\\(y(t)\\) is the output signal</li> <li>\\(M_y\\) is some finite constant</li> </ul> Signal Type Bounded? Reason Step: \\(u(t) = 1\\) Yes Constant, finite Sine: \\(u(t) = \\sin(\\omega t)\\) Yes Always between -1 and 1 Ramp: \\(u(t) = t\\) No Grows without bound Exponential: \\(u(t) = e^{t}\\) No Grows without bound Decaying: \\(u(t) = e^{-t}\\) Yes Decays to zero <p>Understanding boundedness is essential because stability definitions revolve around the relationship between bounded inputs and bounded outputs.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#bibo-stability-the-input-output-view","title":"BIBO Stability: The Input-Output View","text":"<p>BIBO stability (Bounded-Input, Bounded-Output stability) is the most intuitive stability definition. A system is BIBO stable if every bounded input produces a bounded output.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#bibo-stability-definition","title":"BIBO Stability Definition","text":"<p>A system is BIBO stable if and only if:</p> <p>For every bounded input \\(u(t)\\), the output \\(y(t)\\) is also bounded.</p> <p>This is an input-output view of stability\u2014we only care about what goes in and what comes out. We don't look \"inside\" the system at internal state variables.</p> <p>For linear time-invariant (LTI) systems described by transfer functions, BIBO stability has a clean characterization:</p> <p>BIBO Stability Criterion</p> <p>A transfer function \\(G(s)\\) is BIBO stable if and only if all its poles have negative real parts\u2014that is, all poles lie in the open left half-plane (LHP).</p> <p>This connects directly to what we learned in Chapter 6. Each pole contributes a mode to the response:</p> <ul> <li>LHP poles \u2192 decaying modes \u2192 bounded contributions</li> <li>RHP poles \u2192 growing modes \u2192 unbounded contributions</li> <li>Imaginary axis poles \u2192 sustained oscillations \u2192 potentially unbounded</li> </ul> <p>The \"potentially\" for imaginary axis poles depends on the input. If the input contains the same frequency as an imaginary axis pole, resonance can cause unbounded growth. This is why we exclude the imaginary axis from the stable region.</p> Pole Location BIBO Stable? Time Response All in LHP Yes All modes decay Any in RHP No At least one mode grows Any on imaginary axis No Sustained or growing oscillation"},{"location":"chapters/10-stability-routh-hurwitz/#asymptotic-stability-eventually-settling-down","title":"Asymptotic Stability: Eventually Settling Down","text":"<p>Asymptotic stability looks at what happens to the system's response as time goes to infinity, specifically starting from any initial condition with zero input.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#asymptotic-stability-definition","title":"Asymptotic Stability Definition","text":"<p>A system is asymptotically stable if:</p> <p>\\(\\lim_{t \\to \\infty} y(t) = 0\\)</p> <p>for any initial conditions and zero input.</p> <p>In words: disturb the system from equilibrium and then leave it alone. If it returns to equilibrium, it's asymptotically stable.</p> <p>For LTI systems, asymptotic stability and BIBO stability are essentially equivalent when the transfer function captures all system dynamics. A system is asymptotically stable if and only if all poles are in the open LHP.</p> <p>The intuition: asymptotic stability means all natural modes decay. Since the natural modes correspond to poles, all poles must be in the LHP where exponential decay occurs.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#marginal-stability-the-edge-case","title":"Marginal Stability: The Edge Case","text":"<p>Marginal stability (also called critical stability) describes systems that neither settle down nor blow up\u2014they sit on the boundary between stability and instability.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#marginal-stability-definition","title":"Marginal Stability Definition","text":"<p>A system is marginally stable if:</p> <ul> <li>The output remains bounded for bounded inputs (no growth)</li> <li>The output does not decay to zero (no settling)</li> </ul> <p>For LTI systems, marginal stability occurs when:</p> <ul> <li>All poles are in the LHP or on the imaginary axis</li> <li>Poles on the imaginary axis are simple (not repeated)</li> </ul> <p>A pole at \\(s = j\\omega\\) produces a sustained sinusoid at frequency \\(\\omega\\). A pole at \\(s = 0\\) produces a constant offset. These don't decay, but they don't grow either\u2014as long as they're simple poles.</p> Pole Configuration Stability Type All poles strictly in LHP Asymptotically stable Simple poles on imaginary axis, none in RHP Marginally stable Repeated poles on imaginary axis Unstable Any pole in RHP Unstable <p>Marginal Stability Is Fragile</p> <p>Marginally stable systems are theoretical idealizations. In practice, friction, resistance, or any tiny perturbation pushes the poles slightly left (stable) or right (unstable). A \"marginally stable\" design is living dangerously\u2014the slightest model error can tip it either way.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#internal-stability-looking-inside","title":"Internal Stability: Looking Inside","text":"<p>Internal stability goes beyond input-output behavior to examine what happens to all internal state variables. A system can be BIBO stable (bounded output for bounded input) while having internal variables that grow without bound\u2014a dangerous hidden instability.</p> <p>This can happen when unstable poles are cancelled by zeros in the transfer function. Consider:</p>"},{"location":"chapters/10-stability-routh-hurwitz/#hidden-instability-example","title":"Hidden Instability Example","text":"<p>\\(G(s) = \\frac{s - 2}{(s + 1)(s - 2)} = \\frac{1}{s + 1}\\)</p> <p>The transfer function simplifies to a stable first-order system. But the pole at \\(s = +2\\) still exists in the original system\u2014it's just invisible in the input-output relationship. Any disturbance or initial condition can excite this hidden mode, causing an internal state to grow exponentially while the output appears well-behaved.</p> <p>A system is internally stable if all modes decay, including those cancelled by zeros. For practical control design:</p> <p>Never Cancel Unstable Poles</p> <p>Attempting to stabilize a system by placing a controller zero on an unstable pole creates internal instability. The output may look fine, but internal state variables are growing exponentially. Eventually, something will saturate, the model will break down, and failure will occur suddenly and catastrophically.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#unstable-systems-when-things-go-wrong","title":"Unstable Systems: When Things Go Wrong","text":"<p>An unstable system is one that fails the stability test\u2014its response grows without bound for some bounded input or some initial condition. For LTI systems, instability means at least one pole is in the right half-plane or a repeated pole is on the imaginary axis.</p> <p>The consequences of instability depend on the application:</p> <ul> <li>Mechanical systems: Excessive vibration, structural failure</li> <li>Electrical systems: Component burnout, circuit destruction</li> <li>Aerospace: Loss of vehicle, crash</li> <li>Chemical processes: Runaway reactions, explosions</li> <li>Thermal systems: Overheating, fires</li> </ul> <p>Helping Gyra</p> <p>\"When I'm unstable, it starts small\u2014a tiny wobble I can't quite correct. But exponential growth is relentless. That wobble doubles, then doubles again. Within a fraction of a second, I'm past the point of no return, falling with increasing speed until I hit the floor. Stability margin isn't just a number; it's my margin for survival.\"</p> <p>The study of stability isn't about avoiding minor inconveniences\u2014it's about preventing catastrophic failure. This is why stability analysis comes before any other design consideration.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#the-characteristic-equation-and-polynomial","title":"The Characteristic Equation and Polynomial","text":"<p>The characteristic polynomial is the denominator of the closed-loop transfer function, and the characteristic equation is that polynomial set equal to zero.</p> <p>For a transfer function:</p>"},{"location":"chapters/10-stability-routh-hurwitz/#characteristic-polynomial","title":"Characteristic Polynomial","text":"<p>\\(G(s) = \\frac{N(s)}{D(s)}\\)</p> <p>The characteristic polynomial is \\(D(s)\\), and the characteristic equation is:</p> <p>\\(D(s) = 0\\)</p> <p>For a standard negative feedback system with forward gain \\(G(s)\\) and feedback \\(H(s)\\):</p>"},{"location":"chapters/10-stability-routh-hurwitz/#closed-loop-characteristic-equation","title":"Closed-Loop Characteristic Equation","text":"<p>\\(1 + G(s)H(s) = 0\\)</p> <p>Rearranging: the characteristic polynomial is the numerator of \\(1 + G(s)H(s)\\) after combining over a common denominator.</p> <p>The characteristic roots are the solutions to the characteristic equation\u2014these are the closed-loop poles. The stability of the system depends entirely on the locations of these roots.</p> <p>Consider a closed-loop system with:</p> <p>\\(G(s) = \\frac{K}{s(s+2)(s+5)}\\), \\(H(s) = 1\\)</p> <p>The characteristic equation is:</p> <p>\\(1 + G(s)H(s) = 1 + \\frac{K}{s(s+2)(s+5)} = 0\\)</p> <p>Multiplying through:</p> <p>\\(s(s+2)(s+5) + K = 0\\)</p> <p>\\(s^3 + 7s^2 + 10s + K = 0\\)</p> <p>This is a cubic polynomial. For small \\(K\\), the roots are near \\(s = 0, -2, -5\\) (stable). As \\(K\\) increases, the roots move. At some critical \\(K\\), roots may cross into the RHP, causing instability. The Routh-Hurwitz criterion will tell us exactly when.</p> Component Definition Characteristic polynomial Denominator \\(D(s)\\) of closed-loop transfer function Characteristic equation \\(D(s) = 0\\) Characteristic roots Solutions to characteristic equation (closed-loop poles)"},{"location":"chapters/10-stability-routh-hurwitz/#why-we-need-the-routh-hurwitz-criterion","title":"Why We Need the Routh-Hurwitz Criterion","text":"<p>You might wonder: if stability depends on pole locations, why not just find the poles? Here's the problem: there's no general formula for finding roots of polynomials of degree 5 or higher. This is a fundamental mathematical limitation proved in the 19th century (the Abel-Ruffini theorem).</p> <p>Even for polynomials where we can find roots:</p> <ul> <li>The algebra becomes tedious for degree 3 and 4</li> <li>Symbolic solutions become unwieldy</li> <li>We often care about stability boundaries in terms of parameters (like gain \\(K\\)), not specific pole values</li> </ul> <p>The Routh-Hurwitz criterion provides an elegant solution: determine whether all roots of a polynomial are in the left half-plane using only the polynomial coefficients\u2014no root finding required.</p> <p>The criterion was developed independently by Edward Routh (1877) and Adolf Hurwitz (1895). Routh's approach uses a tabular method (the Routh array), while Hurwitz used determinants. The results are equivalent; we'll focus on the Routh array because it's more practical for hand calculation.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#diagram-stability-analysis-timeline","title":"Diagram: Stability Analysis Timeline","text":"Stability Analysis Timeline <p>Type: timeline</p> <p>Bloom Taxonomy: Remember (L1) Bloom Verb: recall, identify</p> <p>Learning Objective: Students will recall the historical development of stability analysis methods.</p> <p>Time period: 1850-1900</p> <p>Orientation: Horizontal</p> <p>Events: - 1868: James Clerk Maxwell publishes \"On Governors\" analyzing steam engine regulation - 1877: Edward Routh develops tabular stability criterion, wins Adams Prize - 1890: A.M. Lyapunov develops general stability theory - 1895: Adolf Hurwitz independently develops determinant-based criterion</p> <p>Visual style: Horizontal timeline with portraits and key publications</p> <p>Color coding: - Blue: Routh's contribution - Green: Hurwitz's contribution - Gray: Related developments</p> <p>Interactive features: - Hover over events to see brief descriptions - Click for expanded historical context</p> <p>Implementation: HTML/CSS/JavaScript</p>"},{"location":"chapters/10-stability-routh-hurwitz/#the-routh-hurwitz-criterion","title":"The Routh-Hurwitz Criterion","text":"<p>The Routh-Hurwitz criterion states conditions under which a polynomial has all roots in the left half-plane. Given a polynomial:</p>"},{"location":"chapters/10-stability-routh-hurwitz/#general-polynomial-form","title":"General Polynomial Form","text":"<p>\\(D(s) = a_n s^n + a_{n-1} s^{n-1} + \\cdots + a_1 s + a_0\\)</p> <p>where:</p> <ul> <li>\\(a_n &gt; 0\\) (leading coefficient positive)</li> <li>All \\(a_i\\) are real</li> </ul> <p>The criterion has two parts:</p> <p>Necessary Condition: All coefficients \\(a_i\\) must be positive (assuming \\(a_n &gt; 0\\)). If any coefficient is zero, negative, or missing, the system is either unstable or marginally stable.</p> <p>Necessary and Sufficient Condition: Construct the Routh array from the coefficients. All elements in the first column of the Routh array must be positive.</p> <p>Necessary vs. Sufficient</p> <p>The \"all coefficients positive\" test is necessary but not sufficient. A polynomial can have all positive coefficients but still be unstable. The full Routh array test is both necessary and sufficient\u2014it gives a definitive answer.</p> <p>For a second-order polynomial \\(as^2 + bs + c\\), the necessary condition (all positive coefficients) is also sufficient. For third-order and higher, we need the Routh array.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#routh-array-construction","title":"Routh Array Construction","text":"<p>The Routh array is a triangular table built from polynomial coefficients. The number of sign changes in the first column equals the number of roots in the right half-plane.</p> <p>Given a polynomial of degree \\(n\\):</p> <p>\\(D(s) = a_n s^n + a_{n-1} s^{n-1} + \\cdots + a_1 s + a_0\\)</p> <p>The Routh array has \\(n+1\\) rows, labeled from \\(s^n\\) down to \\(s^0\\).</p>"},{"location":"chapters/10-stability-routh-hurwitz/#routh-array-structure","title":"Routh Array Structure","text":"<p>First two rows come directly from the polynomial coefficients:</p> <ul> <li>Row \\(s^n\\): \\(a_n\\), \\(a_{n-2}\\), \\(a_{n-4}\\), ... (even-indexed from the top)</li> <li>Row \\(s^{n-1}\\): \\(a_{n-1}\\), \\(a_{n-3}\\), \\(a_{n-5}\\), ... (odd-indexed from the top)</li> </ul> <p>Subsequent rows are calculated using a determinant-like formula:</p> <p>For row \\(s^{n-2}\\) and beyond, each element is:</p> <p>\\(\\text{element} = -\\frac{1}{\\text{pivot}} \\begin{vmatrix} \\text{first column entry above} &amp; \\text{column entry above} \\\\ \\text{first column entry two above} &amp; \\text{column entry two above} \\end{vmatrix}\\)</p> <p>Or more simply:</p> <p>\\(b_1 = \\frac{a_{n-1} a_{n-2} - a_n a_{n-3}}{a_{n-1}}\\)</p> <p>Let's construct the array for a fourth-order polynomial:</p> <p>\\(D(s) = a_4 s^4 + a_3 s^3 + a_2 s^2 + a_1 s + a_0\\)</p> Row Column 1 Column 2 Column 3 \\(s^4\\) \\(a_4\\) \\(a_2\\) \\(a_0\\) \\(s^3\\) \\(a_3\\) \\(a_1\\) 0 \\(s^2\\) \\(b_1 = \\frac{a_3 a_2 - a_4 a_1}{a_3}\\) \\(b_2 = \\frac{a_3 a_0 - a_4 \\cdot 0}{a_3} = a_0\\) 0 \\(s^1\\) \\(c_1 = \\frac{b_1 a_1 - a_3 b_2}{b_1}\\) 0 0 \\(s^0\\) \\(a_0\\) 0 0 <p>The first column is what matters: \\(a_4, a_3, b_1, c_1, a_0\\).</p> <p>Routh-Hurwitz Stability Test</p> <p>The number of sign changes in the first column of the Routh array equals the number of roots in the right half-plane. For stability, all first-column elements must be positive (no sign changes).</p>"},{"location":"chapters/10-stability-routh-hurwitz/#diagram-routh-array-constructor","title":"Diagram: Routh Array Constructor","text":"Routh Array Constructor <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: execute, calculate</p> <p>Learning Objective: Students will construct Routh arrays from polynomial coefficients and determine stability by counting sign changes.</p> <p>Canvas layout: - Top (40%): Coefficient input area and polynomial display - Bottom (60%): Routh array with step-by-step construction</p> <p>Visual elements: Input Area: - Polynomial degree selector (2-6) - Coefficient input fields with labels (a_n, a_{n-1}, etc.) - Displayed polynomial in standard form</p> <p>Routh Array: - Grid structure with row labels (s^n, s^{n-1}, etc.) - Cells showing calculated values - First column highlighted - Sign changes marked with red indicators - Calculation tooltips showing formulas used</p> <p>Interactive controls: - Input: Polynomial degree (dropdown 2-6) - Input: Coefficient values (number fields) - Button: Calculate Array - Button: Step Through (builds array row by row) - Button: Reset - Toggle: Show calculation details</p> <p>Data Visibility Requirements: - Stage 1: Show input coefficients arranged in first two rows - Stage 2: Show calculation for first element of row 3 - Stage 3: Complete row 3 - Continue for each row - Final: Highlight first column, count and display sign changes</p> <p>Behavior: - Input validation: warns if leading coefficient is zero or negative - Step-through mode shows one calculation at a time - Current calculation highlighted and formula displayed - Sign changes counted automatically - Stability verdict displayed: \"STABLE (0 RHP poles)\" or \"UNSTABLE (N RHP poles)\" - Warns about special cases (zero in first column, row of zeros)</p> <p>Instructional Rationale: Step-through construction with visible formulas helps students internalize the mechanical process. Seeing calculations explicitly builds procedural fluency before applying to design problems.</p> <p>Implementation: p5.js with canvas-based input fields and dynamic table rendering</p>"},{"location":"chapters/10-stability-routh-hurwitz/#example-third-order-system-stability","title":"Example: Third-Order System Stability","text":"<p>Let's apply the Routh criterion to the characteristic polynomial from our earlier feedback system:</p> <p>\\(D(s) = s^3 + 7s^2 + 10s + K\\)</p> <p>where \\(K\\) is the forward gain. We want to find the range of \\(K\\) for stability.</p> <p>Step 1: Check necessary condition. For all coefficients positive, we need \\(K &gt; 0\\).</p> <p>Step 2: Construct the Routh array.</p> Row Column 1 Column 2 \\(s^3\\) 1 10 \\(s^2\\) 7 K \\(s^1\\) \\(\\frac{7 \\cdot 10 - 1 \\cdot K}{7} = \\frac{70 - K}{7}\\) 0 \\(s^0\\) K 0 <p>Step 3: Apply stability criterion. All first-column elements must be positive:</p> <ul> <li>\\(1 &gt; 0\\) \u2713 (always)</li> <li>\\(7 &gt; 0\\) \u2713 (always)</li> <li>\\(\\frac{70 - K}{7} &gt; 0\\) \u2192 \\(K &lt; 70\\)</li> <li>\\(K &gt; 0\\)</li> </ul> <p>Stability Range: \\(0 &lt; K &lt; 70\\)</p> <p>At \\(K = 70\\), the \\(s^1\\) row has a zero\u2014this is the stability boundary. We'll handle this special case shortly.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#example-fourth-order-system","title":"Example: Fourth-Order System","text":"<p>Consider:</p> <p>\\(D(s) = s^4 + 2s^3 + 3s^2 + 4s + 5\\)</p> <p>Step 1: All coefficients are positive \u2713</p> <p>Step 2: Construct the Routh array.</p> Row Column 1 Column 2 Column 3 \\(s^4\\) 1 3 5 \\(s^3\\) 2 4 0 \\(s^2\\) \\(\\frac{2 \\cdot 3 - 1 \\cdot 4}{2} = 1\\) \\(\\frac{2 \\cdot 5 - 1 \\cdot 0}{2} = 5\\) 0 \\(s^1\\) \\(\\frac{1 \\cdot 4 - 2 \\cdot 5}{1} = -6\\) 0 0 \\(s^0\\) 5 0 0 <p>Step 3: Count sign changes in first column: \\(1, 2, 1, -6, 5\\)</p> <p>Sign changes: - \\(1 \u2192 2\\): no change (+\u2192+) - \\(2 \u2192 1\\): no change (+\u2192+) - \\(1 \u2192 -6\\): sign change (+\u2192\u2212) - \\(-6 \u2192 5\\): sign change (\u2212\u2192+)</p> <p>Result: 2 sign changes \u2192 2 poles in RHP \u2192 System is unstable</p> <p>Even though all coefficients were positive, the system is unstable. This demonstrates why the necessary condition is not sufficient for higher-order polynomials.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#special-case-zero-in-first-column","title":"Special Case: Zero in First Column","text":"<p>Sometimes during Routh array construction, an element in the first column becomes zero while other elements in that row are nonzero. This creates a division-by-zero problem when computing the next row.</p> <p>Solution: Replace the zero with a small positive number \\(\\epsilon\\) and continue the construction. After completing the array, let \\(\\epsilon \u2192 0^+\\) to determine sign changes.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#zero-in-first-column-example","title":"Zero in First Column Example","text":"<p>Consider:</p> <p>\\(D(s) = s^5 + 2s^4 + 2s^3 + 4s^2 + 11s + 10\\)</p> Row Column 1 Column 2 Column 3 \\(s^5\\) 1 2 11 \\(s^4\\) 2 4 10 \\(s^3\\) \\(\\frac{2 \\cdot 2 - 1 \\cdot 4}{2} = 0\\) \u2192 \\(\\epsilon\\) \\(\\frac{2 \\cdot 11 - 1 \\cdot 10}{2} = 6\\) 0 \\(s^2\\) \\(\\frac{\\epsilon \\cdot 4 - 2 \\cdot 6}{\\epsilon} = 4 - \\frac{12}{\\epsilon}\\) ... ... <p>As \\(\\epsilon \u2192 0^+\\), \\(4 - \\frac{12}{\\epsilon} \u2192 -\\infty\\) (large negative).</p> <p>The sign of the \\(s^2\\) row first column is negative for small positive \\(\\epsilon\\). Continue the analysis to count total sign changes.</p> <p>Epsilon Method</p> <p>The \\(\\epsilon\\) method works but can be tedious. Some textbooks teach alternative approaches like multiplying the row by a positive constant or using L'H\u00f4pital's rule. The key insight: a zero in the first column indicates either a pole at the origin or poles symmetric about the imaginary axis.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#special-case-row-of-zeros","title":"Special Case: Row of Zeros","text":"<p>A more significant special case occurs when an entire row becomes zero. This indicates that the polynomial has:</p> <ul> <li>Pairs of roots symmetric about the origin (either on the imaginary axis or symmetric LHP/RHP pairs)</li> <li>The system is at best marginally stable</li> </ul> <p>When a row of zeros occurs, we:</p> <ol> <li>Form the auxiliary polynomial from the row above the zero row</li> <li>Take the derivative of the auxiliary polynomial</li> <li>Use the coefficients of the derivative to replace the zero row</li> <li>Continue the Routh array construction</li> </ol>"},{"location":"chapters/10-stability-routh-hurwitz/#auxiliary-polynomial","title":"Auxiliary Polynomial","text":"<p>The auxiliary polynomial is formed from the row immediately above the zero row. Its degree equals the power of \\(s\\) for that row.</p> <p>For example, if row \\(s^4\\) is: \\(2, 8, 6\\), the auxiliary polynomial is:</p> <p>\\(A(s) = 2s^4 + 8s^2 + 6\\)</p> <p>(Only even or odd powers appear because of how the Routh array alternates.)</p> <p>The derivative is:</p> <p>\\(\\frac{dA}{ds} = 8s^3 + 16s\\)</p> <p>Coefficients: \\(8, 16\\) replace the zero row.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#row-of-zeros-example","title":"Row of Zeros Example","text":"<p>\\(D(s) = s^5 + 2s^4 + 2s^3 + 4s^2 + s + 2\\)</p> Row Column 1 Column 2 Column 3 \\(s^5\\) 1 2 1 \\(s^4\\) 2 4 2 \\(s^3\\) \\(\\frac{2 \\cdot 2 - 1 \\cdot 4}{2} = 0\\) \\(\\frac{2 \\cdot 1 - 1 \\cdot 2}{2} = 0\\) 0 <p>Row \\(s^3\\) is entirely zero!</p> <p>Auxiliary polynomial from row \\(s^4\\): \\(A(s) = 2s^4 + 4s^2 + 2\\)</p> <p>Derivative: \\(\\frac{dA}{ds} = 8s^3 + 8s\\)</p> <p>Replace zero row with coefficients: \\(8, 8\\)</p> Row Column 1 Column 2 Column 3 \\(s^5\\) 1 2 1 \\(s^4\\) 2 4 2 \\(s^3\\) 8 8 0 \\(s^2\\) \\(\\frac{8 \\cdot 4 - 2 \\cdot 8}{8} = 2\\) 2 0 \\(s^1\\) \\(\\frac{2 \\cdot 8 - 8 \\cdot 2}{2} = 0\\) 0 0 <p>Another row of zeros at \\(s^1\\). Auxiliary polynomial from \\(s^2\\): \\(A(s) = 2s^2 + 2\\)</p> <p>Derivative: \\(4s\\), so row becomes: \\(4, 0\\)</p> Row Column 1 \\(s^5\\) 1 \\(s^4\\) 2 \\(s^3\\) 8 \\(s^2\\) 2 \\(s^1\\) 4 \\(s^0\\) 2 <p>First column: all positive \u2192 no sign changes \u2192 no RHP poles.</p> <p>But wait! The row of zeros indicates symmetric roots. The auxiliary polynomial \\(A(s) = 2s^4 + 4s^2 + 2 = 2(s^4 + 2s^2 + 1) = 2(s^2 + 1)^2\\) has roots at \\(s = \\pm j\\) (repeated).</p> <p>Conclusion: System has repeated poles on the imaginary axis \u2192 unstable (by our definition) or at best marginally stable.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#diagram-row-of-zeros-analysis","title":"Diagram: Row of Zeros Analysis","text":"Row of Zeros Analysis <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: differentiate, examine</p> <p>Learning Objective: Students will analyze Routh array special cases by constructing auxiliary polynomials and interpreting symmetric root patterns.</p> <p>Canvas layout: - Left (50%): Routh array with step-by-step construction - Right (50%): S-plane showing pole locations and symmetry</p> <p>Visual elements: Routh Array: - Highlighted row when zero row detected - Auxiliary polynomial displayed - Derivative calculation shown - Replacement row highlighted in different color</p> <p>S-Plane: - Poles plotted as array is constructed - Symmetry lines visible when row of zeros occurs - Imaginary axis highlighted - LHP/RHP regions shaded</p> <p>Interactive controls: - Input: Polynomial coefficients - Button: Step through construction - Button: Show auxiliary polynomial roots - Toggle: Animate pole movement as array builds</p> <p>Data Visibility Requirements: - Stage 1: Initial array with zero row detected - Stage 2: Form auxiliary polynomial explicitly - Stage 3: Show derivative calculation - Stage 4: Replace row and continue - Stage 5: Solve auxiliary polynomial to show symmetric roots - Final: Display complete pole pattern on s-plane</p> <p>Behavior: - Zero row automatically detected and flagged - Auxiliary polynomial formation shown step-by-step - Roots of auxiliary polynomial displayed on s-plane - Interpretation provided (imaginary axis poles, symmetric RHP/LHP pairs)</p> <p>Instructional Rationale: Connecting the algebraic procedure to geometric pole locations builds conceptual understanding of why the row of zeros occurs and what it means for stability.</p> <p>Implementation: p5.js with split canvas for array and s-plane</p>"},{"location":"chapters/10-stability-routh-hurwitz/#the-stability-boundary","title":"The Stability Boundary","text":"<p>The stability boundary is the surface in parameter space where the system transitions from stable to unstable. At the stability boundary, poles lie exactly on the imaginary axis.</p> <p>For a system with adjustable gain \\(K\\), the stability boundary occurs when:</p> <ul> <li>A first-column element of the Routh array equals zero, or</li> <li>A row of zeros appears</li> </ul> <p>From our third-order example:</p> <p>\\(D(s) = s^3 + 7s^2 + 10s + K\\)</p> <p>The first-column element in the \\(s^1\\) row is \\(\\frac{70 - K}{7}\\).</p> <p>Stability boundary: \\(\\frac{70 - K}{7} = 0\\) \u2192 \\(K = 70\\)</p> <p>At \\(K = 70\\), we form the auxiliary polynomial from the \\(s^2\\) row: \\(A(s) = 7s^2 + 70 = 7(s^2 + 10)\\)</p> <p>Roots: \\(s = \\pm j\\sqrt{10} \\approx \\pm j3.16\\)</p> <p>At the stability boundary, the system has a pair of poles on the imaginary axis at \\(\\pm j\\sqrt{10}\\) rad/s, producing sustained oscillation at this frequency. For \\(K &lt; 70\\), these poles are in the LHP (stable). For \\(K &gt; 70\\), they're in the RHP (unstable).</p> Condition Behavior \\(0 &lt; K &lt; 70\\) Stable (all poles in LHP) \\(K = 70\\) Marginally stable (poles on imaginary axis) \\(K &gt; 70\\) Unstable (poles in RHP) <p>Gyra Moment</p> <p>\"My engineers found my stability boundary the first week. When they turned my proportional gain up too high, I didn't just become sluggish or jerky\u2014I started oscillating at a very specific frequency, about 3 rad/s. That was my imaginary-axis frequency, the signature of the stability boundary. They learned: cross that boundary, and I don't just degrade gracefully. I break.\"</p>"},{"location":"chapters/10-stability-routh-hurwitz/#diagram-stability-boundary-explorer","title":"Diagram: Stability Boundary Explorer","text":"Stability Boundary Explorer <p>Type: microsim</p> <p>Bloom Taxonomy: Evaluate (L5) Bloom Verb: assess, judge</p> <p>Learning Objective: Students will evaluate system stability by adjusting gain and observing the transition across the stability boundary.</p> <p>Canvas layout: - Top left (40%): Routh array with key element highlighted - Top right (40%): S-plane with root locus hint - Bottom (20%): Gain slider and time response</p> <p>Visual elements: Routh Array: - Complete array with current K value - Critical element (determines stability) highlighted - Color coding: green (positive), red (negative), yellow (zero)</p> <p>S-Plane: - Closed-loop poles plotted - Poles move as K changes - Imaginary axis emphasized - Stable/unstable region shading</p> <p>Time Response: - Step response for current K - Grows unbounded when unstable - Sustained oscillation at boundary</p> <p>Interactive controls: - Slider: Gain K from 0 to 100 - Play/pause: Animate K sweep - Button: Jump to stability boundary - Toggle: Show root locus path</p> <p>Data Visibility Requirements: - Display current K value prominently - Show critical Routh array element value - Display pole locations numerically - Show stability status: STABLE / BOUNDARY / UNSTABLE - At boundary: show oscillation frequency from auxiliary polynomial</p> <p>Behavior: - As K increases, poles move on s-plane - At K = K_critical, poles cross imaginary axis - Response changes from settling to sustained oscillation to growing - Routh array element changes sign as K crosses boundary</p> <p>Instructional Rationale: Real-time connection between Routh array sign, pole location, and time response reinforces the practical meaning of stability analysis. Students see cause and effect immediately.</p> <p>Implementation: p5.js with linked visualizations and slider control</p>"},{"location":"chapters/10-stability-routh-hurwitz/#relative-stability","title":"Relative Stability","text":"<p>So far, stability has been binary: a system is stable or it isn't. But in practice, some stable systems are more stable than others. Relative stability quantifies how far the poles are from the stability boundary.</p> <p>Two measures of relative stability:</p> <p>Distance from Imaginary Axis: Poles farther left in the s-plane have faster-decaying modes. The dominant pole (rightmost LHP pole) determines the \"least stable\" behavior.</p> <p>Gain Margin and Phase Margin: How much can gain increase before instability? How much phase lag can be added? (We'll explore these in detail in the frequency response chapters.)</p> <p>For the Routh-Hurwitz context, we can test relative stability by shifting the stability boundary. To determine if all poles are to the left of \\(s = -\\sigma\\) (where \\(\\sigma &gt; 0\\)), substitute \\(s = s_1 - \\sigma\\) into the characteristic polynomial and apply the Routh criterion to the new polynomial.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#relative-stability-test","title":"Relative Stability Test","text":"<p>To verify all poles have real part less than \\(-\\sigma\\):</p> <ol> <li>Substitute \\(s = s_1 - \\sigma\\) into \\(D(s)\\)</li> <li>Simplify to get polynomial in \\(s_1\\)</li> <li>Apply Routh criterion to the new polynomial</li> <li>If stable, all original poles are to the left of \\(s = -\\sigma\\)</li> </ol> <p>This is useful when specifications require all poles to be within a certain region\u2014for example, \"all time constants less than 2 seconds\" requires all poles to the left of \\(s = -0.5\\).</p> Pole Constraint Substitution Meaning All poles in LHP None (standard Routh) Basic stability All poles left of \\(s = -1\\) \\(s = s_1 - 1\\) Fast decay (\u03c4 &lt; 1s) All poles left of \\(s = -0.5\\) \\(s = s_1 - 0.5\\) Time constants &lt; 2s <p>When to Use Relative Stability</p> <p>Relative stability tests are valuable when you have settling time requirements. If the spec says \"settle within 4 seconds,\" you need the dominant pole's real part more negative than about \\(-1\\) (since settling takes roughly \\(4\\tau = 4/|Re(p)|\\)). Use the shifted Routh test to verify this without finding the actual poles.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#design-using-routh-hurwitz","title":"Design Using Routh-Hurwitz","text":"<p>The Routh-Hurwitz criterion isn't just for analysis\u2014it's a powerful design tool. Given a system with adjustable parameters, we can determine the range of parameters that maintain stability.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#design-example-two-parameter-stability-region","title":"Design Example: Two-Parameter Stability Region","text":"<p>Consider a proportional-derivative (PD) controller applied to a plant:</p> <p>\\(G(s) = \\frac{K_p + K_d s}{s^3 + 4s^2 + 5s}\\)</p> <p>Closed-loop characteristic equation:</p> <p>\\(s^3 + 4s^2 + (5 + K_d)s + K_p = 0\\)</p> <p>For stability:</p> <ol> <li>All coefficients positive: \\(K_p &gt; 0\\) and \\(5 + K_d &gt; 0\\) \u2192 \\(K_d &gt; -5\\)</li> <li>Routh array first column all positive</li> </ol> <p>Routh array:</p> Row Column 1 Column 2 \\(s^3\\) 1 \\(5 + K_d\\) \\(s^2\\) 4 \\(K_p\\) \\(s^1\\) \\(\\frac{4(5+K_d) - K_p}{4}\\) 0 \\(s^0\\) \\(K_p\\) 0 <p>Stability conditions:</p> <ul> <li>\\(K_p &gt; 0\\)</li> <li>\\(K_d &gt; -5\\)</li> <li>\\(\\frac{4(5+K_d) - K_p}{4} &gt; 0\\) \u2192 \\(K_p &lt; 4(5 + K_d) = 20 + 4K_d\\)</li> </ul> <p>The stable region in the \\((K_d, K_p)\\) plane is bounded by:</p> <ul> <li>\\(K_p = 0\\) (lower boundary)</li> <li>\\(K_d = -5\\) (left boundary)</li> <li>\\(K_p = 20 + 4K_d\\) (upper boundary)</li> </ul>"},{"location":"chapters/10-stability-routh-hurwitz/#diagram-two-parameter-stability-region","title":"Diagram: Two-Parameter Stability Region","text":"Two-Parameter Stability Region <p>Type: microsim</p> <p>Bloom Taxonomy: Create (L6) Bloom Verb: design, construct</p> <p>Learning Objective: Students will design controller gains by identifying stable regions in multi-parameter space using Routh-Hurwitz analysis.</p> <p>Canvas layout: - Left (60%): Parameter space (K_d, K_p) with stability region shaded - Right (40%): Routh array and time response for selected point</p> <p>Visual elements: Parameter Space: - 2D plot with K_d on x-axis, K_p on y-axis - Stable region shaded green - Unstable region shaded red - Stability boundary lines labeled - Current operating point marked</p> <p>Routh Array Panel: - Shows array for current (K_d, K_p) - Elements color-coded by sign - Sign changes highlighted</p> <p>Time Response: - Step response for current parameters - Changes as parameters move</p> <p>Interactive controls: - Click to place operating point in parameter space - Drag operating point to explore - Slider: animate along a line in parameter space - Toggle: show/hide boundary equations - Button: Reset to example</p> <p>Data Visibility Requirements: - Display current K_d, K_p values - Show Routh array elements symbolically and numerically - Display stability status - On boundary: show imaginary axis poles</p> <p>Behavior: - Green region = all Routh elements positive - Red region = at least one sign change - Boundary lines where Routh elements = 0 - Crossing boundary changes response dramatically - Sound/visual alert when entering unstable region</p> <p>Instructional Rationale: Mapping algebraic conditions to visual regions in parameter space helps students understand how Routh-Hurwitz enables systematic design. Interactivity builds intuition for controller tuning.</p> <p>Implementation: p5.js with 2D parameter space and linked displays</p>"},{"location":"chapters/10-stability-routh-hurwitz/#summary-routh-hurwitz-at-a-glance","title":"Summary: Routh-Hurwitz at a Glance","text":"<p>The Routh-Hurwitz criterion is one of the most practical tools in control engineering. Here's a quick reference:</p> <p>Purpose: Determine if a polynomial has all roots in the LHP (stable) without finding the roots.</p> <p>Necessary Condition: All coefficients must be positive and present.</p> <p>Routh Array Construction:</p> <ol> <li>First two rows from coefficients (alternating)</li> <li>Subsequent rows by cross-multiplication formula</li> <li>Continue until \\(s^0\\) row</li> </ol> <p>Stability Test: Count sign changes in first column = number of RHP poles.</p> <p>Special Cases:</p> Case Indication Action Zero in first column Possible imaginary axis poles Replace with \u03b5, let \u03b5 \u2192 0\u207a Row of zeros Symmetric pole pairs Form auxiliary polynomial, differentiate, continue <p>Design Use: Find stability boundaries by setting first-column elements to zero, solve for parameter values.</p> <p>Relative Stability: Substitute \\(s = s_1 - \\sigma\\) to test if poles are left of \\(s = -\\sigma\\).</p> <p>Key Insight</p> <p>The Routh-Hurwitz criterion transforms the question \"Where are the poles?\" into the question \"What are the signs of these algebraic expressions?\" The latter is much easier to answer, especially when parameters are unknown.</p>"},{"location":"chapters/10-stability-routh-hurwitz/#connecting-to-whats-next","title":"Connecting to What's Next","text":"<p>You now have a complete algebraic toolkit for stability analysis. The Routh-Hurwitz criterion tells you whether a system is stable and how many poles are in the RHP, but it doesn't tell you where those poles are. For deeper insight into pole movement as parameters change, we'll develop the root locus technique in Chapter 11.</p> <p>The root locus graphically shows how closed-loop poles move as gain varies\u2014you'll see exactly how poles migrate from stable to unstable regions. The Routh criterion gives you the boundary; root locus gives you the whole picture.</p> <p>Later, frequency-domain methods (Bode plots, Nyquist criterion) will provide yet another perspective on stability\u2014one that connects directly to experimental measurements and robust design. The Routh-Hurwitz criterion remains the fastest pencil-and-paper check, while frequency methods offer design insight.</p> <p>Helping Gyra</p> <p>\"You've learned to answer my most important question: 'Will I fall?' With the Routh-Hurwitz criterion, you can check my stability without solving any polynomial equations. That's elegant. But now I want to know more\u2014not just whether I'm stable, but how stable, and how I could be more stable. The root locus will show you exactly where my poles are heading as you tune my gains. It's like getting a preview of my future.\"</p>"},{"location":"chapters/10-stability-routh-hurwitz/#key-takeaways","title":"Key Takeaways","text":"<p>This chapter has equipped you to analyze stability systematically:</p> <ul> <li> <p>Stability is the prerequisite for all other design requirements. An unstable system is worse than useless.</p> </li> <li> <p>BIBO stability requires all poles in the open LHP. Asymptotic stability means disturbances die out. Marginal stability means the system neither settles nor explodes.</p> </li> <li> <p>Internal stability requires attention to cancelled poles. Never cancel unstable poles with zeros.</p> </li> <li> <p>The characteristic polynomial is the closed-loop denominator; its roots are the closed-loop poles.</p> </li> <li> <p>The Routh-Hurwitz criterion determines stability from polynomial coefficients alone:</p> </li> <li>Build the Routh array from coefficients</li> <li>Count sign changes in first column = RHP poles</li> <li> <p>All positive first column = stable</p> </li> <li> <p>Special cases (zero in first column, row of zeros) indicate symmetric pole configurations and require modified procedures.</p> </li> <li> <p>The stability boundary is where first-column elements equal zero\u2014poles on the imaginary axis.</p> </li> <li> <p>Relative stability asks how far into the LHP the poles lie.</p> </li> <li> <p>Routh-Hurwitz enables design by finding stability boundaries in parameter space.</p> </li> </ul> Self-Check: Test Your Understanding <p>Before moving on, try these without peeking:</p> <ol> <li> <p>A polynomial has coefficients \\([1, 2, 3, 4, -5]\\). Without constructing the array, is the system definitely unstable? Why?</p> </li> <li> <p>For \\(D(s) = s^3 + 3s^2 + 2s + K\\), find the range of \\(K\\) for stability.</p> </li> <li> <p>What does a row of zeros in the Routh array indicate about the pole locations?</p> </li> <li> <p>True or false: If all coefficients of a polynomial are positive, the system must be stable.</p> </li> <li> <p>A system has characteristic equation \\(s^2 + 2s + K = 0\\). For what values of \\(K\\) is the system stable?</p> </li> </ol> <p>Answers: (1) Yes\u2014negative coefficient violates necessary condition. (2) \\(0 &lt; K &lt; 6\\). (3) Poles symmetric about origin (imaginary axis or symmetric RHP/LHP pairs). (4) False\u2014necessary but not sufficient for order \u2265 3. (5) \\(K &gt; 0\\).</p>"},{"location":"chapters/11-root-locus-analysis-design/","title":"Root Locus Analysis and Design","text":""},{"location":"chapters/11-root-locus-analysis-design/#summary","title":"Summary","text":"<p>This chapter develops the root locus method for analyzing how closed-loop poles move as a system parameter (typically gain) varies. Students will learn the rules for constructing root locus plots including starting/ending points, real-axis segments, asymptotes, breakaway points, and angles of departure/arrival. The magnitude and angle conditions provide the mathematical foundation. Root locus techniques are extended to controller design, enabling engineers to select gains that place poles at desired locations. Dominant pole design and compensation concepts prepare students for systematic controller synthesis.</p>"},{"location":"chapters/11-root-locus-analysis-design/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 22 concepts from the learning graph:</p> <ol> <li>Root Locus</li> <li>Root Locus Rules</li> <li>Starting Points</li> <li>Ending Points</li> <li>Number of Branches</li> <li>Symmetry Property</li> <li>Real Axis Segments</li> <li>Angle Condition</li> <li>Magnitude Condition</li> <li>Breakaway Point</li> <li>Break-In Point</li> <li>Asymptotes</li> <li>Centroid</li> <li>Asymptote Angles</li> <li>Departure Angle</li> <li>Arrival Angle</li> <li>Imaginary Axis Crossing</li> <li>Root Locus Gain</li> <li>Gain Adjustment</li> <li>Dominant Pole Design</li> <li>Pole Placement</li> <li>Root Locus Compensation</li> </ol>"},{"location":"chapters/11-root-locus-analysis-design/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 6: Poles, Zeros, and System Analysis</li> <li>Chapter 9: Block Diagrams and Signal Flow</li> <li>Chapter 10: Stability Analysis and Routh-Hurwitz</li> </ul>"},{"location":"chapters/11-root-locus-analysis-design/#from-stability-boundaries-to-pole-trajectories","title":"From Stability Boundaries to Pole Trajectories","text":"<p>In Chapter 10, you learned to answer the binary question: \"Is this system stable?\" The Routh-Hurwitz criterion tells you whether poles are in the left or right half-plane, and it identifies the stability boundary\u2014the critical gain where poles cross the imaginary axis. That's powerful, but it leaves you wanting more. Where exactly are those poles? How do they move as gain changes? If I want faster response, which way should I push the gain?</p> <p>The root locus answers all of these questions with a single elegant diagram. It's a graphical technique that shows the complete trajectory of closed-loop poles as a parameter (usually gain \\(K\\)) varies from zero to infinity. One glance at a root locus plot tells you:</p> <ul> <li>Where the poles start (when \\(K = 0\\))</li> <li>Where they end (as \\(K \\to \\infty\\))</li> <li>How they travel between these endpoints</li> <li>When they cross into the unstable region</li> <li>What gain values yield specific pole locations</li> </ul> <p>This isn't just analysis\u2014it's a design tool. Want your dominant poles at a specific location for a target damping ratio and natural frequency? The root locus shows you exactly what gain achieves that. Want to know if adding a compensator will help? Sketch the new root locus and see how the trajectories change.</p> <p>Walter R. Evans developed the root locus method in the 1940s while working on aircraft flight control systems at North American Aviation. Before computers made numerical root-finding trivial, Evans' graphical technique was revolutionary\u2014it gave engineers insight into parameter sensitivity that no amount of calculation could easily provide. Even today, with MATLAB and Python at our fingertips, the root locus remains the preferred tool for understanding how systems behave as parameters change. The visualization it provides is irreplaceable.</p> <p>Gyra Moment</p> <p>\"My engineers don't just test one gain value at a time\u2014they use root locus to see my entire stability future in a single plot. When they're tuning my controller, they literally watch my poles migrate across the s-plane. Move a slider, and my poles shift. Push the gain too high, and they watch my poles march toward the right half-plane. The root locus is a movie of my fate, parameterized by gain.\"</p>"},{"location":"chapters/11-root-locus-analysis-design/#the-root-locus-concept","title":"The Root Locus Concept","text":"<p>The root locus is the set of all possible locations of closed-loop poles as a system parameter varies. Consider the standard negative feedback configuration:</p>"},{"location":"chapters/11-root-locus-analysis-design/#standard-feedback-system","title":"Standard Feedback System","text":"<p>The closed-loop transfer function is:</p> <p>\\(T(s) = \\frac{KG(s)}{1 + KG(s)H(s)}\\)</p> <p>where:</p> <ul> <li>\\(K\\) is the adjustable gain</li> <li>\\(G(s)\\) is the forward path (plant) transfer function</li> <li>\\(H(s)\\) is the feedback path transfer function</li> </ul> <p>The closed-loop poles are the roots of the characteristic equation:</p>"},{"location":"chapters/11-root-locus-analysis-design/#characteristic-equation","title":"Characteristic Equation","text":"<p>\\(1 + KG(s)H(s) = 0\\)</p> <p>This can be rewritten as:</p> <p>\\(KG(s)H(s) = -1\\)</p> <p>As \\(K\\) varies from 0 to \u221e, the roots of this equation trace out curves in the s-plane. These curves constitute the root locus.</p> <p>Here's the key insight: when \\(K = 0\\), the characteristic equation becomes \\(1 = 0\\), which is never satisfied\u2014except at the poles of \\(G(s)H(s)\\), where the loop gain becomes infinite. As \\(K\\) increases, the roots migrate away from the open-loop poles. As \\(K \\to \\infty\\), the roots approach the zeros of \\(G(s)H(s)\\) or head off to infinity along asymptotes.</p> Parameter Value Root Locations \\(K = 0\\) At open-loop poles \\(K &gt; 0\\) (small) Near open-loop poles \\(K = K_{critical}\\) On stability boundary \\(K \\to \\infty\\) At open-loop zeros or infinity"},{"location":"chapters/11-root-locus-analysis-design/#the-angle-and-magnitude-conditions","title":"The Angle and Magnitude Conditions","text":"<p>The characteristic equation \\(1 + KG(s)H(s) = 0\\) can be written as:</p> <p>\\(G(s)H(s) = -\\frac{1}{K}\\)</p> <p>For a point \\(s\\) to lie on the root locus, two conditions must be satisfied simultaneously.</p>"},{"location":"chapters/11-root-locus-analysis-design/#angle-condition","title":"Angle Condition","text":"<p>\\(\\angle G(s)H(s) = (2k+1) \\times 180\u00b0\\)</p> <p>where:</p> <ul> <li>\\(\\angle G(s)H(s)\\) is the angle of the complex number \\(G(s)H(s)\\)</li> <li>\\(k\\) is any integer (0, 1, 2, ...)</li> </ul> <p>This is the angle condition\u2014the phase of the open-loop transfer function at any point on the root locus must be an odd multiple of 180\u00b0.</p>"},{"location":"chapters/11-root-locus-analysis-design/#magnitude-condition","title":"Magnitude Condition","text":"<p>\\(|G(s)H(s)| = \\frac{1}{K}\\)</p> <p>where:</p> <ul> <li>\\(|G(s)H(s)|\\) is the magnitude of \\(G(s)H(s)\\) at point \\(s\\)</li> <li>\\(K\\) is the gain that places a closed-loop pole at \\(s\\)</li> </ul> <p>The magnitude condition tells us the value of \\(K\\) required to place a pole at any specific point on the root locus.</p> <p>The angle condition determines which points are on the root locus. The magnitude condition determines what gain corresponds to each point. This separation is powerful: we can first sketch the locus using angle criteria alone, then find gains as needed using the magnitude condition.</p> <p>To compute angles, express \\(G(s)H(s)\\) in factored form:</p> <p>\\(G(s)H(s) = \\frac{K \\prod_{i=1}^{m}(s-z_i)}{\\prod_{j=1}^{n}(s-p_j)}\\)</p> <p>where:</p> <ul> <li>\\(z_i\\) are the open-loop zeros</li> <li>\\(p_j\\) are the open-loop poles</li> <li>\\(m\\) is the number of zeros</li> <li>\\(n\\) is the number of poles</li> </ul> <p>The angle at any point \\(s\\) is:</p>"},{"location":"chapters/11-root-locus-analysis-design/#angle-calculation","title":"Angle Calculation","text":"<p>\\(\\angle G(s)H(s) = \\sum_{i=1}^{m}\\angle(s-z_i) - \\sum_{j=1}^{n}\\angle(s-p_j)\\)</p> <p>Sum of angles from zeros minus sum of angles from poles. For a point to be on the root locus, this difference must equal \u00b1180\u00b0, \u00b1540\u00b0, etc.</p>"},{"location":"chapters/11-root-locus-analysis-design/#diagram-angle-condition-visualizer","title":"Diagram: Angle Condition Visualizer","text":"Angle Condition Visualizer <p>Type: microsim</p> <p>Bloom Taxonomy: Understand (L2) Bloom Verb: explain, interpret</p> <p>Learning Objective: Students will explain how angles from poles and zeros determine whether a point lies on the root locus.</p> <p>Canvas layout: - Main area (75%): S-plane with poles, zeros, and test point - Right panel (25%): Angle calculations and sum</p> <p>Visual elements: S-Plane: - Complex plane with \u03c3 (real) and j\u03c9 (imaginary) axes - Open-loop poles marked with \u00d7 in blue - Open-loop zeros marked with \u25cb in red - Draggable test point (green dot) - Vectors drawn from each pole and zero to test point - Angle arcs shown at each pole and zero - Different colors for pole angles vs zero angles</p> <p>Angle Panel: - List of individual angles from zeros: \u03c6\u2081, \u03c6\u2082, ... - List of individual angles from poles: \u03b8\u2081, \u03b8\u2082, ... - Sum of zero angles - Sum of pole angles - Net angle: \u03a3\u03c6 - \u03a3\u03b8 - Status indicator: \"ON ROOT LOCUS\" (green) or \"NOT ON ROOT LOCUS\" (red) - Target: \u00b1180\u00b0, \u00b1540\u00b0, etc.</p> <p>Interactive controls: - Drag test point anywhere on s-plane - Preset examples dropdown (simple second-order, complex poles, with zeros) - Toggle: Show/hide angle arcs - Toggle: Show/hide vectors - Button: Animate test point along root locus</p> <p>Data Visibility Requirements: - Stage 1: Show pole and zero locations - Stage 2: Draw vectors from poles/zeros to test point - Stage 3: Display individual angles with values - Stage 4: Calculate and display sum - Stage 5: Compare to 180\u00b0 criterion</p> <p>Behavior: - Angles update in real-time as test point is dragged - Root locus curve shown faintly in background - When test point is exactly on root locus, indicators turn green - Near-misses show how far off the angle is</p> <p>Instructional Rationale: Direct manipulation of the test point with immediate angle feedback helps students internalize why certain s-plane regions are on the locus and others are not. Seeing the angle sum change continuously builds geometric intuition.</p> <p>Implementation: p5.js with draggable elements and real-time angle calculation</p>"},{"location":"chapters/11-root-locus-analysis-design/#root-locus-construction-rules","title":"Root Locus Construction Rules","text":"<p>While modern software generates root locus plots instantly, understanding the construction rules provides crucial insight into system behavior. These rules allow you to sketch the qualitative shape of the root locus by hand and, more importantly, to predict how design changes will affect the locus.</p>"},{"location":"chapters/11-root-locus-analysis-design/#rule-1-number-of-branches","title":"Rule 1: Number of Branches","text":"<p>The root locus has \\(n\\) branches, where \\(n\\) is the number of open-loop poles (the order of the characteristic equation). Each branch starts at an open-loop pole and represents the trajectory of one closed-loop pole.</p>"},{"location":"chapters/11-root-locus-analysis-design/#number-of-branches","title":"Number of Branches","text":"<p>\\(\\text{Number of branches} = n = \\text{number of open-loop poles}\\)</p>"},{"location":"chapters/11-root-locus-analysis-design/#rule-2-starting-points-and-ending-points","title":"Rule 2: Starting Points and Ending Points","text":"<p>Starting points (\\(K = 0\\)): Each branch begins at an open-loop pole. When \\(K = 0\\), the closed-loop poles equal the open-loop poles.</p> <p>Ending points (\\(K \\to \\infty\\)): Branches end at open-loop zeros or at infinity. There are \\(m\\) zeros (counting any at infinity). The \\(m\\) branches approaching finite zeros terminate there; the remaining \\((n-m)\\) branches head to infinity along asymptotes.</p> Number of Symbol Where Branches... Open-loop poles \\(n\\) Start Open-loop zeros \\(m\\) End (finite) Zeros at infinity \\(n-m\\) End (along asymptotes)"},{"location":"chapters/11-root-locus-analysis-design/#rule-3-symmetry-property","title":"Rule 3: Symmetry Property","text":"<p>The root locus is symmetric about the real axis. Complex poles and zeros always come in conjugate pairs (for systems with real coefficients), so the locus must be symmetric. When sketching, you only need to determine the upper half\u2014the lower half is the mirror image.</p>"},{"location":"chapters/11-root-locus-analysis-design/#rule-4-real-axis-segments","title":"Rule 4: Real-Axis Segments","text":"<p>A point on the real axis lies on the root locus if and only if there is an odd number of real poles and zeros to its right.</p> <p>This rule emerges from the angle condition. For a real test point:</p> <ul> <li>Complex poles/zeros contribute angles that cancel (conjugate pairs)</li> <li>Real poles/zeros to the right contribute 180\u00b0 each</li> <li>Real poles/zeros to the left contribute 0\u00b0 each</li> </ul> <p>For the total angle to be \u00b1180\u00b0, we need an odd count from the right.</p>"},{"location":"chapters/11-root-locus-analysis-design/#real-axis-segment-example","title":"Real-Axis Segment Example","text":"<p>Consider a system with poles at \\(s = 0\\), \\(s = -2\\), \\(s = -4\\) and a zero at \\(s = -3\\).</p> <ul> <li>From \\(s = 0\\) to \\(s = -2\\): One pole to the right \u2192 ON locus</li> <li>From \\(s = -2\\) to \\(s = -3\\): Two poles to the right \u2192 OFF locus</li> <li>From \\(s = -3\\) to \\(s = -4\\): Two poles + one zero to the right (3 total) \u2192 ON locus</li> <li>To the left of \\(s = -4\\): All four singularities to the right (4 total) \u2192 OFF locus</li> </ul> <p>Quick Real-Axis Check</p> <p>Count poles and zeros on the real axis. Shade segments that have an odd count to their right. The root locus exists on these shaded segments.</p>"},{"location":"chapters/11-root-locus-analysis-design/#rule-5-asymptotes","title":"Rule 5: Asymptotes","text":"<p>As \\(K \\to \\infty\\), the \\((n-m)\\) branches that don't end at finite zeros go to infinity along straight-line asymptotes. These asymptotes radiate from a common point (the centroid) at specific angles.</p>"},{"location":"chapters/11-root-locus-analysis-design/#asymptote-angles","title":"Asymptote Angles","text":"<p>\\(\\phi_k = \\frac{(2k+1) \\times 180\u00b0}{n-m}\\)</p> <p>where:</p> <ul> <li>\\(\\phi_k\\) is the angle of the \\(k\\)th asymptote</li> <li>\\(k = 0, 1, 2, \\ldots, (n-m-1)\\)</li> <li>\\(n\\) is the number of poles</li> <li>\\(m\\) is the number of zeros</li> </ul>"},{"location":"chapters/11-root-locus-analysis-design/#centroid","title":"Centroid","text":"<p>\\(\\sigma_c = \\frac{\\sum \\text{poles} - \\sum \\text{zeros}}{n-m}\\)</p> <p>where:</p> <ul> <li>\\(\\sigma_c\\) is the real-axis intersection of all asymptotes</li> <li>The sums are over the real parts of poles and zeros</li> </ul> <p>The centroid is a single point on the real axis where all asymptotes meet. The asymptotes then extend at angles \\(\\phi_k\\) from this point.</p> \\(n-m\\) Asymptote Angles 1 180\u00b0 2 \u00b190\u00b0 3 60\u00b0, 180\u00b0, -60\u00b0 4 \u00b145\u00b0, \u00b1135\u00b0"},{"location":"chapters/11-root-locus-analysis-design/#diagram-asymptote-calculator","title":"Diagram: Asymptote Calculator","text":"Asymptote Calculator <p>Type: microsim</p> <p>Bloom Taxonomy: Apply (L3) Bloom Verb: calculate, use</p> <p>Learning Objective: Students will calculate asymptote angles and centroid location for systems with various pole-zero configurations.</p> <p>Canvas layout: - Left (60%): S-plane with poles, zeros, centroid, and asymptotes - Right (40%): Calculation panel with step-by-step formulas</p> <p>Visual elements: S-Plane: - Open-loop poles (\u00d7) and zeros (\u25cb) - Centroid marked with distinct symbol (\u2605) - Asymptotes as dashed lines radiating from centroid - Angle annotations on each asymptote - Real axis emphasized</p> <p>Calculation Panel: - n = [number of poles] - m = [number of zeros] - n - m = [excess poles] - Sum of poles: [value] - Sum of zeros: [value] - Centroid \u03c3c = (\u03a3poles - \u03a3zeros)/(n-m) = [value] - Asymptote angles: \u03c6\u2080 = [value], \u03c6\u2081 = [value], ...</p> <p>Interactive controls: - Input: Number of poles (1-5) - Input: Number of zeros (0 to n-1) - Draggable poles and zeros on s-plane - Preset examples dropdown - Button: Add pole/zero - Button: Reset</p> <p>Data Visibility Requirements: - Show all poles and zeros with numerical values - Display calculation for centroid step-by-step - Show each asymptote angle calculation - Display centroid location on s-plane</p> <p>Behavior: - As poles/zeros are moved, centroid and asymptotes update in real-time - Calculation panel shows formulas with substituted values - Asymptotes visually extend toward infinity at correct angles - Warning if m \u2265 n (improper system)</p> <p>Instructional Rationale: Seeing asymptotes update as poles and zeros move builds intuition for how pole-zero configuration affects high-gain behavior. The calculation panel reinforces the formulas while students explore.</p> <p>Implementation: p5.js with draggable elements and dynamic calculation display</p>"},{"location":"chapters/11-root-locus-analysis-design/#rule-6-breakaway-and-break-in-points","title":"Rule 6: Breakaway and Break-In Points","text":"<p>Breakaway points are locations where root locus branches leave the real axis and become complex. Break-in points are where complex branches return to the real axis.</p> <p>These occur on real-axis segments of the root locus, between poles (breakaway) or between zeros (break-in), at points where \\(K\\) reaches a local maximum or minimum.</p> <p>To find breakaway/break-in points:</p>"},{"location":"chapters/11-root-locus-analysis-design/#breakaway-point-condition","title":"Breakaway Point Condition","text":"<p>\\(\\frac{dK}{ds} = 0\\)</p> <p>Equivalently, from \\(1 + KG(s)H(s) = 0\\), solve:</p> <p>\\(\\frac{d}{ds}\\left[\\frac{-1}{G(s)H(s)}\\right] = 0\\)</p> <p>For simple cases with real poles and zeros:</p> <p>\\(\\sum_{j=1}^{n} \\frac{1}{s-p_j} = \\sum_{i=1}^{m} \\frac{1}{s-z_i}\\)</p> <p>Solve for \\(s\\) on real-axis segments of the locus.</p>"},{"location":"chapters/11-root-locus-analysis-design/#breakaway-point-example","title":"Breakaway Point Example","text":"<p>For \\(G(s) = \\frac{K}{s(s+4)}\\) (poles at 0 and -4, no finite zeros):</p> <p>The real-axis segment from 0 to -4 is on the locus. Setting:</p> <p>\\(\\frac{1}{s} + \\frac{1}{s+4} = 0\\)</p> <p>\\((s+4) + s = 0\\)</p> <p>\\(2s + 4 = 0\\)</p> <p>\\(s = -2\\)</p> <p>The breakaway point is at \\(s = -2\\). At this point, the two branches meet on the real axis and then depart at \u00b190\u00b0 into the complex plane.</p> <p>Helping Gyra</p> <p>\"Breakaway points are where my poles say goodbye to the real axis and head into complex territory. Below my breakaway gain, I have two distinct real poles\u2014overdamped, sluggish. Above it, I have complex conjugate poles\u2014oscillation appears! The breakaway point is my transition from 'boring but stable' to 'responsive but bouncy.'\"</p>"},{"location":"chapters/11-root-locus-analysis-design/#rule-7-departure-and-arrival-angles","title":"Rule 7: Departure and Arrival Angles","text":"<p>When the root locus leaves a complex pole or arrives at a complex zero, it does so at a specific angle. These angles are crucial for accurately sketching the locus near complex singularities.</p>"},{"location":"chapters/11-root-locus-analysis-design/#departure-angle","title":"Departure Angle","text":"<p>\\(\\theta_{dep} = 180\u00b0 - \\sum(\\text{angles from other poles}) + \\sum(\\text{angles from all zeros})\\)</p> <p>All angles measured from the complex pole in question to other poles and zeros.</p>"},{"location":"chapters/11-root-locus-analysis-design/#arrival-angle","title":"Arrival Angle","text":"<p>\\(\\phi_{arr} = 180\u00b0 - \\sum(\\text{angles from all poles}) + \\sum(\\text{angles from other zeros})\\)</p> <p>All angles measured from the complex zero in question.</p>"},{"location":"chapters/11-root-locus-analysis-design/#departure-angle-example","title":"Departure Angle Example","text":"<p>Consider \\(G(s)H(s) = \\frac{K}{(s+1)(s^2+2s+2)}\\)</p> <p>The quadratic factor has roots at \\(s = -1 \\pm j1\\) (complex conjugate poles).</p> <p>For the pole at \\(s = -1 + j\\):</p> <ul> <li>Angle from pole at \\(s = -1\\): \\(\\angle[(-1+j) - (-1)] = \\angle[j] = 90\u00b0\\)</li> <li>Angle from conjugate pole at \\(s = -1-j\\): \\(\\angle[(-1+j) - (-1-j)] = \\angle[2j] = 90\u00b0\\)</li> </ul> <p>Departure angle: \\(\\theta_{dep} = 180\u00b0 - 90\u00b0 - 90\u00b0 = 0\u00b0\\)</p> <p>The locus departs horizontally from this pole (toward the left, as it turns out).</p>"},{"location":"chapters/11-root-locus-analysis-design/#rule-8-imaginary-axis-crossing","title":"Rule 8: Imaginary Axis Crossing","text":"<p>The imaginary axis crossing determines the critical gain for stability\u2014the same boundary we found with Routh-Hurwitz in Chapter 10. There are two methods:</p> <p>Method 1: Routh-Hurwitz Set the first-column element that goes to zero equal to zero and solve for \\(K\\). The auxiliary polynomial gives the crossing frequency.</p> <p>Method 2: Direct Substitution Substitute \\(s = j\\omega\\) into the characteristic equation and set real and imaginary parts separately to zero. Solve for \\(\\omega\\) and \\(K\\).</p>"},{"location":"chapters/11-root-locus-analysis-design/#imaginary-axis-crossing-example","title":"Imaginary Axis Crossing Example","text":"<p>For \\(1 + \\frac{K}{s(s+2)(s+4)} = 0\\)</p> <p>Characteristic equation: \\(s^3 + 6s^2 + 8s + K = 0\\)</p> <p>Substitute \\(s = j\\omega\\):</p> <p>\\((j\\omega)^3 + 6(j\\omega)^2 + 8(j\\omega) + K = 0\\)</p> <p>\\(-j\\omega^3 - 6\\omega^2 + 8j\\omega + K = 0\\)</p> <p>Real part: \\(-6\\omega^2 + K = 0 \\Rightarrow K = 6\\omega^2\\)</p> <p>Imaginary part: \\(-\\omega^3 + 8\\omega = 0 \\Rightarrow \\omega(\\omega^2 - 8) = 0\\)</p> <p>So \\(\\omega = \\sqrt{8} = 2\\sqrt{2}\\) rad/s (ignoring \\(\\omega = 0\\))</p> <p>And \\(K = 6 \\times 8 = 48\\)</p> <p>The root locus crosses the imaginary axis at \\(s = \\pm j2\\sqrt{2}\\) when \\(K = 48\\).</p>"},{"location":"chapters/11-root-locus-analysis-design/#diagram-complete-root-locus-constructor","title":"Diagram: Complete Root Locus Constructor","text":"Complete Root Locus Constructor <p>Type: microsim</p> <p>Bloom Taxonomy: Analyze (L4) Bloom Verb: differentiate, organize</p> <p>Learning Objective: Students will analyze root locus plots by identifying key features (asymptotes, breakaway points, departure angles, crossings) and understanding their relationship to system behavior.</p> <p>Canvas layout: - Main area (70%): S-plane with complete root locus - Side panel (30%): Feature checklist and gain slider with response</p> <p>Visual elements: S-Plane: - Open-loop poles (\u00d7) and zeros (\u25cb) - Complete root locus curves - Asymptotes (dashed lines) - Centroid marked - Breakaway/break-in points highlighted - Departure/arrival angles shown with arcs - Imaginary axis crossings marked with diamonds - Current operating point based on gain slider</p> <p>Feature Panel: - Checklist of root locus features:   - [ ] Starting points (poles)   - [ ] Ending points (zeros/asymptotes)   - [ ] Real-axis segments   - [ ] Asymptotes (angles, centroid)   - [ ] Breakaway points   - [ ] Departure angles (if complex poles)   - [ ] Imaginary axis crossings - Current gain K = [value] - Current pole locations - Step response plot</p> <p>Interactive controls: - Gain slider K (0 to 2\u00d7 critical) - Dropdown: System presets (second-order, third-order, with zeros) - Toggle: Show/hide each feature type - Toggle: Animate gain sweep - Button: Show construction steps</p> <p>Data Visibility Requirements: - Show numerical values for all key points - Display gain at each significant point (breakaway, crossing) - Show pole locations as K changes - Display damping ratio and natural frequency for complex poles</p> <p>Behavior: - As gain slider moves, operating point moves along locus - Poles highlighted at current position - Step response updates with gain - Features highlighted when toggle enabled - Animation mode sweeps gain from 0 to max</p> <p>Instructional Rationale: Comprehensive visualization connects abstract rules to concrete geometry. The feature checklist guides systematic analysis while interactive exploration reveals cause-effect relationships.</p> <p>Implementation: p5.js with multiple visualization layers and linked displays</p>"},{"location":"chapters/11-root-locus-analysis-design/#reading-the-root-locus-a-complete-example","title":"Reading the Root Locus: A Complete Example","text":"<p>Let's work through a complete example to demonstrate all the construction rules working together.</p> <p>Consider the open-loop transfer function:</p>"},{"location":"chapters/11-root-locus-analysis-design/#complete-example","title":"Complete Example","text":"<p>\\(G(s)H(s) = \\frac{K(s+3)}{s(s+1)(s+2)}\\)</p> <p>where:</p> <ul> <li>Poles at \\(s = 0, -1, -2\\) (three poles, \\(n = 3\\))</li> <li>Zero at \\(s = -3\\) (one zero, \\(m = 1\\))</li> </ul> <p>Step 1: Number of Branches</p> <p>\\(n = 3\\) branches</p> <p>Step 2: Starting and Ending Points</p> <ul> <li>Start: \\(s = 0, -1, -2\\) (the three poles)</li> <li>End: One branch ends at \\(s = -3\\) (the zero); two branches go to infinity</li> </ul> <p>Step 3: Real-Axis Segments</p> <p>Count poles and zeros to the right of test points:</p> <ul> <li>Right of \\(s = 0\\): 0 singularities \u2192 OFF (even)</li> <li>Between \\(s = 0\\) and \\(s = -1\\): 1 pole \u2192 ON (odd)</li> <li>Between \\(s = -1\\) and \\(s = -2\\): 2 poles \u2192 OFF (even)</li> <li>Between \\(s = -2\\) and \\(s = -3\\): 3 poles \u2192 ON (odd)</li> <li>Left of \\(s = -3\\): 3 poles + 1 zero = 4 \u2192 OFF (even)</li> </ul> <p>Root locus on real axis: \\([-1, 0]\\) and \\([-3, -2]\\)</p> <p>Step 4: Asymptotes</p> <p>\\(n - m = 3 - 1 = 2\\) asymptotes</p> <p>Angles: \\(\\phi_0 = \\frac{180\u00b0}{2} = 90\u00b0\\), \\(\\phi_1 = \\frac{540\u00b0}{2} = 270\u00b0 = -90\u00b0\\)</p> <p>Centroid: \\(\\sigma_c = \\frac{(0 + (-1) + (-2)) - (-3)}{2} = \\frac{-3 + 3}{2} = 0\\)</p> <p>The asymptotes are vertical lines at \\(\\sigma = 0\\), going straight up and down.</p> <p>Step 5: Breakaway Point</p> <p>On the segment \\([-1, 0]\\):</p> <p>\\(\\frac{1}{s} + \\frac{1}{s+1} + \\frac{1}{s+2} = \\frac{1}{s+3}\\)</p> <p>Solving numerically: \\(s \\approx -0.42\\)</p> <p>Step 6: Departure Angles</p> <p>All poles are real, so no departure angle calculation needed.</p> <p>Step 7: Imaginary Axis Crossing</p> <p>Use the characteristic equation: \\(s(s+1)(s+2) + K(s+3) = 0\\)</p> <p>\\(s^3 + 3s^2 + 2s + Ks + 3K = 0\\)</p> <p>\\(s^3 + 3s^2 + (2+K)s + 3K = 0\\)</p> <p>Routh array:</p> Row Col 1 Col 2 \\(s^3\\) 1 \\(2+K\\) \\(s^2\\) 3 \\(3K\\) \\(s^1\\) \\(\\frac{3(2+K) - 3K}{3} = 2\\) 0 \\(s^0\\) \\(3K\\) 0 <p>The \\(s^1\\) row is always 2 (positive)\u2014the locus never crosses the imaginary axis for positive \\(K\\)! This system is stable for all \\(K &gt; 0\\). The zero at \\(s = -3\\) \"pulls\" the locus to the left, preventing instability.</p> Feature Value Number of branches 3 Starting points 0, -1, -2 Ending points -3, \u00b1j\u221e Real-axis segments [-1, 0], [-3, -2] Asymptote angles \u00b190\u00b0 Centroid 0 Breakaway point \u2248 -0.42 Imaginary crossing None (stable for all K &gt; 0) <p>Key Observation</p> <p>Adding a zero to the left of all poles can \"stabilize\" the root locus\u2014the zero pulls branches leftward, potentially keeping them in the LHP for all gains. This is the principle behind lead compensation.</p>"},{"location":"chapters/11-root-locus-analysis-design/#the-magnitude-condition-and-gain-calculation","title":"The Magnitude Condition and Gain Calculation","text":"<p>Once you know a point is on the root locus (via the angle condition), the magnitude condition tells you the value of \\(K\\) that places a closed-loop pole there.</p>"},{"location":"chapters/11-root-locus-analysis-design/#magnitude-condition-gain-formula","title":"Magnitude Condition (Gain Formula)","text":"<p>\\(K = \\frac{1}{|G(s)H(s)|} = \\frac{\\prod |s - p_j|}{\\prod |s - z_i|}\\)</p> <p>where:</p> <ul> <li>\\(|s - p_j|\\) is the distance from test point \\(s\\) to pole \\(p_j\\)</li> <li>\\(|s - z_i|\\) is the distance from test point \\(s\\) to zero \\(z_i\\)</li> </ul> <p>In words: Gain equals product of distances to poles divided by product of distances to zeros.</p> <p>This is remarkably convenient for graphical analysis. Measure distances on your root locus plot, multiply the pole distances, divide by zero distances, and you have the gain.</p>"},{"location":"chapters/11-root-locus-analysis-design/#gain-calculation-example","title":"Gain Calculation Example","text":"<p>For \\(G(s)H(s) = \\frac{K}{s(s+4)}\\), find \\(K\\) when poles are at \\(s = -2 \\pm j2\\).</p> <p>Test point: \\(s = -2 + j2\\)</p> <p>Distance to pole at \\(s = 0\\): \\(|-2 + j2| = \\sqrt{4 + 4} = \\sqrt{8} = 2\\sqrt{2}\\)</p> <p>Distance to pole at \\(s = -4\\): \\(|-2 + j2 - (-4)| = |2 + j2| = \\sqrt{4 + 4} = 2\\sqrt{2}\\)</p> <p>\\(K = 2\\sqrt{2} \\times 2\\sqrt{2} = 8\\)</p> <p>When \\(K = 8\\), the closed-loop poles are at \\(s = -2 \\pm j2\\), giving:</p> <ul> <li>Natural frequency: \\(\\omega_n = \\sqrt{(-2)^2 + 2^2} = \\sqrt{8} = 2\\sqrt{2}\\) rad/s</li> <li>Damping ratio: \\(\\zeta = \\frac{2}{2\\sqrt{2}} = \\frac{1}{\\sqrt{2}} \\approx 0.707\\)</li> </ul> <p>This is the well-known \"optimal\" damping ratio\u2014significant overshoot but fast settling.</p>"},{"location":"chapters/11-root-locus-analysis-design/#root-locus-gain-and-system-performance","title":"Root Locus Gain and System Performance","text":"<p>The parameter \\(K\\) in the root locus isn't just a mathematical variable\u2014it's a tuning knob with real consequences. Understanding how \\(K\\) affects performance is essential for design.</p> <p>As \\(K\\) increases along the root locus:</p> Performance Aspect Effect of Increasing \\(K\\) Speed of response Initially faster (poles move left) Stability Eventually degrades (poles may cross to RHP) Damping Often decreases (poles become more oscillatory) Steady-state error Decreases (higher gain reduces error) Overshoot Often increases (less damping) <p>There's typically a trade-off: more gain improves steady-state accuracy and initial speed but can lead to oscillation and even instability. The root locus visualizes this trade-off perfectly\u2014you can see poles becoming complex, approaching the imaginary axis, and crossing into the RHP.</p>"},{"location":"chapters/11-root-locus-analysis-design/#diagram-gain-response-explorer","title":"Diagram: Gain-Response Explorer","text":"Gain-Response Explorer <p>Type: microsim</p> <p>Bloom Taxonomy: Evaluate (L5) Bloom Verb: assess, judge, compare</p> <p>Learning Objective: Students will evaluate the effect of gain on system performance by observing how time-domain specifications change as poles move along the root locus.</p> <p>Canvas layout: - Left (45%): Root locus with current operating point - Right top (35%): Step response plot - Right bottom (20%): Performance metrics table</p> <p>Visual elements: Root Locus: - Complete root locus - Operating point marker (moves with gain slider) - Constant damping ratio lines (\u03b6 = 0.3, 0.5, 0.707, 1.0) - Constant natural frequency circles (\u03c9n = 1, 2, 3, ...) - Shaded regions: \"fast\", \"slow\", \"oscillatory\"</p> <p>Step Response: - Time response curve - Rise time markers - Overshoot indicator - Settling time marker - Steady-state value line</p> <p>Performance Metrics: - Rise time: [value] - Overshoot: [value]% - Settling time (2%): [value] - Steady-state error: [value]% - Damping ratio \u03b6: [value] - Natural frequency \u03c9n: [value]</p> <p>Interactive controls: - Gain slider K (logarithmic scale) - Input: Step magnitude - Dropdown: System presets - Toggle: Show \u03b6 lines - Toggle: Show \u03c9n circles - Button: Compare two gains side-by-side</p> <p>Data Visibility Requirements: - Show current K value prominently - Display pole locations numerically - Show all performance metrics - Highlight when crossing stability boundary</p> <p>Behavior: - As K changes, operating point moves along locus - Step response updates in real-time - Metrics recalculate and display - Warning when approaching instability - Visual feedback when poles become complex</p> <p>Instructional Rationale: Linking root locus position to time-domain performance builds the intuition needed for controller tuning. Students see the consequence of every gain choice immediately.</p> <p>Implementation: p5.js with gain slider and synchronized displays</p>"},{"location":"chapters/11-root-locus-analysis-design/#gain-adjustment-for-desired-performance","title":"Gain Adjustment for Desired Performance","text":"<p>The root locus enables direct design: choose a desired pole location based on performance specifications, then read off the required gain.</p>"},{"location":"chapters/11-root-locus-analysis-design/#design-procedure","title":"Design Procedure","text":"<ol> <li>Translate specifications into desired pole locations</li> <li>\\(\\zeta\\) specifies a line: \\(\\cos(\\theta) = \\zeta\\) where \\(\\theta\\) is angle from negative real axis</li> <li>\\(\\omega_n\\) specifies a circle of radius \\(\\omega_n\\)</li> <li>Settling time \u2192 minimum distance from imaginary axis</li> <li> <p>Maximum overshoot \u2192 minimum damping ratio</p> </li> <li> <p>Find where the root locus intersects the desired region</p> </li> <li> <p>Use the magnitude condition to calculate the required gain</p> </li> <li> <p>Verify that all other poles (non-dominant) are acceptable</p> </li> </ol>"},{"location":"chapters/11-root-locus-analysis-design/#design-example-meeting-a-damping-requirement","title":"Design Example: Meeting a Damping Requirement","text":"<p>Given: \\(G(s) = \\frac{K}{s(s+6)}\\)</p> <p>Requirement: Closed-loop damping ratio \\(\\zeta = 0.5\\)</p> <p>The angle for \\(\\zeta = 0.5\\) is \\(\\theta = \\cos^{-1}(0.5) = 60\u00b0\\) from the negative real axis.</p> <p>The root locus for this system:</p> <ul> <li>Starts at \\(s = 0, -6\\)</li> <li>Asymptotes at \u00b190\u00b0 from centroid at \\(\\sigma_c = -3\\)</li> <li>Breakaway at \\(s = -3\\)</li> </ul> <p>The locus departs vertically from \\(s = -3\\). The \\(\\zeta = 0.5\\) lines intersect the locus at \\(s = -3 \\pm j3\\sqrt{3}\\).</p> <p>Gain at this point:</p> <p>\\(K = |s| \\cdot |s + 6| = |-3 + j3\\sqrt{3}| \\cdot |3 + j3\\sqrt{3}|\\)</p> <p>\\(K = 6 \\times 6 = 36\\)</p> <p>With \\(K = 36\\), the closed-loop poles are at \\(s = -3 \\pm j5.2\\), giving \\(\\zeta = 0.5\\) exactly.</p>"},{"location":"chapters/11-root-locus-analysis-design/#dominant-pole-design","title":"Dominant Pole Design","text":"<p>Real systems often have more than two poles. A third-order system has three poles; higher-order systems have even more. Analyzing all poles is complex, but the dominant pole concept simplifies matters.</p> <p>Dominant poles are the closed-loop poles closest to the imaginary axis. They have the slowest decay rates and thus contribute most to the response for the longest time. If the dominant poles are well-separated from the other poles (at least 5\u00d7 farther from the imaginary axis), the system behaves approximately like a second-order system defined by the dominant poles alone.</p>"},{"location":"chapters/11-root-locus-analysis-design/#dominant-pole-criterion","title":"Dominant Pole Criterion","text":"<p>\\(|\\text{Re}(p_{non-dominant})| &gt; 5 |\\text{Re}(p_{dominant})|\\)</p> <p>When this condition holds, the contribution from non-dominant poles decays so quickly that it becomes negligible within the rise time of the dominant response.</p>"},{"location":"chapters/11-root-locus-analysis-design/#dominant-pole-design-example","title":"Dominant Pole Design Example","text":"<p>Consider \\(G(s) = \\frac{K}{s(s+1)(s+10)}\\)</p> <p>For small \\(K\\), poles are near 0, -1, -10. As \\(K\\) increases, the poles at 0 and -1 become complex and dominate the response\u2014they're much closer to the imaginary axis than the pole near -10.</p> <p>If we design for the dominant pair to have \\(\\zeta = 0.707\\) and \\(\\omega_n = 1\\), the dominant poles would be at \\(s = -0.707 \\pm j0.707\\). The third pole should remain near \\(s = -10\\). Since \\(10 &gt; 5 \\times 0.707\\), the dominance condition is satisfied.</p> <p>Validity of Dominant Pole Assumption</p> <p>The dominant pole approximation fails when:</p> <ul> <li>Non-dominant poles aren't far enough away</li> <li>Zeros are near the dominant poles (zeros can boost non-dominant modes)</li> <li>The initial transient matters (non-dominant modes contribute early)</li> </ul> <p>Always verify with simulation when the separation isn't large.</p>"},{"location":"chapters/11-root-locus-analysis-design/#pole-placement-design","title":"Pole Placement Design","text":"<p>Pole placement is the art of choosing pole locations to meet performance specifications, then using the root locus (or other techniques) to determine how to achieve those locations.</p> <p>The relationship between s-plane location and time-domain specifications:</p> Specification S-Plane Requirement Settling time \\(t_s\\) \\(\\text{Re}(s) &lt; -\\frac{4}{t_s}\\) (2% criterion) Peak overshoot \\(M_p\\)% Damping ratio \\(\\zeta\\) on specific line Rise time \\(t_r\\) Natural frequency \\(\\omega_n &gt; \\frac{1.8}{t_r}\\) Steady-state error Loop gain (not directly a pole location) <p>The root locus shows you where poles can go as \\(K\\) varies. If the locus passes through your desired region, you're in luck\u2014just set the appropriate gain. If it doesn't, you'll need compensation (additional poles and zeros) to reshape the locus.</p>"},{"location":"chapters/11-root-locus-analysis-design/#diagram-pole-placement-designer","title":"Diagram: Pole Placement Designer","text":"Pole Placement Designer <p>Type: microsim</p> <p>Bloom Taxonomy: Create (L6) Bloom Verb: design, construct</p> <p>Learning Objective: Students will design closed-loop pole locations to meet given time-domain specifications, using the root locus to determine required gain.</p> <p>Canvas layout: - Left (50%): S-plane with specification regions and root locus - Right (50%): Specifications input, step response, and results</p> <p>Visual elements: S-Plane: - Specification regions shaded:   - Settling time boundary (vertical line)   - Damping ratio boundary (radial lines)   - Natural frequency boundary (arc) - Feasible region where all specs met (intersection) - Root locus overlay - Draggable target point - Current pole locations marked</p> <p>Specifications Panel: - Input: Maximum settling time (seconds) - Input: Maximum overshoot (%) - Input: Maximum rise time (seconds) - Calculated boundaries displayed - Feasibility indicator: \"Achievable\" or \"Not achievable\"</p> <p>Results Panel: - Required gain K = [value] - Resulting pole locations - Actual performance metrics vs. specifications - Step response plot with spec markers</p> <p>Interactive controls: - Drag target point on s-plane - Specification input fields - Dropdown: System presets - Button: Auto-place poles (find optimal) - Toggle: Show/hide specification boundaries</p> <p>Data Visibility Requirements: - Show specification boundaries with labels - Display required gain when target is on locus - Show calculated vs. specified metrics - Indicate if selected point is on locus</p> <p>Behavior: - As target is dragged, show required K if on locus - Show \"Not on locus\" if target is off the locus - Feasible region updates as specs change - Auto-place finds intersection of specs and locus - Warning if locus never enters feasible region</p> <p>Instructional Rationale: Interactive design experience helps students internalize the connection between specifications, s-plane regions, and root locus. The immediate feedback loop accelerates learning of design trade-offs.</p> <p>Implementation: p5.js with specification inputs, region shading, and locus overlay</p>"},{"location":"chapters/11-root-locus-analysis-design/#root-locus-compensation","title":"Root Locus Compensation","text":"<p>When the root locus doesn't pass through the desired pole locations, we need compensation\u2014adding poles and/or zeros to reshape the locus.</p>"},{"location":"chapters/11-root-locus-analysis-design/#lead-compensation","title":"Lead Compensation","text":"<p>A lead compensator adds a zero to the left of a pole:</p>"},{"location":"chapters/11-root-locus-analysis-design/#lead-compensator","title":"Lead Compensator","text":"<p>\\(G_c(s) = K_c \\frac{s + z}{s + p}\\)</p> <p>where:</p> <ul> <li>\\(z &lt; p\\) (zero closer to origin than pole)</li> <li>Both \\(z\\) and \\(p\\) are positive real numbers</li> </ul> <p>The zero \"pulls\" the root locus to the left, improving stability margins and potentially allowing higher gains. The pole is placed far to the left so it doesn't interfere much.</p> <p>Effects of lead compensation:</p> <ul> <li>Improves transient response (faster settling)</li> <li>Increases phase margin</li> <li>May increase bandwidth</li> <li>Generally increases high-frequency noise sensitivity</li> </ul>"},{"location":"chapters/11-root-locus-analysis-design/#lag-compensation","title":"Lag Compensation","text":"<p>A lag compensator adds a pole to the left of a zero (both near the origin):</p>"},{"location":"chapters/11-root-locus-analysis-design/#lag-compensator","title":"Lag Compensator","text":"<p>\\(G_c(s) = K_c \\frac{s + z}{s + p}\\)</p> <p>where:</p> <ul> <li>\\(p &lt; z\\) (pole closer to origin than zero)</li> <li>Both small (near the origin)</li> </ul> <p>The lag compensator doesn't significantly change the root locus shape but increases DC gain, reducing steady-state error.</p> <p>Effects of lag compensation:</p> <ul> <li>Reduces steady-state error</li> <li>Minimal effect on transient response (if properly designed)</li> <li>Decreases bandwidth</li> <li>Adds phase lag at low frequencies</li> </ul>"},{"location":"chapters/11-root-locus-analysis-design/#lead-lag-compensation","title":"Lead-Lag Compensation","text":"<p>For demanding specifications, combine lead and lag:</p>"},{"location":"chapters/11-root-locus-analysis-design/#lead-lag-compensator","title":"Lead-Lag Compensator","text":"<p>\\(G_c(s) = K_c \\frac{(s + z_1)(s + z_2)}{(s + p_1)(s + p_2)}\\)</p> <p>where:</p> <ul> <li>One zero-pole pair provides lead (transient improvement)</li> <li>One zero-pole pair provides lag (steady-state improvement)</li> </ul> Compensator Type Effect on Root Locus Primary Benefit Lead Pulls locus left Faster transient, more stability Lag Minimal shape change Lower steady-state error Lead-Lag Combined effects Both transient and steady-state <p>Gyra Moment</p> <p>\"When my basic controller can't give my engineers the performance they want, they add compensators. A lead compensator is like adding anticipation to my control\u2014I sense change coming and act earlier. A lag compensator is like adding patience\u2014I accumulate small corrections over time. The best controllers give me both: quick reactions and long-term precision.\"</p>"},{"location":"chapters/11-root-locus-analysis-design/#diagram-compensation-effects-explorer","title":"Diagram: Compensation Effects Explorer","text":"Compensation Effects Explorer <p>Type: microsim</p> <p>Bloom Taxonomy: Evaluate (L5) Bloom Verb: compare, critique, assess</p> <p>Learning Objective: Students will evaluate the effects of lead and lag compensation on root locus shape and system performance.</p> <p>Canvas layout: - Top left (40%): Original root locus - Top right (40%): Compensated root locus - Bottom (20%): Comparison response and metrics</p> <p>Visual elements: Original Root Locus: - System poles and zeros - Uncompensated root locus - Current operating point</p> <p>Compensated Root Locus: - Original system poles/zeros (faded) - Compensator pole/zero (highlighted) - New root locus - New operating point (same K or same specs)</p> <p>Comparison Panel: - Step responses overlaid (original vs compensated) - Metrics table: settling time, overshoot, steady-state error - Phase margin comparison - Gain margin comparison</p> <p>Interactive controls: - Dropdown: Compensator type (Lead, Lag, Lead-Lag, None) - Sliders: Zero location, Pole location - Radio: Match gain or match specs - Dropdown: System presets - Toggle: Show both step responses</p> <p>Data Visibility Requirements: - Show compensator transfer function - Display pole/zero locations - Show before/after metrics - Highlight improvement or degradation</p> <p>Behavior: - As compensator parameters change, right plot updates - Responses update in real-time - Color coding: green for improvement, red for degradation - Constraint: zero left of pole for lead, pole left of zero for lag</p> <p>Instructional Rationale: Side-by-side comparison with interactive parameters helps students develop intuition for compensator design. Seeing both root locus shape change and performance impact builds design judgment.</p> <p>Implementation: p5.js with dual plots and synchronized compensator controls</p>"},{"location":"chapters/11-root-locus-analysis-design/#connecting-root-locus-to-previous-concepts","title":"Connecting Root Locus to Previous Concepts","text":"<p>The root locus method ties together many concepts from earlier chapters:</p> <p>From Chapter 6 (Poles and Zeros): The root locus shows how open-loop poles and zeros determine closed-loop pole trajectories. Zeros attract branches; poles repel them (at \\(K = 0\\)).</p> <p>From Chapter 9 (Block Diagrams): The characteristic equation \\(1 + GH = 0\\) comes from the closed-loop transfer function of negative feedback systems.</p> <p>From Chapter 10 (Routh-Hurwitz): The stability boundary from Routh-Hurwitz corresponds to imaginary axis crossings on the root locus. Both methods find the critical gain, but root locus shows the complete trajectory.</p> <p>Looking Ahead to Frequency Methods: The root locus is a time-domain/s-plane technique. Bode plots and Nyquist diagrams (upcoming chapters) analyze the same systems from a frequency-domain perspective. The connections are deep:</p> <ul> <li>Gain margin from Bode corresponds to distance from imaginary axis crossing</li> <li>Phase margin relates to damping ratio of dominant poles</li> <li>Both frequency and root locus methods inform compensator design</li> </ul> Concept Root Locus Connection Pole locations Branch starting points Zero locations Branch ending points Characteristic equation Defines the locus Stability boundary Imaginary axis crossing Dominant poles Poles closest to j\u03c9-axis"},{"location":"chapters/11-root-locus-analysis-design/#summary-the-root-locus-toolkit","title":"Summary: The Root Locus Toolkit","text":"<p>The root locus method provides a complete graphical analysis of closed-loop pole movement. Here's your quick reference:</p> <p>Purpose: Visualize how closed-loop poles move as gain varies; design gain for desired pole locations.</p> <p>Foundation: The characteristic equation \\(1 + KG(s)H(s) = 0\\)</p> <ul> <li>Angle condition: \\(\\angle GH = \\pm 180\u00b0\\) determines locus points</li> <li>Magnitude condition: \\(K = 1/|GH|\\) gives gain at each point</li> </ul> <p>Construction Rules Summary:</p> Rule What It Determines Branches = \\(n\\) Number of trajectories Start at poles Initial points (\\(K = 0\\)) End at zeros/\u221e Final points (\\(K \u2192 \u221e\\)) Real axis test Which real segments are on locus Asymptotes Behavior as branches go to infinity Breakaway Where branches leave real axis Departure angles Direction leaving complex poles Axis crossing Stability boundary <p>Design Applications:</p> <ul> <li>Gain adjustment for performance specifications</li> <li>Dominant pole design for simplified analysis</li> <li>Pole placement for meeting time-domain specs</li> <li>Compensation design when basic gain isn't enough</li> </ul> <p>Key Insight: The root locus transforms gain selection from guesswork into geometry. Instead of trial-and-error simulation, you can see all possible pole locations at once and choose the gain that achieves your objectives.</p> <p>The Power of Visualization</p> <p>Before computers, the root locus was a practical calculation tool. Today, its value is primarily conceptual\u2014it provides insight that pure numerical methods cannot. When you understand root locus, you understand how closed-loop systems behave as parameters change, and that understanding is priceless for design.</p>"},{"location":"chapters/11-root-locus-analysis-design/#connecting-to-whats-next","title":"Connecting to What's Next","text":"<p>You now have a powerful tool for analyzing and designing control systems in the s-domain. The root locus shows you exactly how poles move as gain changes, enabling precise gain selection and revealing when compensation is needed.</p> <p>In the next chapter, we'll shift perspective from the s-plane to the frequency domain. Bode plots represent system behavior as a function of sinusoidal frequency, providing a different but complementary view. You'll learn to read gain and phase margins directly from frequency response plots\u2014the same stability margins that root locus shows as imaginary axis crossings.</p> <p>The combination of root locus (s-domain) and Bode analysis (frequency domain) gives you two powerful lenses for understanding the same system. Master both, and you'll have the complete classical control design toolkit.</p> <p>Helping Gyra</p> <p>\"You've learned to see my future in the s-plane\u2014every possible pole location as gain varies, all in one picture. The root locus is like a choose-your-own-adventure map of my stability. Now you're ready for the frequency domain, where you'll listen to how I respond to different frequencies. Between root locus and Bode, you'll know everything about me: where my poles go, how I respond to oscillations, and how much margin I have before instability. That's a complete understanding.\"</p>"},{"location":"chapters/11-root-locus-analysis-design/#key-takeaways","title":"Key Takeaways","text":"<p>This chapter has equipped you with the root locus method for control system analysis and design:</p> <ul> <li> <p>The root locus is the set of all possible closed-loop pole locations as gain \\(K\\) varies from 0 to \u221e.</p> </li> <li> <p>The angle condition (\\(\\angle GH = \u00b1180\u00b0\\)) determines which points are on the locus. The magnitude condition (\\(K = 1/|GH|\\)) gives the gain at each point.</p> </li> <li> <p>Construction rules enable systematic sketching:</p> </li> <li>\\(n\\) branches start at open-loop poles, end at zeros or infinity</li> <li>Real-axis segments with odd number of singularities to the right</li> <li>Asymptotes at specific angles from the centroid</li> <li>Breakaway points where branches leave the real axis</li> <li> <p>Departure angles from complex poles</p> </li> <li> <p>The imaginary axis crossing gives the stability boundary\u2014the same result as Routh-Hurwitz, but with more context.</p> </li> <li> <p>Dominant pole design approximates higher-order systems by second-order behavior when non-dominant poles are far left.</p> </li> <li> <p>Pole placement translates time-domain specifications into s-plane regions.</p> </li> <li> <p>Compensation (lead, lag, lead-lag) reshapes the root locus to enable otherwise unachievable specifications.</p> </li> </ul> Self-Check: Test Your Understanding <p>Before moving on, try these without peeking:</p> <ol> <li> <p>A system has 4 poles and 1 zero. How many root locus branches are there? How many go to infinity?</p> </li> <li> <p>For \\(G(s)H(s) = \\frac{K}{s(s+4)(s+6)}\\), what are the asymptote angles and centroid?</p> </li> <li> <p>Why does the root locus exist on a real-axis segment only if there's an odd number of singularities to its right?</p> </li> <li> <p>If the root locus never crosses the imaginary axis (stays in LHP for all positive K), what does this mean for stability?</p> </li> <li> <p>What is the primary difference between lead and lag compensation in terms of root locus effect?</p> </li> </ol> <p>Answers: (1) 4 branches; 3 go to infinity. (2) Asymptotes at \u00b160\u00b0, 180\u00b0; centroid at \\(\\sigma_c = (0-4-6)/3 = -10/3 \u2248 -3.33\\). (3) Complex singularities contribute conjugate angles that cancel; real singularities to the right each contribute 180\u00b0, so odd count gives net \u00b1180\u00b0. (4) System is stable for all K &gt; 0. (5) Lead adds a zero that pulls the locus left (improves transient); lag adds a pole-zero pair near the origin that doesn't change the shape much but increases DC gain (reduces steady-state error).</p>"},{"location":"chapters/12-frequency-response-bode-plots/","title":"Frequency Response and Bode Plots","text":""},{"location":"chapters/12-frequency-response-bode-plots/#summary","title":"Summary","text":"<p>This chapter introduces frequency-domain analysis as a powerful complement to time-domain methods. Students will learn to characterize system behavior using sinusoidal steady-state response, magnitude and phase relationships, and the substitution s=j\u03c9. Bode plots are developed as graphical tools showing magnitude (in decibels) and phase versus frequency on logarithmic scales. Systematic construction techniques for first-order, second-order, integrator, and differentiator terms are presented. The chapter also covers bandwidth, cutoff frequency, resonance phenomena, and filter characteristics (low-pass, high-pass, bandpass, notch).</p>"},{"location":"chapters/12-frequency-response-bode-plots/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 35 concepts from the learning graph:</p> <ol> <li>Frequency Response</li> <li>Sinusoidal Steady State</li> <li>Magnitude Response</li> <li>Phase Response</li> <li>Frequency Transfer Func</li> <li>Substitution s=jw</li> <li>Bode Plot</li> <li>Bode Magnitude Plot</li> <li>Bode Phase Plot</li> <li>Decibel</li> <li>Logarithmic Scale</li> <li>Decade</li> <li>Octave</li> <li>Corner Frequency</li> <li>Break Frequency</li> <li>Asymptotic Approximation</li> <li>Bode Plot Construction</li> <li>First-Order Factor</li> <li>Second-Order Factor</li> <li>First-Order Bode Plot</li> <li>Second-Order Bode Plot</li> <li>Integrator Bode Plot</li> <li>Differentiator Bode Plot</li> <li>Constant Gain Term</li> <li>Time Delay in Bode</li> <li>Resonant Peak</li> <li>Resonant Frequency</li> <li>Quality Factor</li> <li>Bandwidth</li> <li>Cutoff Frequency</li> <li>Half-Power Point</li> <li>Low-Pass System</li> <li>High-Pass System</li> <li>Bandpass System</li> <li>Notch Filter</li> </ol>"},{"location":"chapters/12-frequency-response-bode-plots/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 3: Time-Domain Response Fundamentals</li> <li>Chapter 4: Transient Response Specifications</li> <li>Chapter 5: Laplace Transform Methods</li> <li>Chapter 6: Poles, Zeros, and System Analysis</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/13-nyquist-stability-margins/","title":"Nyquist Analysis and Stability Margins","text":""},{"location":"chapters/13-nyquist-stability-margins/#summary","title":"Summary","text":"<p>This chapter extends frequency-domain analysis to stability determination. Students will learn to construct Nyquist diagrams (polar plots of loop transfer functions) and apply the Nyquist stability criterion based on encirclements of the critical point. Gain margin and phase margin are developed as quantitative measures of how far a system is from instability, providing crucial robustness information. The chapter also covers minimum-phase and non-minimum-phase systems, right-half-plane poles and zeros, and conditionally stable systems. These concepts connect frequency response directly to closed-loop stability.</p>"},{"location":"chapters/13-nyquist-stability-margins/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 20 concepts from the learning graph:</p> <ol> <li>Gain Margin</li> <li>Phase Margin</li> <li>Stability Margins</li> <li>Crossover Frequency</li> <li>Gain Crossover</li> <li>Phase Crossover</li> <li>Minimum Phase System</li> <li>Non-Minimum Phase</li> <li>All-Pass System</li> <li>Nyquist Plot</li> <li>Nyquist Diagram</li> <li>Nyquist Criterion</li> <li>Nyquist Contour</li> <li>Encirclement</li> <li>Clockwise Encirclement</li> <li>Right-Half Plane Poles</li> <li>Right-Half Plane Zeros</li> <li>Conditionally Stable</li> <li>Gain Margin from Nyquist</li> <li>Phase Margin from Nyquist</li> </ol>"},{"location":"chapters/13-nyquist-stability-margins/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 6: Poles, Zeros, and System Analysis</li> <li>Chapter 10: Stability Analysis and Routh-Hurwitz</li> <li>Chapter 11: Root Locus Analysis and Design</li> <li>Chapter 12: Frequency Response and Bode Plots</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/14-steady-state-error-analysis/","title":"Steady-State Error Analysis","text":""},{"location":"chapters/14-steady-state-error-analysis/#summary","title":"Summary","text":"<p>This chapter focuses on the accuracy of control systems in tracking reference inputs after transients have settled. Students will learn to calculate steady-state errors for step, ramp, and parabolic inputs using error constants (position, velocity, and acceleration). The system type classification based on the number of integrators in the open-loop transfer function provides a systematic way to predict steady-state accuracy. The chapter also addresses how disturbances affect steady-state performance and how controller design can reduce or eliminate steady-state errors.</p>"},{"location":"chapters/14-steady-state-error-analysis/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 13 concepts from the learning graph:</p> <ol> <li>Steady-State Error</li> <li>Steady-State Accuracy</li> <li>Error Constants</li> <li>Position Error Constant</li> <li>Velocity Error Constant</li> <li>Acceleration Error Const</li> <li>System Type</li> <li>Type 0 System</li> <li>Type 1 System</li> <li>Type 2 System</li> <li>Type Number</li> <li>Error Coefficients</li> <li>Disturbance Error</li> </ol>"},{"location":"chapters/14-steady-state-error-analysis/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Introduction to Control Systems</li> <li>Chapter 3: Time-Domain Response Fundamentals</li> <li>Chapter 6: Poles, Zeros, and System Analysis</li> <li>Chapter 9: Block Diagrams and Signal Flow</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/15-pid-control-tuning/","title":"PID Control and Controller Tuning","text":""},{"location":"chapters/15-pid-control-tuning/#summary","title":"Summary","text":"<p>This chapter introduces the most widely used controller structure in industrial applications: the PID controller. Students will learn how proportional, integral, and derivative control actions individually affect system behavior, and how they combine in P, PI, PD, and PID controllers. Controller gains and their equivalent time-domain parameters (integral time, derivative time) are explained. Systematic tuning methods including Ziegler-Nichols (reaction curve and ultimate gain methods) provide starting points for controller design. Practical considerations including anti-windup and derivative kick are addressed.</p>"},{"location":"chapters/15-pid-control-tuning/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 21 concepts from the learning graph:</p> <ol> <li>Proportional Control</li> <li>Integral Control</li> <li>Derivative Control</li> <li>P Controller</li> <li>PI Controller</li> <li>PD Controller</li> <li>PID Controller</li> <li>Proportional Gain</li> <li>Integral Gain</li> <li>Derivative Gain</li> <li>Integral Time</li> <li>Derivative Time</li> <li>Controller Tuning</li> <li>Ziegler-Nichols Method</li> <li>Reaction Curve Method</li> <li>Ultimate Gain Method</li> <li>Ultimate Gain</li> <li>Ultimate Period</li> <li>Trial and Error Tuning</li> <li>Anti-Windup</li> <li>Derivative Kick</li> </ol>"},{"location":"chapters/15-pid-control-tuning/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 1: Introduction to Control Systems</li> <li>Chapter 3: Time-Domain Response Fundamentals</li> <li>Chapter 8: Linearization and Nonlinear Effects</li> <li>Chapter 10: Stability Analysis and Routh-Hurwitz</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"chapters/16-compensator-design-performance/","title":"Compensator Design and Performance Tradeoffs","text":""},{"location":"chapters/16-compensator-design-performance/#summary","title":"Summary","text":"<p>This chapter develops systematic methods for designing lead and lag compensators to meet performance specifications. Students will learn how phase lead improves transient response and stability margins while phase lag improves steady-state accuracy. Design procedures using both Bode plots and root locus are presented, enabling engineers to choose the approach best suited to given specifications. The chapter concludes with performance tradeoffs including the fundamental tension between speed and stability, sensitivity functions, robustness concepts, and the handling of disturbances and noise in feedback systems.</p>"},{"location":"chapters/16-compensator-design-performance/#concepts-covered","title":"Concepts Covered","text":"<p>This chapter covers the following 20 concepts from the learning graph:</p> <ol> <li>Lead Compensator</li> <li>Lag Compensator</li> <li>Lead-Lag Compensator</li> <li>Phase Lead</li> <li>Phase Lag</li> <li>Compensator Design</li> <li>Maximum Phase Lead</li> <li>Compensation Zero</li> <li>Compensation Pole</li> <li>Bode Design Method</li> <li>Root Locus Design</li> <li>Performance Specs</li> <li>Design Tradeoffs</li> <li>Speed vs Stability</li> <li>Robustness</li> <li>Sensitivity</li> <li>Sensitivity Function</li> <li>Complementary Sensitivity</li> <li>Disturbance Rejection</li> <li>Noise Attenuation</li> </ol>"},{"location":"chapters/16-compensator-design-performance/#prerequisites","title":"Prerequisites","text":"<p>This chapter builds on concepts from:</p> <ul> <li>Chapter 4: Transient Response Specifications</li> <li>Chapter 6: Poles, Zeros, and System Analysis</li> <li>Chapter 9: Block Diagrams and Signal Flow</li> <li>Chapter 10: Stability Analysis and Routh-Hurwitz</li> <li>Chapter 11: Root Locus Analysis and Design</li> <li>Chapter 12: Frequency Response and Bode Plots</li> <li>Chapter 13: Nyquist Analysis and Stability Margins</li> <li>Chapter 14: Steady-State Error Analysis</li> </ul> <p>TODO: Generate Chapter Content</p>"},{"location":"learning-graph/","title":"Learning Graph for Control Systems","text":"<p>View the Learning Graph</p> <p>This section contains the learning graph for this textbook. A learning graph is a graph of concepts used in this textbook. Each concept is represented by a node in a network graph. Concepts are connected by directed edges that indicate what concepts each node depends on before that concept is understood by the student.</p> <p>A learning graph is the foundational data structure for intelligent textbooks that can recommend learning paths. A learning graph is like a roadmap of concepts to help students arrive at their learning goals.</p> <p>At the left of the learning graph are prerequisite or foundational concepts. They have no outbound edges. They only have inbound edges for other concepts that depend on understanding these foundational prerequisite concepts. At the far right we have the most advanced concepts in the course. To master these concepts you must understand all the concepts that they point to.</p>"},{"location":"learning-graph/#learning-graph-statistics","title":"Learning Graph Statistics","text":"<ul> <li>Total Concepts: 300</li> <li>Foundational Concepts: 1 (Control System)</li> <li>Taxonomy Categories: 13</li> <li>Total Dependencies: 485</li> </ul> <p>Here are other files used by the learning graph.</p>"},{"location":"learning-graph/#course-description","title":"Course Description","text":"<p>We use the Course Description as the source document for the concepts that are included in this course. The course description uses the 2001 Bloom taxonomy to order learning objectives.</p>"},{"location":"learning-graph/#list-of-concepts","title":"List of Concepts","text":"<p>We use generative AI to convert the course description into a Concept List. Each concept is in the form of a short Title Case label with most labels under 32 characters long.</p>"},{"location":"learning-graph/#concept-dependency-list","title":"Concept Dependency List","text":"<p>We next use generative AI to create a Directed Acyclic Graph (DAG). DAGs do not have cycles where concepts depend on themselves. We provide the DAG in two formats. One is a CSV file and the other format is a JSON file that uses the vis-network JavaScript library format. The vis-network format uses <code>nodes</code>, <code>edges</code> and <code>metadata</code> elements with edges containing <code>from</code> and <code>to</code> properties. This makes it easy for you to view and edit the learning graph using an editor built with the vis-network tools.</p>"},{"location":"learning-graph/#analysis-documentation","title":"Analysis &amp; Documentation","text":""},{"location":"learning-graph/#course-description-quality-assessment","title":"Course Description Quality Assessment","text":"<p>This report rates the overall quality of the course description for the purpose of generating a learning graph.</p> <ul> <li>Course description fields and content depth analysis</li> <li>Validates course description has sufficient depth for generating 300 concepts</li> <li>Compares course description against similar courses</li> <li>Identifies content gaps and strengths</li> <li>Suggests areas of improvement</li> </ul> <p>View the Course Description Quality Assessment</p>"},{"location":"learning-graph/#learning-graph-quality-validation","title":"Learning Graph Quality Validation","text":"<p>This report gives you an overall assessment of the quality of the learning graph. It uses graph algorithms to look for specific quality patterns in the graph.</p> <ul> <li>Graph structure validation - all concepts are connected</li> <li>DAG validation (no cycles detected)</li> <li>Foundational concepts: 1 entry point (Control System)</li> <li>Indegree distribution analysis</li> <li>Longest dependency chain: 18 concepts</li> <li>Connectivity: 100% of nodes connected to the main cluster</li> </ul> <p>View the Learning Graph Quality Validation</p>"},{"location":"learning-graph/#concept-taxonomy","title":"Concept Taxonomy","text":"<p>In order to see patterns in the learning graph, it is useful to assign colors to each concept based on the concept type. We use generative AI to create about a dozen categories for our concepts and then place each concept into a single primary classifier.</p> <ul> <li>13 taxonomy categories covering all control systems topics</li> <li>Category organization - foundational elements first, performance concepts last</li> <li>Balanced categories with pedagogical flow</li> <li>Clear 3-5 letter abbreviations for use in CSV file</li> </ul> <p>View the Concept Taxonomy</p>"},{"location":"learning-graph/#taxonomy-distribution","title":"Taxonomy Distribution","text":"<p>This report shows how many concepts fit into each category of the taxonomy. Our goal is a somewhat balanced taxonomy where each category holds an equal number of concepts. We also don't want any category to contain over 30% of our concepts.</p> <ul> <li>Statistical breakdown by category</li> <li>Detailed concept listing by category</li> <li>Visual distribution chart</li> <li>Balance verification</li> </ul> <p>View the Taxonomy Distribution Report</p>"},{"location":"learning-graph/concept-list/","title":"Control Systems Concept List","text":"<p>This document contains the 300 concepts for the Control Systems intelligent textbook. Each concept is numbered with a unique ConceptID for reference in the learning graph.</p>"},{"location":"learning-graph/concept-list/#concepts","title":"Concepts","text":"<ol> <li>Control System</li> <li>Feedback</li> <li>Open-Loop Control</li> <li>Closed-Loop Control</li> <li>Plant</li> <li>Controller</li> <li>Actuator</li> <li>Sensor</li> <li>Reference Input</li> <li>Error Signal</li> <li>Disturbance</li> <li>System Response</li> <li>Dynamic System</li> <li>Linear System</li> <li>Time-Invariant System</li> <li>LTI System</li> <li>Superposition Principle</li> <li>Homogeneity</li> <li>Causality</li> <li>Differential Equation</li> <li>First-Order System</li> <li>Second-Order System</li> <li>Higher-Order System</li> <li>Order of a System</li> <li>Initial Conditions</li> <li>Natural Response</li> <li>Forced Response</li> <li>Total Response</li> <li>Zero-Input Response</li> <li>Zero-State Response</li> <li>Transient Response</li> <li>Steady-State Response</li> <li>Time Constant</li> <li>Damping Ratio</li> <li>Natural Frequency</li> <li>Damped Frequency</li> <li>Undamped System</li> <li>Underdamped System</li> <li>Critically Damped System</li> <li>Overdamped System</li> <li>Overshoot</li> <li>Percent Overshoot</li> <li>Settling Time</li> <li>Rise Time</li> <li>Peak Time</li> <li>Delay Time</li> <li>Step Input</li> <li>Impulse Input</li> <li>Ramp Input</li> <li>Parabolic Input</li> <li>Sinusoidal Input</li> <li>Unit Step Response</li> <li>Impulse Response</li> <li>Ramp Response</li> <li>Standard Test Inputs</li> <li>Transfer Function</li> <li>Laplace Transform</li> <li>Inverse Laplace Transform</li> <li>S-Domain</li> <li>Time Domain</li> <li>Frequency Domain</li> <li>Poles</li> <li>Zeros</li> <li>Pole-Zero Plot</li> <li>Pole-Zero Cancellation</li> <li>Dominant Poles</li> <li>Pole Locations</li> <li>Complex Conjugate Poles</li> <li>Real Poles</li> <li>Repeated Poles</li> <li>Simple Poles</li> <li>Pole at Origin</li> <li>Poles in Left Half Plane</li> <li>Poles in Right Half Plane</li> <li>Poles on Imaginary Axis</li> <li>Initial Value Theorem</li> <li>Final Value Theorem</li> <li>Partial Fraction Expansion</li> <li>Residue Calculation</li> <li>Cover-Up Method</li> <li>Convolution Integral</li> <li>Convolution in S-Domain</li> <li>System Order</li> <li>Proper Transfer Function</li> <li>Strictly Proper Function</li> <li>DC Gain</li> <li>Electrical Systems</li> <li>Mechanical Systems</li> <li>Translational Systems</li> <li>Rotational Systems</li> <li>Electromechanical Systems</li> <li>Motor Model</li> <li>DC Motor</li> <li>Armature-Controlled Motor</li> <li>Field-Controlled Motor</li> <li>Motor Transfer Function</li> <li>RLC Circuit</li> <li>RC Circuit</li> <li>RL Circuit</li> <li>Op-Amp Circuits</li> <li>Mass-Spring-Damper</li> <li>Pendulum System</li> <li>Gear Train</li> <li>Lever System</li> <li>Fluid Systems</li> <li>Thermal Systems</li> <li>Analogous Systems</li> <li>Impedance Analogy</li> <li>Mobility Analogy</li> <li>Force-Voltage Analogy</li> <li>Force-Current Analogy</li> <li>Linearization</li> <li>Operating Point</li> <li>Equilibrium Point</li> <li>Small Signal Analysis</li> <li>Taylor Series Expansion</li> <li>Nonlinear System</li> <li>Saturation</li> <li>Dead Zone</li> <li>Backlash</li> <li>Hysteresis</li> <li>Block Diagram</li> <li>Summing Junction</li> <li>Pickoff Point</li> <li>Cascade Connection</li> <li>Parallel Connection</li> <li>Feedback Connection</li> <li>Block Diagram Reduction</li> <li>Block Diagram Algebra</li> <li>Forward Path</li> <li>Feedback Path</li> <li>Loop</li> <li>Inner Loop</li> <li>Outer Loop</li> <li>Loop Gain</li> <li>Closed-Loop Transfer</li> <li>Open-Loop Transfer</li> <li>Unity Feedback</li> <li>Non-Unity Feedback</li> <li>Signal Flow Graph</li> <li>Node</li> <li>Branch</li> <li>Branch Gain</li> <li>Mason's Gain Formula</li> <li>Forward Path Gain</li> <li>Loop Gain Calculation</li> <li>Non-Touching Loops</li> <li>Graph Determinant</li> <li>Cofactor</li> <li>Stability</li> <li>BIBO Stability</li> <li>Internal Stability</li> <li>Asymptotic Stability</li> <li>Marginal Stability</li> <li>Unstable System</li> <li>Bounded Input</li> <li>Bounded Output</li> <li>Characteristic Equation</li> <li>Characteristic Polynomial</li> <li>Characteristic Roots</li> <li>Routh-Hurwitz Criterion</li> <li>Routh Array</li> <li>Routh Array Construction</li> <li>Special Cases Routh</li> <li>Zero in First Column</li> <li>Row of Zeros</li> <li>Auxiliary Polynomial</li> <li>Stability Boundary</li> <li>Relative Stability</li> <li>Root Locus</li> <li>Root Locus Rules</li> <li>Starting Points</li> <li>Ending Points</li> <li>Number of Branches</li> <li>Symmetry Property</li> <li>Real Axis Segments</li> <li>Angle Condition</li> <li>Magnitude Condition</li> <li>Breakaway Point</li> <li>Break-In Point</li> <li>Asymptotes</li> <li>Centroid</li> <li>Asymptote Angles</li> <li>Departure Angle</li> <li>Arrival Angle</li> <li>Imaginary Axis Crossing</li> <li>Root Locus Gain</li> <li>Gain Adjustment</li> <li>Dominant Pole Design</li> <li>Pole Placement</li> <li>Root Locus Compensation</li> <li>Frequency Response</li> <li>Sinusoidal Steady State</li> <li>Magnitude Response</li> <li>Phase Response</li> <li>Frequency Transfer Func</li> <li>Substitution s=jw</li> <li>Bode Plot</li> <li>Bode Magnitude Plot</li> <li>Bode Phase Plot</li> <li>Decibel</li> <li>Logarithmic Scale</li> <li>Decade</li> <li>Octave</li> <li>Corner Frequency</li> <li>Break Frequency</li> <li>Asymptotic Approximation</li> <li>Bode Plot Construction</li> <li>First-Order Factor</li> <li>Second-Order Factor</li> <li>First-Order Bode Plot</li> <li>Second-Order Bode Plot</li> <li>Integrator Bode Plot</li> <li>Differentiator Bode Plot</li> <li>Constant Gain Term</li> <li>Time Delay in Bode</li> <li>Resonant Peak</li> <li>Resonant Frequency</li> <li>Quality Factor</li> <li>Bandwidth</li> <li>Cutoff Frequency</li> <li>Half-Power Point</li> <li>Low-Pass System</li> <li>High-Pass System</li> <li>Bandpass System</li> <li>Notch Filter</li> <li>Gain Margin</li> <li>Phase Margin</li> <li>Stability Margins</li> <li>Crossover Frequency</li> <li>Gain Crossover</li> <li>Phase Crossover</li> <li>Minimum Phase System</li> <li>Non-Minimum Phase</li> <li>All-Pass System</li> <li>Nyquist Plot</li> <li>Nyquist Diagram</li> <li>Nyquist Criterion</li> <li>Nyquist Contour</li> <li>Encirclement</li> <li>Clockwise Encirclement</li> <li>Right-Half Plane Poles</li> <li>Right-Half Plane Zeros</li> <li>Conditionally Stable</li> <li>Gain Margin from Nyquist</li> <li>Phase Margin from Nyquist</li> <li>Steady-State Error</li> <li>Steady-State Accuracy</li> <li>Error Constants</li> <li>Position Error Constant</li> <li>Velocity Error Constant</li> <li>Acceleration Error Const</li> <li>System Type</li> <li>Type 0 System</li> <li>Type 1 System</li> <li>Type 2 System</li> <li>Type Number</li> <li>Error Coefficients</li> <li>Disturbance Error</li> <li>Proportional Control</li> <li>Integral Control</li> <li>Derivative Control</li> <li>P Controller</li> <li>PI Controller</li> <li>PD Controller</li> <li>PID Controller</li> <li>Proportional Gain</li> <li>Integral Gain</li> <li>Derivative Gain</li> <li>Integral Time</li> <li>Derivative Time</li> <li>Controller Tuning</li> <li>Ziegler-Nichols Method</li> <li>Reaction Curve Method</li> <li>Ultimate Gain Method</li> <li>Ultimate Gain</li> <li>Ultimate Period</li> <li>Trial and Error Tuning</li> <li>Anti-Windup</li> <li>Derivative Kick</li> <li>Lead Compensator</li> <li>Lag Compensator</li> <li>Lead-Lag Compensator</li> <li>Phase Lead</li> <li>Phase Lag</li> <li>Compensator Design</li> <li>Maximum Phase Lead</li> <li>Compensation Zero</li> <li>Compensation Pole</li> <li>Bode Design Method</li> <li>Root Locus Design</li> <li>Performance Specs</li> <li>Design Tradeoffs</li> <li>Speed vs Stability</li> <li>Robustness</li> <li>Sensitivity</li> <li>Sensitivity Function</li> <li>Complementary Sensitivity</li> <li>Disturbance Rejection</li> <li>Noise Attenuation</li> </ol>"},{"location":"learning-graph/concept-taxonomy/","title":"Concept Taxonomy","text":"<p>This document defines the categorical taxonomy for organizing the 300 concepts in the Control Systems learning graph.</p>"},{"location":"learning-graph/concept-taxonomy/#taxonomy-categories","title":"Taxonomy Categories","text":"Category Name TaxonomyID Description Foundation Concepts FOUND Basic definitions, terminology, and introductory concepts for control systems System Properties PROP Properties and characteristics of dynamic and LTI systems Time Response TIME Time-domain analysis, transient and steady-state response concepts Laplace Methods LAPL Laplace transform techniques, s-domain analysis, and transfer functions Physical Modeling MODEL Mathematical modeling of electrical, mechanical, and electromechanical systems Linearization LINEAR Linearization techniques and nonlinear system concepts Block Diagrams BLOCK Block diagram representation, reduction, and signal flow graphs Stability Analysis STAB Stability concepts, Routh-Hurwitz criterion, and stability margins Root Locus RLOC Root locus analysis and design techniques Frequency Response FREQ Frequency-domain analysis, Bode plots, and Nyquist diagrams Steady-State Error ERROR Steady-state error analysis, system type, and error constants Controller Design CTRL PID control, compensator design, and controller tuning methods Performance PERF Performance specifications, design tradeoffs, and robustness"},{"location":"learning-graph/concept-taxonomy/#category-descriptions","title":"Category Descriptions","text":""},{"location":"learning-graph/concept-taxonomy/#found-foundation-concepts","title":"FOUND - Foundation Concepts","text":"<p>Core vocabulary and fundamental building blocks including control system, feedback, open/closed-loop control, plant, controller, actuator, sensor, and basic signal definitions.</p>"},{"location":"learning-graph/concept-taxonomy/#prop-system-properties","title":"PROP - System Properties","text":"<p>Characteristics of systems including linearity, time-invariance, LTI properties, superposition, causality, and system order concepts.</p>"},{"location":"learning-graph/concept-taxonomy/#time-time-response","title":"TIME - Time Response","text":"<p>Analysis of system behavior in time domain including natural/forced response, transient specifications (overshoot, settling time, rise time), damping, and response to standard test inputs.</p>"},{"location":"learning-graph/concept-taxonomy/#lapl-laplace-methods","title":"LAPL - Laplace Methods","text":"<p>Mathematical tools for system analysis including Laplace transforms, s-domain representation, poles, zeros, partial fractions, and transfer function properties.</p>"},{"location":"learning-graph/concept-taxonomy/#model-physical-modeling","title":"MODEL - Physical Modeling","text":"<p>Modeling of real systems including electrical circuits (RLC, RC, RL, op-amp), mechanical systems (mass-spring-damper, pendulum, gears), motors, and analogous system concepts.</p>"},{"location":"learning-graph/concept-taxonomy/#linear-linearization","title":"LINEAR - Linearization","text":"<p>Handling of nonlinear systems including linearization at operating points, Taylor series expansion, and common nonlinearities (saturation, dead zone, backlash, hysteresis).</p>"},{"location":"learning-graph/concept-taxonomy/#block-block-diagrams","title":"BLOCK - Block Diagrams","text":"<p>System representation using block diagrams and signal flow graphs including summing junctions, cascade/parallel/feedback connections, reduction techniques, and Mason's gain formula.</p>"},{"location":"learning-graph/concept-taxonomy/#stab-stability-analysis","title":"STAB - Stability Analysis","text":"<p>Fundamental stability concepts including BIBO stability, characteristic equation, Routh-Hurwitz criterion, and introduction to relative stability concepts.</p>"},{"location":"learning-graph/concept-taxonomy/#rloc-root-locus","title":"RLOC - Root Locus","text":"<p>Root locus method for analyzing closed-loop pole locations including construction rules, breakaway points, asymptotes, angles, and design using root locus.</p>"},{"location":"learning-graph/concept-taxonomy/#freq-frequency-response","title":"FREQ - Frequency Response","text":"<p>Frequency-domain analysis including Bode plots (magnitude and phase), frequency response characteristics, Nyquist diagrams and criterion, and stability margins (gain and phase margin).</p>"},{"location":"learning-graph/concept-taxonomy/#error-steady-state-error","title":"ERROR - Steady-State Error","text":"<p>Analysis of steady-state accuracy including error constants, system type classification, and disturbance error concepts.</p>"},{"location":"learning-graph/concept-taxonomy/#ctrl-controller-design","title":"CTRL - Controller Design","text":"<p>Design of controllers including proportional, integral, and derivative control, PID tuning methods (Ziegler-Nichols), and lead/lag compensation techniques.</p>"},{"location":"learning-graph/concept-taxonomy/#perf-performance","title":"PERF - Performance","text":"<p>High-level design considerations including performance specifications, design tradeoffs, robustness, sensitivity functions, and disturbance/noise handling.</p>"},{"location":"learning-graph/course-description-assessment/","title":"Course Description Quality Assessment","text":"<p>Course: Control Systems Assessment Date: 2026-01-31 Quality Score: 100/100</p>"},{"location":"learning-graph/course-description-assessment/#scoring-summary","title":"Scoring Summary","text":"Element Points Max Assessment Title 5 5 Clear, descriptive title present Target Audience 5 5 Specific audience identified (upper-division EE undergrads, ME, CompE, Mechatronics) Prerequisites 5 5 Comprehensive list including Calculus, Diff Eq, Linear Algebra, Complex numbers, Signals/Systems, Programming Main Topics Covered 10 10 9 well-organized topic sections covering full breadth Topics Excluded 5 5 Clear boundaries set (State-space, Digital, MIMO, Optimal control, etc.) Learning Outcomes Header 5 5 Uses Bloom's 2001 taxonomy structure Remember Level 10 10 6 specific, actionable outcomes Understand Level 10 10 6 specific, actionable outcomes Apply Level 10 10 6 specific, actionable outcomes Analyze Level 10 10 6 specific, actionable outcomes Evaluate Level 10 10 6 specific, actionable outcomes Create Level 10 10 6 specific outcomes with capstone ideas Descriptive Context 5 5 Strong overview explaining course relevance and pedagogical approach Total 100 100"},{"location":"learning-graph/course-description-assessment/#strengths","title":"Strengths","text":"<ol> <li> <p>Comprehensive Prerequisites: The prerequisites section provides specific mathematical and technical skills, ensuring students are properly prepared.</p> </li> <li> <p>Well-Defined Scope: The \"Concepts NOT covered\" section clearly bounds the course to classical, continuous-time, SISO control using transfer function methods.</p> </li> <li> <p>Complete Bloom's Taxonomy Coverage: All six cognitive levels are addressed with multiple specific, actionable outcomes per level (6 outcomes each).</p> </li> <li> <p>Logical Topic Organization: Topics flow naturally from foundations through modeling, analysis, and design.</p> </li> <li> <p>ABET Alignment: Explicit mention of ABET alignment signals accreditation-ready design.</p> </li> <li> <p>Clear Audience Definition: Multiple engineering disciplines identified with qualification requirements.</p> </li> </ol>"},{"location":"learning-graph/course-description-assessment/#estimated-concept-count","title":"Estimated Concept Count","text":"<p>Based on the course description, approximately 180-220 concepts can be derived:</p> <ul> <li>Foundations: ~15 concepts</li> <li>System Modeling: ~25 concepts</li> <li>Laplace Transform Methods: ~20 concepts</li> <li>Block Diagrams and Signal Flow: ~15 concepts</li> <li>Time-Domain Analysis: ~25 concepts</li> <li>Stability Analysis: ~25 concepts</li> <li>Frequency-Domain Analysis: ~30 concepts</li> <li>Controller Design: ~30 concepts</li> <li>Computer-Aided Analysis: ~15 concepts</li> <li>Cross-cutting concepts and applications: ~20 concepts</li> </ul> <p>This is consistent with similar undergraduate control systems courses at accredited institutions.</p>"},{"location":"learning-graph/course-description-assessment/#recommendation","title":"Recommendation","text":"<p>PROCEED - This course description is fully ready for learning graph generation. The quality score of 100/100 exceeds the recommended threshold of 70.</p>"},{"location":"learning-graph/quality-metrics/","title":"Learning Graph Quality Metrics Report","text":""},{"location":"learning-graph/quality-metrics/#overview","title":"Overview","text":"<ul> <li>Total Concepts: 300</li> <li>Foundational Concepts (no dependencies): 1</li> <li>Concepts with Dependencies: 299</li> <li>Average Dependencies per Concept: 1.62</li> </ul>"},{"location":"learning-graph/quality-metrics/#graph-structure-validation","title":"Graph Structure Validation","text":"<ul> <li>Valid DAG Structure: \u274c No</li> <li>Self-Dependencies: None detected \u2705</li> <li>Cycles Detected: 0</li> </ul>"},{"location":"learning-graph/quality-metrics/#foundational-concepts","title":"Foundational Concepts","text":"<p>These concepts have no prerequisites:</p> <ul> <li>1: Control System</li> </ul>"},{"location":"learning-graph/quality-metrics/#dependency-chain-analysis","title":"Dependency Chain Analysis","text":"<ul> <li>Maximum Dependency Chain Length: 18</li> </ul>"},{"location":"learning-graph/quality-metrics/#longest-learning-path","title":"Longest Learning Path:","text":"<ol> <li>Control System (ID: 1)</li> <li>Dynamic System (ID: 13)</li> <li>Linear System (ID: 14)</li> <li>LTI System (ID: 16)</li> <li>Transfer Function (ID: 56)</li> <li>Block Diagram (ID: 122)</li> <li>Cascade Connection (ID: 125)</li> <li>Block Diagram Reduction (ID: 128)</li> <li>Closed-Loop Transfer (ID: 136)</li> <li>Forward Path (ID: 130)</li> <li>Loop (ID: 132)</li> <li>Loop Gain (ID: 135)</li> <li>Root Locus (ID: 170)</li> <li>Root Locus Rules (ID: 171)</li> <li>Magnitude Condition (ID: 178)</li> <li>Root Locus Gain (ID: 187)</li> <li>Gain Adjustment (ID: 188)</li> <li>Conditionally Stable (ID: 244)</li> </ol>"},{"location":"learning-graph/quality-metrics/#orphaned-nodes-analysis","title":"Orphaned Nodes Analysis","text":"<ul> <li>Total Orphaned Nodes: 125</li> </ul> <p>Concepts that are not prerequisites for any other concept:</p> <ul> <li>7: Actuator</li> <li>17: Superposition Principle</li> <li>18: Homogeneity</li> <li>19: Causality</li> <li>23: Higher-Order System</li> <li>29: Zero-Input Response</li> <li>30: Zero-State Response</li> <li>37: Undamped System</li> <li>39: Critically Damped System</li> <li>40: Overdamped System</li> <li>42: Percent Overshoot</li> <li>45: Peak Time</li> <li>46: Delay Time</li> <li>50: Parabolic Input</li> <li>52: Unit Step Response</li> <li>54: Ramp Response</li> <li>55: Standard Test Inputs</li> <li>60: Time Domain</li> <li>65: Pole-Zero Cancellation</li> <li>69: Real Poles</li> </ul> <p>...and 105 more</p>"},{"location":"learning-graph/quality-metrics/#connected-components","title":"Connected Components","text":"<ul> <li>Number of Connected Components: 1</li> </ul> <p>\u2705 All concepts are connected in a single graph.</p>"},{"location":"learning-graph/quality-metrics/#indegree-analysis","title":"Indegree Analysis","text":"<p>Top 10 concepts that are prerequisites for the most other concepts:</p> Rank Concept ID Concept Label Indegree 1 56 Transfer Function 15 2 150 Stability 14 3 171 Root Locus Rules 13 4 198 Bode Plot 13 5 1 Control System 10 6 62 Poles 10 7 122 Block Diagram 9 8 6 Controller 8 9 20 Differential Equation 8 10 59 S-Domain 8"},{"location":"learning-graph/quality-metrics/#outdegree-distribution","title":"Outdegree Distribution","text":"Dependencies Number of Concepts 0 1 1 134 2 147 3 15 4 3"},{"location":"learning-graph/quality-metrics/#recommendations","title":"Recommendations","text":"<ul> <li>\u26a0\ufe0f Many orphaned nodes (125): Consider if these should be prerequisites for advanced concepts</li> <li>\u2139\ufe0f Long dependency chains (18): Ensure students can follow extended learning paths</li> </ul> <p>Report generated by learning-graph-reports/analyze_graph.py</p>"},{"location":"learning-graph/taxonomy-distribution/","title":"Taxonomy Distribution Report","text":""},{"location":"learning-graph/taxonomy-distribution/#overview","title":"Overview","text":"<ul> <li>Total Concepts: 300</li> <li>Number of Taxonomies: 13</li> <li>Average Concepts per Taxonomy: 23.1</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#distribution-summary","title":"Distribution Summary","text":"Category TaxonomyID Count Percentage Status Frequency Response FREQ 55 18.3% \u2705 Time Response TIME 35 11.7% \u2705 Controller Design CTRL 32 10.7% \u2705 Laplace Methods LAPL 31 10.3% \u2705 Block Diagrams BLOCK 28 9.3% \u2705 Physical Modeling MODEL 25 8.3% \u2705 Root Locus RLOC 22 7.3% \u2705 Stability Analysis STAB 20 6.7% \u2705 Steady-State Error ERROR 13 4.3% \u2705 Foundation Concepts FOUND 12 4.0% \u2705 Linearization LINEAR 10 3.3% \u2705 Performance PERF 9 3.0% \u2705 System Properties PROP 8 2.7% \u2139\ufe0f Under"},{"location":"learning-graph/taxonomy-distribution/#visual-distribution","title":"Visual Distribution","text":"<pre><code>FREQ   \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  55 ( 18.3%)\nTIME   \u2588\u2588\u2588\u2588\u2588  35 ( 11.7%)\nCTRL   \u2588\u2588\u2588\u2588\u2588  32 ( 10.7%)\nLAPL   \u2588\u2588\u2588\u2588\u2588  31 ( 10.3%)\nBLOCK  \u2588\u2588\u2588\u2588  28 (  9.3%)\nMODEL  \u2588\u2588\u2588\u2588  25 (  8.3%)\nRLOC   \u2588\u2588\u2588  22 (  7.3%)\nSTAB   \u2588\u2588\u2588  20 (  6.7%)\nERROR  \u2588\u2588  13 (  4.3%)\nFOUND  \u2588\u2588  12 (  4.0%)\nLINEAR \u2588  10 (  3.3%)\nPERF   \u2588   9 (  3.0%)\nPROP   \u2588   8 (  2.7%)\n</code></pre>"},{"location":"learning-graph/taxonomy-distribution/#balance-analysis","title":"Balance Analysis","text":""},{"location":"learning-graph/taxonomy-distribution/#no-over-represented-categories","title":"\u2705 No Over-Represented Categories","text":"<p>All categories are under the 30% threshold. Good balance!</p>"},{"location":"learning-graph/taxonomy-distribution/#i-under-represented-categories-3","title":"\u2139\ufe0f Under-Represented Categories (&lt;3%)","text":"<ul> <li>System Properties (PROP): 8 concepts (2.7%)</li> <li>Note: Small categories are acceptable for specialized topics</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#category-details","title":"Category Details","text":""},{"location":"learning-graph/taxonomy-distribution/#frequency-response-freq","title":"Frequency Response (FREQ)","text":"<p>Count: 55 concepts (18.3%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Frequency Response</li> </ol> </li> <li> <ol> <li>Sinusoidal Steady State</li> </ol> </li> <li> <ol> <li>Magnitude Response</li> </ol> </li> <li> <ol> <li>Phase Response</li> </ol> </li> <li> <ol> <li>Frequency Transfer Func</li> </ol> </li> <li> <ol> <li>Substitution s=jw</li> </ol> </li> <li> <ol> <li>Bode Plot</li> </ol> </li> <li> <ol> <li>Bode Magnitude Plot</li> </ol> </li> <li> <ol> <li>Bode Phase Plot</li> </ol> </li> <li> <ol> <li>Decibel</li> </ol> </li> <li> <ol> <li>Logarithmic Scale</li> </ol> </li> <li> <ol> <li>Decade</li> </ol> </li> <li> <ol> <li>Octave</li> </ol> </li> <li> <ol> <li>Corner Frequency</li> </ol> </li> <li> <ol> <li>Break Frequency</li> </ol> </li> <li>...and 40 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#time-response-time","title":"Time Response (TIME)","text":"<p>Count: 35 concepts (11.7%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>First-Order System</li> </ol> </li> <li> <ol> <li>Second-Order System</li> </ol> </li> <li> <ol> <li>Higher-Order System</li> </ol> </li> <li> <ol> <li>Order of a System</li> </ol> </li> <li> <ol> <li>Initial Conditions</li> </ol> </li> <li> <ol> <li>Natural Response</li> </ol> </li> <li> <ol> <li>Forced Response</li> </ol> </li> <li> <ol> <li>Total Response</li> </ol> </li> <li> <ol> <li>Zero-Input Response</li> </ol> </li> <li> <ol> <li>Zero-State Response</li> </ol> </li> <li> <ol> <li>Transient Response</li> </ol> </li> <li> <ol> <li>Steady-State Response</li> </ol> </li> <li> <ol> <li>Time Constant</li> </ol> </li> <li> <ol> <li>Damping Ratio</li> </ol> </li> <li> <ol> <li>Natural Frequency</li> </ol> </li> <li>...and 20 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#controller-design-ctrl","title":"Controller Design (CTRL)","text":"<p>Count: 32 concepts (10.7%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Proportional Control</li> </ol> </li> <li> <ol> <li>Integral Control</li> </ol> </li> <li> <ol> <li>Derivative Control</li> </ol> </li> <li> <ol> <li>P Controller</li> </ol> </li> <li> <ol> <li>PI Controller</li> </ol> </li> <li> <ol> <li>PD Controller</li> </ol> </li> <li> <ol> <li>PID Controller</li> </ol> </li> <li> <ol> <li>Proportional Gain</li> </ol> </li> <li> <ol> <li>Integral Gain</li> </ol> </li> <li> <ol> <li>Derivative Gain</li> </ol> </li> <li> <ol> <li>Integral Time</li> </ol> </li> <li> <ol> <li>Derivative Time</li> </ol> </li> <li> <ol> <li>Controller Tuning</li> </ol> </li> <li> <ol> <li>Ziegler-Nichols Method</li> </ol> </li> <li> <ol> <li>Reaction Curve Method</li> </ol> </li> <li>...and 17 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#laplace-methods-lapl","title":"Laplace Methods (LAPL)","text":"<p>Count: 31 concepts (10.3%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Transfer Function</li> </ol> </li> <li> <ol> <li>Laplace Transform</li> </ol> </li> <li> <ol> <li>Inverse Laplace Transform</li> </ol> </li> <li> <ol> <li>S-Domain</li> </ol> </li> <li> <ol> <li>Time Domain</li> </ol> </li> <li> <ol> <li>Frequency Domain</li> </ol> </li> <li> <ol> <li>Poles</li> </ol> </li> <li> <ol> <li>Zeros</li> </ol> </li> <li> <ol> <li>Pole-Zero Plot</li> </ol> </li> <li> <ol> <li>Pole-Zero Cancellation</li> </ol> </li> <li> <ol> <li>Dominant Poles</li> </ol> </li> <li> <ol> <li>Pole Locations</li> </ol> </li> <li> <ol> <li>Complex Conjugate Poles</li> </ol> </li> <li> <ol> <li>Real Poles</li> </ol> </li> <li> <ol> <li>Repeated Poles</li> </ol> </li> <li>...and 16 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#block-diagrams-block","title":"Block Diagrams (BLOCK)","text":"<p>Count: 28 concepts (9.3%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Block Diagram</li> </ol> </li> <li> <ol> <li>Summing Junction</li> </ol> </li> <li> <ol> <li>Pickoff Point</li> </ol> </li> <li> <ol> <li>Cascade Connection</li> </ol> </li> <li> <ol> <li>Parallel Connection</li> </ol> </li> <li> <ol> <li>Feedback Connection</li> </ol> </li> <li> <ol> <li>Block Diagram Reduction</li> </ol> </li> <li> <ol> <li>Block Diagram Algebra</li> </ol> </li> <li> <ol> <li>Forward Path</li> </ol> </li> <li> <ol> <li>Feedback Path</li> </ol> </li> <li> <ol> <li>Loop</li> </ol> </li> <li> <ol> <li>Inner Loop</li> </ol> </li> <li> <ol> <li>Outer Loop</li> </ol> </li> <li> <ol> <li>Loop Gain</li> </ol> </li> <li> <ol> <li>Closed-Loop Transfer</li> </ol> </li> <li>...and 13 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#physical-modeling-model","title":"Physical Modeling (MODEL)","text":"<p>Count: 25 concepts (8.3%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Electrical Systems</li> </ol> </li> <li> <ol> <li>Mechanical Systems</li> </ol> </li> <li> <ol> <li>Translational Systems</li> </ol> </li> <li> <ol> <li>Rotational Systems</li> </ol> </li> <li> <ol> <li>Electromechanical Systems</li> </ol> </li> <li> <ol> <li>Motor Model</li> </ol> </li> <li> <ol> <li>DC Motor</li> </ol> </li> <li> <ol> <li>Armature-Controlled Motor</li> </ol> </li> <li> <ol> <li>Field-Controlled Motor</li> </ol> </li> <li> <ol> <li>Motor Transfer Function</li> </ol> </li> <li> <ol> <li>RLC Circuit</li> </ol> </li> <li> <ol> <li>RC Circuit</li> </ol> </li> <li> <ol> <li>RL Circuit</li> </ol> </li> <li> <ol> <li>Op-Amp Circuits</li> </ol> </li> <li> <ol> <li>Mass-Spring-Damper</li> </ol> </li> <li>...and 10 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#root-locus-rloc","title":"Root Locus (RLOC)","text":"<p>Count: 22 concepts (7.3%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Root Locus</li> </ol> </li> <li> <ol> <li>Root Locus Rules</li> </ol> </li> <li> <ol> <li>Starting Points</li> </ol> </li> <li> <ol> <li>Ending Points</li> </ol> </li> <li> <ol> <li>Number of Branches</li> </ol> </li> <li> <ol> <li>Symmetry Property</li> </ol> </li> <li> <ol> <li>Real Axis Segments</li> </ol> </li> <li> <ol> <li>Angle Condition</li> </ol> </li> <li> <ol> <li>Magnitude Condition</li> </ol> </li> <li> <ol> <li>Breakaway Point</li> </ol> </li> <li> <ol> <li>Break-In Point</li> </ol> </li> <li> <ol> <li>Asymptotes</li> </ol> </li> <li> <ol> <li>Centroid</li> </ol> </li> <li> <ol> <li>Asymptote Angles</li> </ol> </li> <li> <ol> <li>Departure Angle</li> </ol> </li> <li>...and 7 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#stability-analysis-stab","title":"Stability Analysis (STAB)","text":"<p>Count: 20 concepts (6.7%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Stability</li> </ol> </li> <li> <ol> <li>BIBO Stability</li> </ol> </li> <li> <ol> <li>Internal Stability</li> </ol> </li> <li> <ol> <li>Asymptotic Stability</li> </ol> </li> <li> <ol> <li>Marginal Stability</li> </ol> </li> <li> <ol> <li>Unstable System</li> </ol> </li> <li> <ol> <li>Bounded Input</li> </ol> </li> <li> <ol> <li>Bounded Output</li> </ol> </li> <li> <ol> <li>Characteristic Equation</li> </ol> </li> <li> <ol> <li>Characteristic Polynomial</li> </ol> </li> <li> <ol> <li>Characteristic Roots</li> </ol> </li> <li> <ol> <li>Routh-Hurwitz Criterion</li> </ol> </li> <li> <ol> <li>Routh Array</li> </ol> </li> <li> <ol> <li>Routh Array Construction</li> </ol> </li> <li> <ol> <li>Special Cases Routh</li> </ol> </li> <li>...and 5 more</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#steady-state-error-error","title":"Steady-State Error (ERROR)","text":"<p>Count: 13 concepts (4.3%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Steady-State Error</li> </ol> </li> <li> <ol> <li>Steady-State Accuracy</li> </ol> </li> <li> <ol> <li>Error Constants</li> </ol> </li> <li> <ol> <li>Position Error Constant</li> </ol> </li> <li> <ol> <li>Velocity Error Constant</li> </ol> </li> <li> <ol> <li>Acceleration Error Const</li> </ol> </li> <li> <ol> <li>System Type</li> </ol> </li> <li> <ol> <li>Type 0 System</li> </ol> </li> <li> <ol> <li>Type 1 System</li> </ol> </li> <li> <ol> <li>Type 2 System</li> </ol> </li> <li> <ol> <li>Type Number</li> </ol> </li> <li> <ol> <li>Error Coefficients</li> </ol> </li> <li> <ol> <li>Disturbance Error</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#foundation-concepts-found","title":"Foundation Concepts (FOUND)","text":"<p>Count: 12 concepts (4.0%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Control System</li> </ol> </li> <li> <ol> <li>Feedback</li> </ol> </li> <li> <ol> <li>Open-Loop Control</li> </ol> </li> <li> <ol> <li>Closed-Loop Control</li> </ol> </li> <li> <ol> <li>Plant</li> </ol> </li> <li> <ol> <li>Controller</li> </ol> </li> <li> <ol> <li>Actuator</li> </ol> </li> <li> <ol> <li>Sensor</li> </ol> </li> <li> <ol> <li>Reference Input</li> </ol> </li> <li> <ol> <li>Error Signal</li> </ol> </li> <li> <ol> <li>Disturbance</li> </ol> </li> <li> <ol> <li>System Response</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#linearization-linear","title":"Linearization (LINEAR)","text":"<p>Count: 10 concepts (3.3%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Linearization</li> </ol> </li> <li> <ol> <li>Operating Point</li> </ol> </li> <li> <ol> <li>Equilibrium Point</li> </ol> </li> <li> <ol> <li>Small Signal Analysis</li> </ol> </li> <li> <ol> <li>Taylor Series Expansion</li> </ol> </li> <li> <ol> <li>Nonlinear System</li> </ol> </li> <li> <ol> <li>Saturation</li> </ol> </li> <li> <ol> <li>Dead Zone</li> </ol> </li> <li> <ol> <li>Backlash</li> </ol> </li> <li> <ol> <li>Hysteresis</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#performance-perf","title":"Performance (PERF)","text":"<p>Count: 9 concepts (3.0%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Performance Specs</li> </ol> </li> <li> <ol> <li>Design Tradeoffs</li> </ol> </li> <li> <ol> <li>Speed vs Stability</li> </ol> </li> <li> <ol> <li>Robustness</li> </ol> </li> <li> <ol> <li>Sensitivity</li> </ol> </li> <li> <ol> <li>Sensitivity Function</li> </ol> </li> <li> <ol> <li>Complementary Sensitivity</li> </ol> </li> <li> <ol> <li>Disturbance Rejection</li> </ol> </li> <li> <ol> <li>Noise Attenuation</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#system-properties-prop","title":"System Properties (PROP)","text":"<p>Count: 8 concepts (2.7%)</p> <p>Concepts:</p> <ul> <li> <ol> <li>Dynamic System</li> </ol> </li> <li> <ol> <li>Linear System</li> </ol> </li> <li> <ol> <li>Time-Invariant System</li> </ol> </li> <li> <ol> <li>LTI System</li> </ol> </li> <li> <ol> <li>Superposition Principle</li> </ol> </li> <li> <ol> <li>Homogeneity</li> </ol> </li> <li> <ol> <li>Causality</li> </ol> </li> <li> <ol> <li>Differential Equation</li> </ol> </li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#recommendations","title":"Recommendations","text":"<ul> <li>\u2705 Good balance: Categories are reasonably distributed (spread: 15.7%)</li> <li>\u2705 MISC category minimal: Good categorization specificity</li> </ul>"},{"location":"learning-graph/taxonomy-distribution/#educational-use-recommendations","title":"Educational Use Recommendations","text":"<ul> <li>Use taxonomy categories for color-coding in graph visualizations</li> <li>Design curriculum modules based on taxonomy groupings</li> <li>Create filtered views for focused learning paths</li> <li>Use categories for assessment organization</li> <li>Enable navigation by topic area in interactive tools</li> </ul> <p>Report generated by learning-graph-reports/taxonomy_distribution.py</p>"},{"location":"prompts/generate-chapter-content/","title":"Generate Chapter Content","text":"<p>Note that the tone guide has been moved to the CLAUDE.md file which is read when claude starts up.</p> <p>Use the /chapter-content-generator to generate content for chapter 5. Use the file at @docs/chapters/05-laplace-transform-methods/index.md When finished, write the session log to logs/ch-5.md </p> <p>Prompt</p> <p>Use the /chapter-content-generator to generate content for chapter 6. Use the file at @docs/chapters/06-poles-zeros-system-analysis/index.md When finished, write the session log to logs/ch-6.md </p> <p>Use the /chapter-content-generator to generate content for chapter 7. Use the file at @docs/chapters/07-physical-system-modeling/index.md The reading level is for a college-level course. When finished, write the session log to logs/ch-7.md </p> <p>Use the /chapter-content-generator to generate content for chapter 8. Use the file at @docs/chapters/08-linearization-nonlinear-effects/index.md The reading level is for a college-level course. When finished, write the session log to logs/ch-8.md </p> <p>Use the /chapter-content-generator to generate content for chapter 9. Use the file at @docs/chapters/09-block-diagrams-signal-flow/index.md The reading level is for a college-level course. When finished, write the session log to logs/ch-9.md</p> <p>Use the /chapter-content-generator to generate content for chapter 10. Use the file at @docs/chapters/10-stability-routh-hurwitz/index.md The reading level is for a college-level course. When finished, write the session log to logs/ch-10.md</p> <p>Use the /chapter-content-generator to generate content for chapter 11. Use the file at @docs/chapters/11-root-locus-analysis-design/index.md The reading level is for a college-level course. When finished, write the session log to logs/ch-11.md</p> <p>Use the /chapter-content-generator to generate content for chapter 12. Use the file at @docs/chapters/12-frequency-response-bode-plots/index.md The reading level is for a college-level course. When finished, write the session log to logs/ch-12.md</p> <p>Use the /chapter-content-generator to generate content for chapter 13. Use the file at @docs/chapters/13-nyquist-stability-margins/index.md The reading level is for a college-level course. When finished, write the session log to logs/ch-13.md</p> <p>14-steady-state-error-analysis 15-pid-control-tuning 16-compensator-design-performance</p>"},{"location":"sims/graph-viewer/","title":"Learning Graph Viewer","text":"<p>Open Learning Graph Viewer Fullscreen (recommended)</p> <p>This interactive viewer allows you to explore the learning graph for the Control Systems course.</p>"},{"location":"sims/graph-viewer/#features","title":"Features","text":"<ul> <li>Search: Type in the search box to find specific concepts</li> <li>Category Filtering: Use checkboxes to show/hide concept categories</li> <li>Interactive Navigation: Click and drag to explore, scroll to zoom</li> <li>Statistics: View real-time counts of visible nodes and edges</li> </ul>"},{"location":"sims/graph-viewer/#using-the-viewer","title":"Using the Viewer","text":"<ol> <li> <p>Search for Concepts: Start typing in the search box to find concepts. Click on a result to focus on that node.</p> </li> <li> <p>Filter by Category: Use the category checkboxes in the sidebar to show or hide groups of related concepts. Use \"Check All\" or \"Uncheck All\" for bulk operations.</p> </li> <li> <p>Navigate the Graph:</p> </li> <li>Drag to pan around the graph</li> <li>Scroll to zoom in and out</li> <li> <p>Click on a node to select it and highlight its connections</p> </li> <li> <p>View Statistics: The sidebar shows counts of visible nodes, edges, and foundational concepts.</p> </li> </ol>"},{"location":"sims/graph-viewer/#graph-structure","title":"Graph Structure","text":"<ul> <li>Foundational Concepts (left side): Prerequisites with no dependencies</li> <li>Advanced Concepts (right side): Topics that build on multiple prerequisites</li> <li>Edges: Arrows point from a concept to its prerequisites</li> </ul>"},{"location":"stories/","title":"List of Stories","text":""},{"location":"stories/mip/","title":"MiP: The Robot That Wouldn\u2019t Fall","text":""},{"location":"stories/mip/#panel-1-the-impossible-toy","title":"Panel 1 \u2014 The Impossible Toy","text":"Please generate a wide-landscape image with a width/height ratio of 16:9. The image is in the style of a graphic novel that uses a bright pallet of colors. A wide, cinematic panel set inside a brightly lit toy store. The art style is colorful, clean-lined, and slightly exaggerated, similar to a modern STEM-friendly graphic novel. The shelves curve inward using forced perspective, creating a sense of depth and wonder. Toys blur into the background, but one small robot stands sharply in focus at the center.  The robot is upright on **two wheels**, with no visible support. Its body is rounded, plastic, and friendly-looking \u2014 not humanoid, but expressive. The eyes are LED-style shapes glowing softly, giving it personality. Its posture is confident and centered.  Around the robot, faint semi-transparent arrows point downward, symbolizing gravity. These arrows have subtle cartoon faces, hinting at gravity as a persistent force trying to pull the robot down. Despite this, the robot remains perfectly vertical.  Children are visible in the background as silhouettes or lightly detailed figures \u2014 one kneeling, one pointing, one frozen mid-step \u2014 all clearly reacting with surprise and curiosity. Their expressions are wide-eyed and amazed.  The lighting highlights the robot, almost like a spotlight, emphasizing that this is *not an ordinary toy*.   <p>Most toys fall over. This one refused.</p>"},{"location":"stories/mip/#panel-2-years-before-the-shelf","title":"Panel 2 \u2014 Years Before the Shelf","text":"Interior of a small engineering lab drawn in warm, slightly chaotic graphic-novel style. The room is cluttered but alive with creativity. Tables are covered with circuit boards, motors, wires, batteries, notebooks, and 3D-printed parts. Whiteboards on the walls are packed with equations, block diagrams, arrows, timing loops, and handwritten notes like \u201ctoo unstable,\u201d \u201cbattery drain,\u201d and \u201ctry again.\u201d  A team of engineers \u2014 diverse in age, gender, and appearance \u2014 are gathered around a rough prototype robot held together with tape and zip ties. One engineer holds a laptop showing oscillating graphs. Another adjusts a screwdriver. A third watches nervously.  In the background, a previous prototype is mid-fall, captured in a dramatic freeze-frame moment, with comic-style motion lines and a playful \u201cCLACK!\u201d sound effect as it tips over.  The mood is determined but tired \u2014 coffee cups everywhere.  <p>MiP wasn\u2019t born in a toy store. It was built through years of trial, error, and stubborn optimism.</p>"},{"location":"stories/mip/#panel-3-the-cost-war","title":"Panel 3 \u2014 The Cost War","text":"A split-panel composition showing two contrasting robots side by side.  **Left side:** A sleek, over-engineered robot covered in sensors: cameras, laser-like beams, thick wiring, large batteries, and heavy metal components. It glows dramatically but looks complicated and expensive. A large exaggerated price tag hangs off it, clearly marked as \u201cToo Expensive.\u201d  **Right side:** A simpler robot design \u2014 lighter plastic shell, smaller motors, minimal sensors. It looks friendly, approachable, and toy-like. Engineers are actively simplifying it: one erases components from a blueprint with a giant eraser; another removes extra parts while keeping the robot balanced.  Between the two sides is a visual tug-of-war rope labeled \u201cCost vs. Performance.\u201d   <p>Every sensor added cost. Every cheap motor added instability.</p> <p>The real challenge wasn\u2019t balance.</p> <p>It was balance on a budget.</p>"},{"location":"stories/mip/#panel-4-gravity-is-the-villain","title":"Panel 4 \u2014 Gravity Is the Villain","text":"A diagram-style but playful panel. The robot is shown as a simplified figure balancing on two wheels, drawn multiple times in ghosted overlays to show motion over time. A vertical dashed line marks the ideal center of mass directly above the axle.  Large downward arrows labeled \u201cGravity\u201d press constantly from above. Gravity is subtly personified with mischievous expressions \u2014 never evil, just relentless.  The robot is shown slightly leaning forward in one overlay and slightly backward in another, emphasizing instability. The ground beneath is flat but drawn with subtle vibration lines, suggesting how sensitive balance is.  Technical annotations float around the image, like a textbook diagram \u2014 but stylized for a comic.   <p>MiP lives on the edge.</p> <p>Lean too far forward \u2014 fall. Lean too far back \u2014 fall.</p> <p>Do nothing \u2014 fall anyway.</p>"},{"location":"stories/mip/#panel-5-inside-the-robots-mind","title":"Panel 5 \u2014 Inside the Robot\u2019s Mind","text":"A detailed cutaway view of the robot\u2019s interior, shown as if one side of its body is transparent. Inside, a tiny microcontroller sits at the center, glowing softly like a brain. Lines radiate outward to sensors and motors in looping paths.  The control loop is clearly visible: sensor \u2192 processor \u2192 motor \u2192 motion \u2192 sensor again, drawn as a continuous circular arrow.  Three stylized icons float near the processor:  * **P** is bold and alert, holding a ruler (measuring error). * **I** is calm and thoughtful, holding a notebook (tracking history). * **D** is sharp and fast, holding a stopwatch (watching speed).  These characters are abstract and symbolic, not cartoon mascots.   <p>MiP doesn\u2019t balance by instinct.</p> <p>It balances by feedback.</p>"},{"location":"stories/mip/#panel-6-the-speed-of-correction","title":"Panel 6 \u2014 The Speed of Correction","text":"An action-heavy panel showing the robot\u2019s wheels in motion. Motion blur lines indicate micro-adjustments forward and backward. Tiny timestamps float by \u2014 \u201c1 ms,\u201d \u201c2 ms,\u201d \u201c3 ms\u201d \u2014 showing how fast corrections happen.  The robot\u2019s face remains cheerful and calm, contrasting with the intense activity beneath the surface. The environment is slightly blurred to emphasize speed and reaction.  The control loop from the previous panel appears faintly as a ghosted overlay, reinforcing that it never stops running.   <p>MiP measures, decides, and reacts \u2014</p> <p>hundreds of times per second.</p> <p>Balance is not a moment.</p> <p>It\u2019s a process.</p>"},{"location":"stories/mip/#panel-7-software-wins","title":"Panel 7 \u2014 Software Wins","text":"Engineers gathered around a laptop displaying tuning graphs labeled P, I, and D. Sliders and curves adjust dynamically on screen. Two robots sit side by side in the foreground.  One robot jitters nervously, wheels shaking, body oscillating. The other stands smooth and stable. They are physically identical \u2014 the only visible difference is a glowing software icon hovering above the stable one.  The background fades slightly to focus attention on the tuning process.   <p>The parts were modest.</p> <p>The intelligence was precise.</p> <p>Tiny numbers made the difference between chaos and calm.</p>"},{"location":"stories/mip/#panel-8-from-stability-to-fun","title":"Panel 8 \u2014 From Stability to Fun","text":"A lively montage-style panel showing the robot in multiple playful poses: dancing, carrying a small object, responding to a hand gesture, and recovering from a gentle push. Each pose flows into the next with curved motion lines.  Beneath all the action, faint translucent balance loops remain visible, quietly anchoring every movement.  The color palette is bright and joyful, emphasizing playfulness built on stability.   <p>Once MiP could balance\u2026</p> <p>it could be fun.</p> <p>Every trick rode on invisible math.</p>"},{"location":"stories/mip/#panel-9-why-kids-connected","title":"Panel 9 \u2014 Why Kids Connected","text":"Children interact gently with the robot. One child nudges it slightly. The robot leans, corrects, and rolls forward smoothly. Its eyes briefly widen in surprise, then return to a friendly expression.  Importantly, the robot is shown *not* perfectly rigid \u2014 it sways, adjusts, and recovers. Motion lines emphasize resilience rather than stiffness.  The kids are laughing, relaxed, and engaged.   <p>Kids didn\u2019t love MiP because it never fell.</p> <p>They loved it because it didn\u2019t give up.</p>"},{"location":"stories/mip/#panel-10-the-quiet-lesson","title":"Panel 10 \u2014 The Quiet Lesson","text":"A final wide, calm panel. The robot stands upright against a clean background. Faint engineering diagrams \u2014 equations, block diagrams, arrows \u2014 dissolve into playful doodles and motion lines.  Gravity arrows still exist but are smaller now, less threatening. The robot stands centered, balanced, confident.  The composition feels resolved and reflective.   <p>Stability isn\u2019t about being perfect.</p> <p>It\u2019s about correcting fast enough.</p> <p>That\u2019s control theory.</p> <p>That\u2019s engineering.</p> <p>That\u2019s MiP.</p>"}]}